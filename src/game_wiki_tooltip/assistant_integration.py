"""
Integration layer between the new unified UI and existing RAG/Wiki systems.
"""

import asyncio
import logging
import threading
import time
from typing import Optional
from dataclasses import dataclass
import os

from PyQt6.QtCore import QObject, pyqtSignal, QTimer, QThread, Qt, QPoint

from src.game_wiki_tooltip.window_component import AssistantController, TransitionMessages, MessageType, WindowState
from src.game_wiki_tooltip.core.config import SettingsManager
from src.game_wiki_tooltip.ai.rag_config import LLMSettings
from src.game_wiki_tooltip.core.utils import get_foreground_title
from src.game_wiki_tooltip.core.smart_interaction_manager import SmartInteractionManager, InteractionMode

# Lazy load AI modules - import only when needed to speed up startup
logger = logging.getLogger(__name__)
process_query_unified = None
get_default_config = None
EnhancedRagQuery = None
_ai_modules_loaded = False
_ai_modules_loading = False  # Prevent duplicate loading
_ai_load_lock = threading.Lock()  # Thread lock to protect loading state

class AIModuleLoader(QThread):
    """Background thread for loading AI modules"""
    load_completed = pyqtSignal(bool)  # Load completed signal, parameter is success or not
    
    def run(self):
        """Load AI modules in background thread"""
        # Set low priority to avoid affecting UI responsiveness
        try:
            import os
            if hasattr(os, 'nice'):
                os.nice(10)  # Unix/Linux
            else:
                # Windows: set thread priority
                import ctypes
                import sys
                if sys.platform == 'win32':
                    thread_handle = ctypes.windll.kernel32.GetCurrentThread()
                    ctypes.windll.kernel32.SetThreadPriority(thread_handle, -1)  # THREAD_PRIORITY_BELOW_NORMAL
        except Exception as e:
            logger.warning(f"Failed to set thread priority: {e}")
        
        success = _lazy_load_ai_modules()
        self.load_completed.emit(success)

def _lazy_load_ai_modules():
    """Lazy load AI modules, only import when first used"""
    global process_query_unified, get_default_config, EnhancedRagQuery, _ai_modules_loaded, _ai_modules_loading
    
    with _ai_load_lock:
        if _ai_modules_loaded:
            logger.info("âœ… AI modules already loaded (probably during splash screen)")
            return True
            
        if _ai_modules_loading:
            # Another thread is loading, wait for completion
            logger.info("â³ AI module is being loaded by another thread, waiting...")
            while _ai_modules_loading and not _ai_modules_loaded:
                time.sleep(0.1)
            return _ai_modules_loaded
            
        _ai_modules_loading = True
        
    try:
        logger.info("ğŸ”„ Starting AI module loading (fallback - should have been loaded during splash)...")
        start_time = time.time()
        
        # Check if modules were already loaded by splash screen
        if process_query_unified and get_default_config and EnhancedRagQuery:
            logger.info("âœ… AI modules were already loaded by splash screen")
            with _ai_load_lock:
                _ai_modules_loaded = True
                _ai_modules_loading = False
            return True
        
        # Fallback: load modules if not already loaded
        from src.game_wiki_tooltip.ai.unified_query_processor import process_query_unified as _process_query_unified
        from src.game_wiki_tooltip.ai.rag_config import get_default_config as _get_default_config
        from src.game_wiki_tooltip.ai.rag_query import EnhancedRagQuery as _EnhancedRagQuery
        
        process_query_unified = _process_query_unified
        get_default_config = _get_default_config
        EnhancedRagQuery = _EnhancedRagQuery
        
        with _ai_load_lock:
            _ai_modules_loaded = True
            _ai_modules_loading = False
            
        elapsed = time.time() - start_time
        logger.info(f"âœ… AI module loading completed (fallback), time taken: {elapsed:.2f} seconds")
        return True
    except ImportError as e:
        logger.error(f"Failed to import AI components: {e}")
        with _ai_load_lock:
            _ai_modules_loading = False
        return False

def get_selected_game_title():
    """Get current game title from active window"""
    return get_foreground_title()

@dataclass
class QueryIntent:
    """Query intent detection result"""
    intent_type: str  # "wiki" or "guide"
    confidence: float
    rewritten_query: Optional[str] = None
    translated_query: Optional[str] = None  # Add translated query field
    unified_query_result: Optional[object] = None  # Complete unified query result


class QueryWorker(QThread):
    """Worker thread for processing queries asynchronously"""
    
    # Signals
    intent_detected = pyqtSignal(object)  # QueryIntent
    wiki_result = pyqtSignal(str, str)  # url, title
    guide_chunk = pyqtSignal(str)  # streaming chunk
    error_occurred = pyqtSignal(str)  # error message
    
    def __init__(self, rag_integration, query: str, game_context: str = None, search_mode: str = "auto", parent=None):
        super().__init__(parent)
        self.rag_integration = rag_integration
        self.query = query
        self.game_context = game_context
        self.search_mode = search_mode
        self._stop_requested = False
        self._current_task = None  # Current running async task
        
    def run(self):
        """Run the query processing in thread"""
        try:
            # Create event loop for this thread
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            
            try:
                # Process query asynchronously
                loop.run_until_complete(self._process_query())
            finally:
                loop.close()
                
        except Exception as e:
            logger.error(f"Query worker error: {e}")
            self.error_occurred.emit(str(e))
            
    async def _process_query(self):
        """Process the query asynchronously"""
        try:
            # Check if stop has been requested
            if self._stop_requested:
                return
            
            # Wait for AI modules to load if needed (with timeout)
            if not await self._wait_for_ai_modules():
                self.error_occurred.emit("AI modules are still loading. Please try again in a moment.")
                return
                
            # Use unified query processor for intent detection and query optimization
            intent = await self.rag_integration.process_query_async(
                self.query, 
                game_context=self.game_context,
                search_mode=self.search_mode
            )
            
            # Check again if stop has been requested
            if self._stop_requested:
                return
                
            self.intent_detected.emit(intent)
            
            if intent.intent_type == "unsupported":
                # For unsupported window_component, emit error signal directly
                error_msg = f"The current window '{self.game_context}' is not in the list of supported games.\n\nPlease check the settings page for supported games, or try using this tool in a supported game window."
                self.error_occurred.emit(error_msg)
                return
            elif intent.intent_type == "wiki":
                # Check if stop has been requested
                if self._stop_requested:
                    return
                    
                # For wiki search, use original query (because wiki search does not need optimized query)
                search_url, search_title = await self.rag_integration.prepare_wiki_search_async(
                    self.query,  # Use original query for wiki search
                    game_context=self.game_context
                )
                
                if not self._stop_requested:
                    self.wiki_result.emit(search_url, search_title)
            else:
                # Check if stop has been requested
                if self._stop_requested:
                    return
                    
                # For guide query, pass both original query and processed query
                processed_query = intent.rewritten_query or intent.translated_query or self.query
                
                # Set current task and pass stop flag
                self._current_task = self.rag_integration.generate_guide_async(
                    processed_query,  # Query used for retrieval
                    game_context=self.game_context,
                    original_query=self.query,  # Original query, used for answer generation
                    skip_query_processing=True,  # Skip query processing inside RAG
                    unified_query_result=intent.unified_query_result,  # Pass complete unified query result
                    stop_flag=lambda: self._stop_requested  # Pass stop flag check function
                )
                await self._current_task
                
        except asyncio.CancelledError:
            logger.info("Query processing cancelled")
        except Exception as e:
            if not self._stop_requested:  # Only report error if not stopped
                logger.error(f"Query processing error: {e}")
                self.error_occurred.emit(str(e))
    
    async def _wait_for_ai_modules(self) -> bool:
        """Wait for AI modules to load with timeout"""
        max_wait = 5.0  # Maximum 5 seconds
        check_interval = 0.1
        elapsed = 0.0
        
        while elapsed < max_wait:
            # Check if modules are loaded
            if _ai_modules_loaded:
                return True
            
            # Check if stop requested
            if self._stop_requested:
                return False
                
            # Wait a bit
            await asyncio.sleep(check_interval)
            elapsed += check_interval
            
        # Timeout
        return _ai_modules_loaded
            
    def stop(self):
        """Request to stop the worker"""
        try:
            self._stop_requested = True
            logger.info("ğŸ›‘ QueryWorker stop request issued")
            
            # If there's a current task, try to cancel it
            if self._current_task and not self._current_task.done():
                try:
                    self._current_task.cancel()
                    logger.info("ğŸ›‘ Current async task cancelled")
                except Exception as e:
                    logger.error(f"Error cancelling async task: {e}")
                    
        except Exception as e:
            logger.error(f"Error during QueryWorker stop process: {e}")


class RAGIntegration(QObject):
    """Integrates RAG engine with the UI"""
    
    # Signals for UI updates
    streaming_chunk_ready = pyqtSignal(str)
    wiki_result_ready = pyqtSignal(str, str)  # url, title
    wiki_link_updated = pyqtSignal(str, str)  # æ–°ä¿¡å·ï¼šç”¨äºæ›´æ–°èŠå¤©çª—å£ä¸­çš„wikié“¾æ¥
    error_occurred = pyqtSignal(str)
    
    def __init__(self, settings_manager: SettingsManager, limited_mode: bool = False):
        super().__init__()
        self.settings_manager = settings_manager
        self.limited_mode = limited_mode
        self.rag_engine = None
        self.query_processor = None
        self._pending_wiki_update = None  # Store wiki link information to be updated
        self._llm_config = None  # Store configured LLM configuration
        
        # RAG initialization state tracking
        self._rag_initializing = False  # Flag to prevent duplicate initializations
        self._rag_init_game = None      # Track which game is being initialized
        self._current_rag_game = None   # Track current initialized game
        
        # Initialize game configuration manager

        # Select game configuration file based on language settings
        self._init_game_config_manager()
        
        # Initialize AI components based on mode
        if limited_mode:
            logger.info("ğŸš¨ RAG Integration running in limited mode, skipping AI component initialization")
        else:
            self._init_ai_components()
            
    def _init_game_config_manager(self):
        """Initialize game configuration manager based on language settings"""
        from src.game_wiki_tooltip.core.utils import APPDATA_DIR
        from src.game_wiki_tooltip.core.config import GameConfigManager
        
        # Get current language settings
        settings = self.settings_manager.get()
        current_language = settings.get('language', 'zh')  # Default to Chinese
        
        # Select configuration file based on language
        if current_language == 'en':
            games_config_path = APPDATA_DIR / "games_en.json"
            logger.info(f"ğŸŒ Using English game configuration: {games_config_path}")
        else:
            # Default to Chinese configuration (zh or other)
            games_config_path = APPDATA_DIR / "games_zh.json"
            logger.info(f"ğŸŒ Using Chinese game configuration: {games_config_path}")
            
        # Check if configuration file exists, fallback to default games.json if not
        if not games_config_path.exists():
            logger.warning(f"âš ï¸ Language configuration file not found: {games_config_path}")
            fallback_path = APPDATA_DIR / "games.json"
            if fallback_path.exists():
                games_config_path = fallback_path
                logger.info(f"ğŸ“„ Falling back to default configuration file: {games_config_path}")
            else:
                logger.error(f"âŒ Even default configuration file doesn't exist: {fallback_path}")
        
        self.game_cfg_mgr = GameConfigManager(games_config_path)
        self._current_language = current_language
        logger.info(f"âœ… Game configuration manager initialized, current language: {current_language}")
        
    def reload_for_language_change(self):
        """Reload game configuration when language settings change"""
        logger.info("ğŸ”„ Language setting change detected, reloading game configuration")
        self._init_game_config_manager()
        
    def _init_ai_components(self):
        """Initialize AI components with settings"""
        # Skip AI component initialization if in limited mode
        if self.limited_mode:
            logger.info("ğŸš¨ Skipping AI component initialization in limited mode")
            return
            
        # Just log that we'll initialize on demand - don't actually initialize anything
        logger.info("ğŸ“Œ AI components will be initialized on first use (lazy loading)")
        
    def _ensure_ai_components_loaded(self):
        """Ensure AI components are loaded (called before actual use)"""
        if self.limited_mode:
            return False
            
        # If AI modules are loading, wait but don't block UI
        if _ai_modules_loading:
            logger.info("â³ AI modules are loading in background...")
            # For UI operations, return immediately
            # The actual query processing will handle waiting
            if not _ai_modules_loaded:
                return False
        
        # Try to load AI modules
        if not _lazy_load_ai_modules():
            logger.error("âŒ AI module loading failed")
            return False
            
        # Initialize only when first called
        if hasattr(self, '_ai_initialized') and self._ai_initialized:
            return True
            
        try:
            # Get API settings
            settings = self.settings_manager.get()
            api_settings = settings.get('api', {})
            gemini_api_key = api_settings.get('gemini_api_key', '')
            # No longer need separate Jina API key, use Gemini API key for embeddings
            
            # Check environment variables
            if not gemini_api_key:
                gemini_api_key = os.getenv('GEMINI_API_KEY') or os.getenv('GOOGLE_API_KEY')
            # Gemini API key is used for both LLM and embeddings
            
            # Check if API key is available
            has_api_key = bool(gemini_api_key)
            
            if has_api_key:
                logger.info("âœ… Complete API key configuration detected, initializing AI components")
                
                llm_config = LLMSettings(
                    api_key=gemini_api_key,
                    model='gemini-2.5-flash-lite'
                )
                
                # Store LLM configuration for other methods
                self._llm_config = llm_config
                
                # Initialize query processor - remove, we will directly use process_query_unified function
                # if process_query_unified:
                #     self.query_processor = process_query_unified(llm_config=llm_config)
                
                # Don't read game window at startup - wait for user interaction
                logger.info("âœ… AI components configuration ready, RAG will be initialized on demand")
                self._last_game_window = None
                self._last_vector_game_name = None
            else:
                missing_keys = []
                if not gemini_api_key:
                    missing_keys.append("Gemini API Key")
                if not has_api_key:
                    missing_keys.append("Jina API Key")
                
                logger.warning(f"âŒ Missing required API keys: {', '.join(missing_keys)}")
                logger.warning("Cannot initialize AI components, need to configure both Gemini API Key and Jina API Key")
                return False
                    
        except Exception as e:
            logger.error(f"Failed to initialize AI components: {e}")
            return False
            
        self._ai_initialized = True
        return True
            
    def _init_rag_for_game(self, game_name: str, llm_config: LLMSettings, google_api_key: str, wait_for_init: bool = False):
        """Initialize RAG engine for specific game"""
        try:
            # Check if already initializing or initialized for this game
            if self._rag_initializing and self._rag_init_game == game_name:
                logger.info(f"âš ï¸ RAG initialization already in progress for game '{game_name}', skipping duplicate")
                return
                
            if self._current_rag_game == game_name and self.rag_engine:
                logger.info(f"âœ“ RAG engine already initialized for game '{game_name}', no need to reinitialize")
                return
            
            # Mark as initializing
            self._rag_initializing = True
            self._rag_init_game = game_name
            
            # Ensure AI components are loaded first
            if not _ai_modules_loaded:
                logger.info("AI modules not yet loaded, ensuring they are loaded first...")
                if not self._ensure_ai_components_loaded():
                    logger.error("Failed to load AI components, cannot initialize RAG")
                    self._rag_initializing = False
                    self._rag_init_game = None
                    return
            
            if not (get_default_config and EnhancedRagQuery):
                logger.warning("RAG components not available after loading attempt")
                self._rag_initializing = False
                self._rag_init_game = None
                return
                
            logger.info(f"ğŸ”„ Initializing new RAG engine for game '{game_name}'")
            
            # Clear old RAG engine
            if hasattr(self, 'rag_engine') and self.rag_engine:
                logger.info("ğŸ—‘ï¸ Clearing old RAG engine instance")
                self.rag_engine = None
                
            # Get RAG config
            rag_config = get_default_config()
            
            # Custom hybrid search configuration, disable unified query processing
            custom_hybrid_config = rag_config.hybrid_search.to_dict()
            custom_hybrid_config["enable_unified_processing"] = False  # Disable unified query processing
            custom_hybrid_config["enable_query_rewrite"] = False      # Disable query rewrite
            custom_hybrid_config["enable_query_translation"] = False  # Disable query translation
            
            # Create RAG engine
            self.rag_engine = EnhancedRagQuery(
                vector_store_path=None,  # Will be auto-detected
                enable_hybrid_search=rag_config.hybrid_search.enabled,
                hybrid_config=custom_hybrid_config,  # Use custom configuration
                llm_config=llm_config,
                google_api_key=google_api_key,  # Pass Google API key
                enable_query_rewrite=False,  # Disable query rewrite, avoid duplicate LLM calls
                enable_summarization=rag_config.summarization.enabled,
                summarization_config=rag_config.summarization.to_dict(),
                enable_intent_reranking=rag_config.intent_reranking.enabled,
                reranking_config=rag_config.intent_reranking.to_dict()
            )
            
            # Initialize the engine in thread
            def init_rag():
                # Set low priority to avoid affecting UI responsiveness
                try:
                    import os
                    if hasattr(os, 'nice'):
                        os.nice(10)  # Unix/Linux
                    else:
                        # Windows: set thread priority
                        import ctypes
                        import sys
                        if sys.platform == 'win32':
                            thread_handle = ctypes.windll.kernel32.GetCurrentThread()
                            ctypes.windll.kernel32.SetThreadPriority(thread_handle, -2)  # THREAD_PRIORITY_LOWEST
                except Exception as e:
                    logger.warning(f"Failed to set thread priority: {e}")
                
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                try:
                    logger.info(f"ğŸš€ Starting async RAG engine initialization (game: {game_name})")
                    loop.run_until_complete(self.rag_engine.initialize(game_name))
                    logger.info(f"âœ… RAG engine initialization completed (game: {game_name})")
                    self._rag_init_complete = True
                    self._current_rag_game = game_name  # Record current RAG engine game
                    # Clear initialization flags on success
                    self._rag_initializing = False
                    self._rag_init_game = None
                    # Clear error information
                    if hasattr(self, '_rag_init_error'):
                        delattr(self, '_rag_init_error')
                except Exception as e:
                    logger.error(f"âŒ RAG engine initialization failed (game: {game_name}): {e}")
                    self.rag_engine = None
                    self._rag_init_complete = False
                    self._rag_init_error = str(e)  # Record initialization error
                    self._current_rag_game = None
                    # Clear initialization flags on failure
                    self._rag_initializing = False
                    self._rag_init_game = None
                finally:
                    loop.close()
            
            # Reset initialization status
            self._rag_init_complete = False
            
            # Run initialization in a separate thread
            import threading
            init_thread = threading.Thread(target=init_rag)
            init_thread.daemon = True
            init_thread.start()
            
            # If waiting for initialization to complete
            if wait_for_init:
                # Wait for initialization to complete, up to 5 seconds
                import time
                start_time = time.time()
                while not hasattr(self, '_rag_init_complete') or not self._rag_init_complete:
                    if time.time() - start_time > 5:  # Timeout
                        logger.warning("RAG initialization timeout")
                        break
                    time.sleep(0.1)
            
        except Exception as e:
            logger.error(f"Failed to initialize RAG for {game_name}: {e}")
            # Ensure initialization flags are cleared on any error
            self._rag_initializing = False
            self._rag_init_game = None
            
    async def process_query_async(self, query: str, game_context: str = None, search_mode: str = "auto") -> QueryIntent:
        """Process query using unified query processor for intent detection"""
        logger.info(f"Start unified query processing: '{query}' (game context: {game_context}, search mode: {search_mode}, limited mode: {self.limited_mode})")
        
        # Handle manual search mode selection
        if search_mode == "wiki":
            logger.info("ğŸ“š Manual wiki search mode selected")
            return QueryIntent(
                intent_type='wiki',
                confidence=1.0,
                rewritten_query=query,
                translated_query=query
            )
        elif search_mode == "ai":
            logger.info("ğŸ¤– Manual AI search mode selected")
            return QueryIntent(
                intent_type='guide',
                confidence=1.0,
                rewritten_query=query,
                translated_query=query
            )
        
        # If in limited mode, always return wiki intent
        if self.limited_mode:
            logger.info("ğŸš¨ In limited mode, all queries will be treated as wiki queries")
            return QueryIntent(
                intent_type='wiki',
                confidence=0.9,
                rewritten_query=query,
                translated_query=query
            )
            
        # Ensure AI components are loaded (lazy loading)
        if not self._ensure_ai_components_loaded():
            logger.error("âŒ AI component loading failed, switch to wiki mode")
            return QueryIntent(
                intent_type='wiki',
                confidence=0.9,
                rewritten_query=query,
                translated_query=query
            )
        
        # âœ… New: Before calling LLM, check if the game window supports RAG guide query (has vector library)
        if game_context:
            # 1. Check if RAG guide query is supported (has vector library)
            from .ai.rag_query import map_window_title_to_game_name
            game_name = map_window_title_to_game_name(game_context)
            
            # 2. Check if it is supported in games.json configuration (supports wiki query)
            is_wiki_supported = self._is_game_supported_for_wiki(game_context)
            
            # If neither RAG guide query nor wiki query is supported, return unsupported
            if not game_name and not is_wiki_supported:
                logger.info(f"ğŸ“‹ Window '{game_context}' does not support guide query")
                return QueryIntent(
                    intent_type='unsupported',
                    confidence=1.0,
                    rewritten_query=query,
                    translated_query=query
                )
        else:
            # If there is no game context (no recorded game window), skip unified query processing, use simple intent detection
            logger.info("ğŸ“‹ No recorded game window, skip unified query processing, use simple intent detection")
            return self._simple_intent_detection(query)
        
        if not process_query_unified:
            # Fallback to simple detection
            logger.warning("Unified query processor is not available, use simple intent detection")
            return self._simple_intent_detection(query)
            
        try:
            # Use stored LLM configuration, if not create temporary configuration
            llm_config = self._llm_config
            if not llm_config:
                # If there is no stored configuration, create temporary configuration and check API key
                llm_config = LLMSettings(
                    model='gemini-2.5-flash-lite'
                )
                
                # Use LLMSettings's get_api_key method to get API key (supports GEMINI_API_KEY environment variable)
                api_key = llm_config.get_api_key()
                if not api_key:
                    logger.warning("GEMINI_API_KEY not configured, use simple intent detection")
                    return self._simple_intent_detection(query)
                    
                # Update API key in configuration
                llm_config.api_key = api_key
            else:
                # Use stored configuration, verify API key
                api_key = llm_config.get_api_key()
                if not api_key:
                    logger.warning("Stored LLM configuration does not have a valid API key, use simple intent detection")
                    return self._simple_intent_detection(query)
            
            # Use unified query processor for processing (merged translation, rewrite, intent detection)
            result = await asyncio.to_thread(
                process_query_unified,
                query,
                llm_config=llm_config
            )
            
            logger.info(f"Unified processing successful: '{query}' -> intent: {result.intent} (confidence: {result.confidence:.3f})")
            logger.info(f"  Translated result: '{result.translated_query}'")
            logger.info(f"  Rewritten result: '{result.rewritten_query}'")
            logger.info(f"  BM25 optimized: '{result.bm25_optimized_query}'")
            
            return QueryIntent(
                intent_type=result.intent,
                confidence=result.confidence,
                rewritten_query=result.rewritten_query,
                translated_query=result.translated_query,  # Add translated query
                unified_query_result=result  # Pass complete unified query result
            )
            
        except Exception as e:
            logger.error(f"Unified query processing failed: {e}")
            return self._simple_intent_detection(query)
            
    def _is_game_supported_for_wiki(self, window_title: str) -> bool:
        """Check if the game window supports wiki query (based on games.json configuration)"""
        try:
            # Get game configuration
            if hasattr(self, 'game_cfg_mgr') and self.game_cfg_mgr:
                game_config = self.game_cfg_mgr.for_title(window_title)
                if game_config:
                    logger.info(f"ğŸ® Window '{window_title}' found in games.json, supports wiki query")
                    return True
            
            logger.info(f"ğŸ“‹ Window '{window_title}' not found in games.json")
            return False
        except Exception as e:
            logger.error(f"Error checking game configuration: {e}")
            return False
            
    def _simple_intent_detection(self, query: str) -> QueryIntent:
        """Simple keyword-based intent detection"""
        # If in limited mode, always return wiki intent
        if self.limited_mode:
            return QueryIntent(
                intent_type='wiki',
                confidence=0.9,
                rewritten_query=query,
                translated_query=query
            )
            
        query_lower = query.lower()
        
        # Wiki intent keywords
        wiki_keywords = ['æ˜¯ä»€ä¹ˆ', 'what is', 'wiki', 'ä»‹ç»', 'info']
        # Guide intent keywords  
        guide_keywords = ['æ€ä¹ˆ', 'å¦‚ä½•', 'how to', 'guide', 'æ¨è', 'best']
        
        wiki_score = sum(1 for kw in wiki_keywords if kw in query_lower)
        guide_score = sum(1 for kw in guide_keywords if kw in query_lower)
        
        if wiki_score > guide_score:
            return QueryIntent(
                intent_type='wiki', 
                confidence=0.7, 
                rewritten_query=query,
                translated_query=query
            )
        else:
            return QueryIntent(
                intent_type='guide', 
                confidence=0.7,
                rewritten_query=query,
                translated_query=query
            )
            
    async def prepare_wiki_search_async(self, query: str, game_context: str = None) -> tuple[str, str]:
        """Prepare wiki search, return search URL and initial title, real URL will be obtained through JavaScript callback"""
        try:
            from urllib.parse import quote, urlparse
            
            # Use the incoming game context, if not get the current game window title
            game_title = game_context or get_selected_game_title()
            logger.info(f"ğŸ® Current game window title: {game_title}")
            
            # Find game configuration - use instance variable
            game_config = self.game_cfg_mgr.for_title(game_title)
            
            if not game_config:
                logger.warning(f"Game configuration not found: {game_title}")
                # Fallback to general search
                search_query = f"{game_title} {query} wiki"
                ddg_url = f"https://duckduckgo.com/?q=!ducky+{quote(search_query)}"
                # Store wiki information to be updated (marked as DuckDuckGo search)
                self._pending_wiki_update = {
                    "initial_url": ddg_url,
                    "query": query,
                    "title": f"Search: {query}",
                    "status": "searching"
                }
            else:
                logger.info(f"Game configuration found: {game_config}")
                
                # Get base URL
                base_url = game_config.BaseUrl
                logger.info(f"Game base URL: {base_url}")
                
                # Extract domain
                if base_url.startswith(('http://', 'https://')):
                    domain = urlparse(base_url).hostname or ''
                else:
                    # If there is no protocol prefix, use base_url as domain
                    domain = base_url.split('/')[0]  # Remove path part
                
                logger.info(f"Extracted domain: {domain}")
                
                # Build correct search query: site:domain user query
                search_query = f"site:{domain} {query}"
                ddg_url = f"https://duckduckgo.com/?q=!ducky+{quote(search_query)}"
                
                logger.info(f"Built search query: {search_query}")
                logger.info(f"DuckDuckGo URL: {ddg_url}")
                
                # Store wiki information to be updated
                self._pending_wiki_update = {
                    "initial_url": ddg_url,
                    "query": query,
                    "title": f"Search: {query}",
                    "domain": domain,
                    "status": "searching"
                }
            
            # Return search URL and temporary title, real URL will be updated through JavaScript callback
            return ddg_url, f"Search: {query}"
                    
        except Exception as e:
            logger.error(f"Wiki search preparation failed: {e}")
            return "", query
            
    def on_wiki_found(self, real_url: str, real_title: str = None):
        """When JavaScript finds the real wiki page, call this method"""
        if self._pending_wiki_update:
            logger.info(f"ğŸ“„ JavaScript found the real wiki page: {real_url}")
            
            # Extract page title (if not provided)
            if not real_title:
                # Extract title from URL
                try:
                    from urllib.parse import unquote
                    parts = real_url.split('/')
                    if parts:
                        real_title = unquote(parts[-1]).replace('_', ' ')
                    else:
                        real_title = self._pending_wiki_update.get("query", "Wiki page")
                except:
                    real_title = self._pending_wiki_update.get("query", "Wiki page")
            
            # Update pending wiki information
            self._pending_wiki_update.update({
                "real_url": real_url,
                "real_title": real_title,
                "status": "found"
            })
            
            # Emit signal to update link in chat window
            self.wiki_link_updated.emit(real_url, real_title)
            logger.info(f"âœ… Emitted wiki link update signal: {real_title} -> {real_url}")
            
            # Clear pending update information
            self._pending_wiki_update = None
        else:
            logger.warning("âš ï¸ Received wiki page callback, but no pending wiki information")
            
    async def generate_guide_async(self, query: str, game_context: str = None, original_query: str = None, skip_query_processing: bool = False, unified_query_result = None, stop_flag = None):
        """Generate guide response with streaming
        
        Args:
            query: å¤„ç†åçš„æŸ¥è¯¢æ–‡æœ¬
            game_context: æ¸¸æˆä¸Šä¸‹æ–‡
            original_query: åŸå§‹æŸ¥è¯¢ï¼ˆç”¨äºç­”æ¡ˆç”Ÿæˆï¼‰
            skip_query_processing: æ˜¯å¦è·³è¿‡RAGå†…éƒ¨çš„æŸ¥è¯¢å¤„ç†
            unified_query_result: é¢„å¤„ç†çš„ç»Ÿä¸€æŸ¥è¯¢ç»“æœï¼ˆæ¥è‡ªprocess_query_unifiedï¼‰
        """
        # If in limited mode, display corresponding prompt information
        if self.limited_mode:
            logger.info("ğŸš¨ In limited mode, AI guide features are unavailable")
            self.error_occurred.emit(
                "ğŸš¨ AI Guide Features Unavailable\n\n"
                "Currently running in limited mode with Wiki search only.\n\n"
                "To use AI guide features, please configure both API keys (both required):\n"
                "â€¢ Google/Gemini API Key (required) - for AI reasoning\n"
                "â€¢ Jina API Key (required) - for vector search\n\n"
                "âš ï¸ Note: Gemini API alone cannot provide high-quality RAG functionality.\n"
                "Jina vector search is essential for complete AI guide features.\n\n"
                "Restart the program after configuration to enable full functionality."
            )
            return
            
        if not self.rag_engine:
            # Try to initialize RAG engine for specified game
            if game_context:
                from src.game_wiki_tooltip.ai.rag_query import map_window_title_to_game_name
                vector_game_name = map_window_title_to_game_name(game_context)
                
                if vector_game_name:
                    logger.info(f"RAG engine not initialized, attempting to initialize for game '{vector_game_name}'")
                    
                    # Get API settings
                    settings = self.settings_manager.get()
                    api_settings = settings.get('api', {})
                    gemini_api_key = api_settings.get('gemini_api_key', '')
                    # No longer need separate Jina API key, use Gemini API key for embeddings
                    
                    # Check environment variables
                    if not gemini_api_key:
                        gemini_api_key = os.getenv('GEMINI_API_KEY') or os.getenv('GOOGLE_API_KEY')
                    
                    # Check if API key is available
                    has_api_key = bool(gemini_api_key)
                    
                    if has_api_key:
                        llm_config = LLMSettings(
                            api_key=gemini_api_key,
                            model='gemini-2.5-flash-lite'
                        )
                        
                        # Check if RAG is already initializing
                        if self._rag_initializing and self._rag_init_game == vector_game_name:
                            logger.info(f"RAG already initializing for {vector_game_name}, showing status and queueing query")
                            # Show initialization status
                            self.streaming_chunk_ready.emit("ğŸš€ AI guide system is initializing, please wait a moment...")
                            
                            # Queue the query to be processed after initialization
                            self._pending_query = {
                                'query': query,
                                'game_context': game_context,
                                'original_query': original_query,
                                'skip_query_processing': skip_query_processing,
                                'unified_query_result': unified_query_result,
                                'stop_flag': stop_flag
                            }
                            
                            # Start checking initialization status
                            if not hasattr(self, '_init_check_timer') or not self._init_check_timer:
                                from PyQt6.QtCore import QTimer
                                self._init_check_timer = QTimer()
                                self._init_check_timer.timeout.connect(self._check_rag_init_and_process_query)
                                self._init_check_timer.start(100)  # Check every 100ms
                            return
                        
                        # Use asynchronous initialization to avoid blocking UI
                        self._init_rag_for_game(vector_game_name, llm_config, gemini_api_key, wait_for_init=False)
                        
                        # Show initialization status
                        self.streaming_chunk_ready.emit("ğŸš€ AI guide system is initializing for the first time, please wait...")
                        
                        # Queue the query
                        self._pending_query = {
                            'query': query,
                            'game_context': game_context,
                            'original_query': original_query,
                            'skip_query_processing': skip_query_processing,
                            'unified_query_result': unified_query_result,
                            'stop_flag': stop_flag
                        }
                        
                        # Start checking initialization status
                        if not hasattr(self, '_init_check_timer') or not self._init_check_timer:
                            from PyQt6.QtCore import QTimer
                            self._init_check_timer = QTimer()
                            self._init_check_timer.timeout.connect(self._check_rag_init_and_process_query)
                            self._init_check_timer.start(100)  # Check every 100ms
                        
                        return
                    else:
                        missing_keys = []
                        if not gemini_api_key:
                            missing_keys.append("Gemini API Key")
                        if not has_api_key:
                            missing_keys.append("Jina API Key")
                        
                        # Use internationalized error information
                        from src.game_wiki_tooltip.core.i18n import get_current_language
                        current_lang = get_current_language()
                        
                        if current_lang == 'zh':
                            error_msg = (
                                f"âŒ ç¼ºå°‘å¿…éœ€çš„APIå¯†é’¥: {', '.join(missing_keys)}\n\n"
                                "AIæ”»ç•¥åŠŸèƒ½éœ€è¦åŒæ—¶é…ç½®ä¸¤ä¸ªAPIå¯†é’¥ï¼š\n"
                                "â€¢ Google/Gemini API Key - ç”¨äºAIæ¨ç†\n"
                                "â€¢ Jina API Key - ç”¨äºå‘é‡æœç´¢\n\n"
                                "âš ï¸ æ³¨æ„ï¼šä»…æœ‰Gemini APIæ— æ³•æä¾›é«˜è´¨é‡çš„RAGåŠŸèƒ½ã€‚\n"
                                "Jinaå‘é‡æœç´¢å¯¹å®Œæ•´çš„AIæ”»ç•¥åŠŸèƒ½è‡³å…³é‡è¦ã€‚\n\n"
                                "è¯·åœ¨è®¾ç½®ä¸­é…ç½®å®Œæ•´çš„APIå¯†é’¥å¹¶é‡è¯•ã€‚"
                            )
                        else:
                            error_msg = (
                                f"âŒ Missing required API keys: {', '.join(missing_keys)}\n\n"
                                "AI guide features require both API keys to be configured:\n"
                                "â€¢ Google/Gemini API Key - for AI reasoning\n"
                                "â€¢ Jina API Key - for vector search\n\n"
                                "âš ï¸ Note: Gemini API alone cannot provide high-quality RAG functionality.\n"
                                "Jina vector search is essential for complete AI guide features.\n\n"
                                "Please configure complete API keys in settings and try again."
                            )
                        
                        self.error_occurred.emit(error_msg)
                        return
                else:
                    logger.info(f"ğŸ“‹ Window '{game_context}' does not support guide queries")
                    
                    # Use internationalized error information
                    from src.game_wiki_tooltip.core.i18n import get_current_language
                    current_lang = get_current_language()
                    
                    if current_lang == 'zh':
                        error_msg = (
                            f"ğŸ® çª—å£ '{game_context}' æš‚æ—¶ä¸æ”¯æŒæ”»ç•¥æŸ¥è¯¢\n\n"
                            "ğŸ’¡ å»ºè®®ï¼šæ‚¨å¯ä»¥å°è¯•ä½¿ç”¨Wikiæœç´¢åŠŸèƒ½æŸ¥æ‰¾ç›¸å…³ä¿¡æ¯\n\n"
                            "ğŸ“š ç›®å‰æ”¯æŒæ”»ç•¥æŸ¥è¯¢çš„æ¸¸æˆï¼š\n"
                            "â€¢ åœ°ç‹±æ½œå…µ2 (HELLDIVERS 2) - æ­¦å™¨é…è£…ã€æ•Œäººæ”»ç•¥ç­‰\n"
                            "â€¢ è‰¾å°”ç™»æ³•ç¯ (Elden Ring) - Bossæ”»ç•¥ã€è£…å¤‡æ¨èç­‰\n"
                            "â€¢ é¥¥è’è”æœºç‰ˆ (Don't Starve Together) - ç”Ÿå­˜æŠ€å·§ã€è§’è‰²æ”»ç•¥ç­‰\n"
                            "â€¢ æ–‡æ˜6 (Civilization VI) - æ–‡æ˜ç‰¹è‰²ã€èƒœåˆ©ç­–ç•¥ç­‰"
                        )
                    else:
                        error_msg = (
                            f"ğŸ® Window '{game_context}' doesn't support guide queries yet\n\n"
                            "ğŸ’¡ Suggestion: You can try using the Wiki search function to find related information\n\n"
                            "ğŸ“š Games currently supporting guide queries:\n"
                            "â€¢ HELLDIVERS 2 - Weapon builds, enemy guides, etc.\n"
                            "â€¢ Elden Ring - Boss guides, equipment recommendations, etc.\n"
                            "â€¢ Don't Starve Together - Survival tips, character guides, etc.\n"
                            "â€¢ Civilization VI - Civilization features, victory strategies, etc."
                        )
                    
                    self.error_occurred.emit(error_msg)
                    return
            else:
                self.error_occurred.emit("RAG engine not initialized and no game context provided")
                return
            
        try:
            # Query RAG engine (it's already async)
            logger.info(f"ğŸ” Directly use processed query for RAG search: '{query}'")
            if original_query:
                logger.info(f"ğŸ“ Use original query for answer generation: '{original_query}'")
            if skip_query_processing:
                logger.info("âš¡ Skip RAG internal query processing, use optimized query")
            if unified_query_result:
                logger.info(f"ğŸ”„ Pass preprocessed unified query result, avoid duplicate processing")
                logger.info(f"   - BM25 optimized query: '{unified_query_result.bm25_optimized_query}'")
            
            # Directly use streaming RAG query, process all logic during streaming
            logger.info("ğŸŒŠ Use streaming RAG query")
            stream_generator = None
            try:
                has_output = False
                # Get streaming generator
                stream_generator = self.rag_engine.query_stream(
                    question=query, 
                    top_k=3, 
                    original_query=original_query,
                    unified_query_result=unified_query_result
                )
                
                # Use real streaming API
                async for chunk in stream_generator:
                    # Check if stop is requested
                    if stop_flag and stop_flag():
                        logger.info("ğŸ›‘ Stop requested, interrupt streaming")
                        break
                        
                    # Ensure chunk is string type
                    if isinstance(chunk, dict):
                        logger.warning(f"Received dictionary type chunk, skip: {chunk}")
                        continue
                    
                    chunk_str = str(chunk) if chunk is not None else ""
                    if chunk_str.strip():  # Only send non-empty content
                        has_output = True
                        self.streaming_chunk_ready.emit(chunk_str)
                        await asyncio.sleep(0.01)  # Very short delay to keep UI responsive
                
                # If there is no output, it may need to switch to wiki mode
                if not has_output:
                    # Check if stop was requested before switching to wiki
                    if stop_flag and stop_flag():
                        logger.info("ğŸ›‘ Stop requested, not switching to wiki mode")
                        return
                        
                    logger.info(f"ğŸ”„ RAG query has no output, may need to switch to wiki mode: '{query}'")
                    
                    from src.game_wiki_tooltip.core.i18n import get_current_language
                    current_lang = get_current_language()
                    
                    if current_lang == 'zh':
                        self.streaming_chunk_ready.emit("ğŸ’¡ è¯¥æ¸¸æˆæš‚æ— æ”»ç•¥æ•°æ®åº“ï¼Œä¸ºæ‚¨è‡ªåŠ¨åˆ‡æ¢åˆ°Wikiæœç´¢æ¨¡å¼...\n\n")
                    else:
                        self.streaming_chunk_ready.emit("ğŸ’¡ No guide database for this game, automatically switching to Wiki search mode...\n\n")
                    
                    # è‡ªåŠ¨åˆ‡æ¢åˆ°wikiæœç´¢
                    try:
                        search_url, search_title = await self.prepare_wiki_search_async(query, game_context)
                        self.wiki_result_ready.emit(search_url, search_title)
                        
                        if current_lang == 'zh':
                            self.streaming_chunk_ready.emit(f"ğŸ”— å·²ä¸ºæ‚¨æ‰“å¼€Wikiæœç´¢: {search_title}\n")
                        else:
                            self.streaming_chunk_ready.emit(f"ğŸ”— Wiki search opened: {search_title}\n")
                    except Exception as wiki_error:
                        logger.error(f"Auto Wiki search failed: {wiki_error}")
                        if current_lang == 'zh':
                            self.streaming_chunk_ready.emit("âŒ Auto Wiki search failed, please click Wiki search button manually\n")
                        else:
                            self.streaming_chunk_ready.emit("âŒ Auto Wiki search failed, please click Wiki search button manually\n")
                    return
                
                logger.info("âœ… Streaming RAG query completed")
                return
                    
            except Exception as e:
                # Handle specific RAG error types
                from src.game_wiki_tooltip.ai.rag_query import VectorStoreUnavailableError
                from src.game_wiki_tooltip.ai.enhanced_bm25_indexer import BM25UnavailableError
                from src.game_wiki_tooltip.core.i18n import t, get_current_language
                
                current_lang = get_current_language()
                error_str = str(e)
                
                # Check for rate limit errors
                if "API_RATE_LIMIT" in error_str or "quota" in error_str.lower() or "rate limit" in error_str.lower() or "429" in error_str:
                    logger.warning("â±ï¸ API rate limit detected")
                    if current_lang == 'zh':
                        error_msg = (
                            "â±ï¸ **API ä½¿ç”¨é™åˆ¶**\n\n"
                            "æ‚¨å·²è¾¾åˆ° Google Gemini API çš„ä½¿ç”¨é™åˆ¶ã€‚å…è´¹è´¦æˆ·é™åˆ¶ï¼š\n"
                            "â€¢ æ¯åˆ†é’Ÿæœ€å¤š 15 æ¬¡è¯·æ±‚\n"
                            "â€¢ æ¯å¤©æœ€å¤š 1500 æ¬¡è¯·æ±‚\n\n"
                            "è¯·ç¨ç­‰ç‰‡åˆ»åå†è¯•ï¼Œæˆ–è€ƒè™‘å‡çº§åˆ°ä»˜è´¹è´¦æˆ·ä»¥è·å¾—æ›´é«˜çš„é…é¢ã€‚"
                        )
                    else:
                        error_msg = (
                            "â±ï¸ **API Rate Limit**\n\n"
                            "You've reached the Google Gemini API usage limit. Free tier limits:\n"
                            "â€¢ Maximum 15 requests per minute\n"
                            "â€¢ Maximum 1500 requests per day\n\n"
                            "Please wait a moment and try again, or consider upgrading to a paid account for higher quotas."
                        )
                    self.streaming_chunk_ready.emit(error_msg)
                    return
                elif isinstance(e, VectorStoreUnavailableError):
                    if current_lang == 'zh':
                        error_msg = f"âŒ {t('rag_vector_store_error')}: {str(e)}"
                    else:
                        error_msg = f"âŒ {t('rag_vector_store_error')}: {str(e)}"
                elif isinstance(e, BM25UnavailableError):
                    if current_lang == 'zh':
                        error_msg = f"âŒ {t('rag_bm25_error')}: {str(e)}"
                    else:
                        error_msg = f"âŒ {t('rag_bm25_error')}: {str(e)}"
                else:
                    # General error - try to switch to wiki mode automatically
                    logger.error(f"Streaming RAG query failed: {e}")
                    
                    # Check if stop was requested before switching to wiki
                    if stop_flag and stop_flag():
                        logger.info("ğŸ›‘ Stop requested, not switching to wiki mode after error")
                        return
                        
                    logger.info("Trying to switch to Wiki search mode...")
                    
                    try:
                        # å¦‚æœæµå¼æŸ¥è¯¢å¤±è´¥ï¼Œè‡ªåŠ¨åˆ‡æ¢åˆ°wikiæœç´¢
                        if current_lang == 'zh':
                            self.streaming_chunk_ready.emit("âŒ AIæ”»ç•¥æŸ¥è¯¢é‡åˆ°é—®é¢˜ï¼Œä¸ºæ‚¨è‡ªåŠ¨åˆ‡æ¢åˆ°Wikiæœç´¢...\n\n")
                        else:
                            self.streaming_chunk_ready.emit("âŒ AI guide query encountered an issue, automatically switching to Wiki search...\n\n")
                        
                        search_url, search_title = await self.prepare_wiki_search_async(query, game_context)
                        self.wiki_result_ready.emit(search_url, search_title)
                        
                        if current_lang == 'zh':
                            self.streaming_chunk_ready.emit(f"ğŸ”— å·²ä¸ºæ‚¨æ‰“å¼€Wikiæœç´¢: {search_title}\n")
                        else:
                            self.streaming_chunk_ready.emit(f"ğŸ”— Wiki search opened: {search_title}\n")
                        return
                    except Exception as wiki_error:
                        logger.error(f"Auto Wiki search also failed: {wiki_error}")
                        if current_lang == 'zh':
                            error_msg = f"âŒ AI guide query failed, and Wiki search also failed. Please try again later.\nError details: {str(e)}"
                        else:
                            error_msg = f"âŒ AI guide query failed, and Wiki search also failed. Please try again later.\nError details: {str(e)}"
                    
                # Send error information (for specific error types or wiki search failure)
                if 'error_msg' in locals():
                    logger.error(f"Send error information to chat window: {error_msg}")
                    self.streaming_chunk_ready.emit(error_msg)
                return
            finally:
                # Ensure asynchronous generator is properly closed
                if stream_generator is not None:
                    try:
                        await stream_generator.aclose()
                        logger.debug("Asynchronous generator properly closed")
                    except Exception as close_error:
                        logger.warning(f"Error closing asynchronous generator: {close_error}")
                    
        except Exception as e:
            logger.error(f"Guide generation failed: {e}")
            self.error_occurred.emit(f"Guide generation failed: {str(e)}")


class IntegratedAssistantController(AssistantController):
    """Enhanced assistant controller with RAG integration"""
    
    # Class-level global instance reference
    _global_instance = None
    
    def __init__(self, settings_manager: SettingsManager, limited_mode: bool = False):
        super().__init__(settings_manager)
        self.limited_mode = limited_mode
        self.rag_integration = RAGIntegration(settings_manager, limited_mode=limited_mode)
        self._setup_connections()
        self._current_worker = None
        self._current_wiki_message = None  # Store current wiki link message component
        
        # Initialize smart interaction manager (pass None as parent, but pass self as controller reference)
        self.smart_interaction = SmartInteractionManager(parent=None, controller=self)
        self._setup_smart_interaction()
        
        # Register as global instance
        IntegratedAssistantController._global_instance = self
        logger.info(f"ğŸŒ Registered as global assistant controller instance (limited_mode={limited_mode})")
        
        # If in limited mode, display prompt information
        if limited_mode:
            logger.info("ğŸš¨ Running in limited mode: only Wiki search functionality is supported")
        else:
            logger.info("âœ… Running in full mode: supports Wiki search and AI guide functionality")
            # Don't preload AI modules immediately, wait for first window display
            self._ai_preload_scheduled = False
            
            # Schedule AI preload immediately after initialization (with a small delay to avoid blocking)
            from PyQt6.QtCore import QTimer
            QTimer.singleShot(100, self._schedule_ai_preload_on_startup)
        
    def _schedule_ai_preload_on_startup(self):
        """Schedule AI preload on startup if not already scheduled"""
        if not hasattr(self, '_ai_preload_scheduled') or not self._ai_preload_scheduled:
            self._ai_preload_scheduled = True
            logger.info("ğŸš€ Scheduling AI module preload on startup")
            self._schedule_ai_preload()
    
    def _schedule_ai_preload(self):
        """Preload AI modules when idle"""
        # Check if already loading
        if hasattr(self, '_ai_loader') and self._ai_loader:
            logger.info("â­ï¸ AI modules already loading, skipping duplicate request")
            return
            
        # First ensure basic modules are preloaded via preloader
        try:
            from src.game_wiki_tooltip.preloader import ensure_preloaded
            ensure_preloaded(timeout=0.1)  # Quick check, don't block
        except:
            pass
            
        logger.info("ğŸš€ Starting AI module background loading immediately...")
        
        # Create and start loader thread with low priority
        self._ai_loader = AIModuleLoader()
        self._ai_loader.load_completed.connect(self._on_ai_modules_loaded)
        self._ai_loader.start()
        
        logger.info("ğŸ“‹ AI modules loading started in background thread")
        
    def handle_stop_generation(self):
        """Handle stop generation request from UI"""
        logger.info("ğŸ›‘ Received stop generation request from UI")
        
        # Stop current worker thread
        if self._current_worker and self._current_worker.isRunning():
            logger.info("ğŸ›‘ Stopping current worker...")
            self._current_worker.stop()
            
        # Reset UI state
        if self.main_window:
            self.main_window.set_generating_state(False)
            # Hide any status messages when generation is stopped
            self.main_window.chat_view.hide_status()
        
    def _on_ai_modules_loaded(self, success: bool):
        """Callback when AI modules are loaded"""
        if success:
            logger.info("âœ… AI module background loading completed")
            # Record loading success status
            self._ai_modules_ready = True
            
            # Now initialize RAG if we have cached game window
            if hasattr(self.rag_integration, '_last_vector_game_name') and self.rag_integration._last_vector_game_name:
                try:
                    logger.info(f"ğŸ® Initializing RAG for cached game: {self.rag_integration._last_vector_game_name}")
                    self.rag_integration._init_rag_for_game(
                        self.rag_integration._last_vector_game_name,
                        self.rag_integration._llm_config,
                        self.rag_integration._llm_config.api_key if hasattr(self.rag_integration, '_llm_config') else None
                    )
                except Exception as e:
                    logger.warning(f"âš ï¸ Failed to initialize RAG for cached game: {e}")
        else:
            logger.warning("âš ï¸ AI module background loading failed")
            
        # Clean up loader reference
        self._ai_loader = None
        
    def __del__(self):
        """Destructor, clean up global instance reference"""
        if IntegratedAssistantController._global_instance is self:
            IntegratedAssistantController._global_instance = None
            logger.info("ğŸŒ Global assistant controller instance reference cleaned up")
        
    def set_current_game_window(self, game_window_title: str):
        """Override parent class method, set current game window and handle RAG engine initialization"""
        super().set_current_game_window(game_window_title)
        
        # æ’é™¤åº”ç”¨ç¨‹åºè‡ªèº«çš„çª—å£
        title_lower = game_window_title.lower()
        app_window_keywords = [
            'gamewiki assistant',
            'gamewiki',
            'game wiki assistant',
            'game wiki'
        ]
        
        # å¦‚æœæ˜¯åº”ç”¨ç¨‹åºè‡ªèº«çš„çª—å£ï¼Œä¸å¤„ç†
        if any(app_keyword in title_lower for app_keyword in app_window_keywords):
            logger.debug(f"ğŸš« Ignoring self window: '{game_window_title}'")
            return
        
        # Check if RAG engine needs to be initialized or switched
        from src.game_wiki_tooltip.ai.rag_query import map_window_title_to_game_name
        vector_game_name = map_window_title_to_game_name(game_window_title)
        
        if vector_game_name:
            logger.info(f"ğŸ® Detected game window, preparing to initialize RAG engine: {vector_game_name}")
            # Check if game needs to be switched
            if not hasattr(self, '_current_vector_game') or self._current_vector_game != vector_game_name:
                logger.info(f"ğŸ”„ Switch RAG engine: {getattr(self, '_current_vector_game', 'None')} -> {vector_game_name}")
                self._current_vector_game = vector_game_name
                # Asynchronously initialize RAG engine, do not block UI
                self._reinitialize_rag_for_game(vector_game_name)
            else:
                logger.info(f"âœ“ Game not switched, continue using current RAG engine: {vector_game_name}")
        else:
            logger.info(f"âš ï¸ Window '{game_window_title}' is not a supported game")
    
    def _setup_connections(self):
        """Setup signal connections"""
        self.rag_integration.streaming_chunk_ready.connect(
            self._on_streaming_chunk
        )
        self.rag_integration.wiki_result_ready.connect(
            self._on_wiki_result
        )
        self.rag_integration.wiki_link_updated.connect(
            self._on_wiki_link_updated
        )
        self.rag_integration.error_occurred.connect(
            self._on_error
        )
        
    def _setup_smart_interaction(self):
        """Setup smart interaction manager"""
        # Connect interaction mode change signal
        self.smart_interaction.interaction_mode_changed.connect(
            self._on_interaction_mode_changed
        )
        
        # Connect mouse state change signal
        self.smart_interaction.mouse_state_changed.connect(
            self._on_mouse_state_changed
        )
        
        # ç§»é™¤çª—å£çŠ¶æ€å˜åŒ–çš„ä¿¡å·è¿æ¥ - æ”¹ä¸ºçƒ­é”®è§¦å‘æ—¶æŒ‰éœ€æ£€æµ‹
    
    def handle_query(self, query: str, mode: str = "auto"):
        """Override to handle query with RAG integration"""
        # Store search mode
        self._search_mode = mode
        
        # Check if the last message in chat view is already this user query
        # to avoid duplication (since it may have been added in the UI already)
        should_add_message = True
        if self.main_window and self.main_window.chat_view.messages:
            last_message = self.main_window.chat_view.messages[-1]
            if (hasattr(last_message, 'message') and 
                last_message.message.type == MessageType.USER_QUERY and 
                last_message.message.content == query):
                should_add_message = False
        
        # Add user message only if not already added
        if should_add_message:
            self.main_window.chat_view.add_message(
                MessageType.USER_QUERY,
                query
            )
        
        # Check RAG engine initialization status (check the RAGIntegration's status)
        if hasattr(self.rag_integration, '_rag_initializing') and self.rag_integration._rag_initializing:
            # RAG engine is initializing, display waiting status
            from src.game_wiki_tooltip.core.i18n import t
            logger.info(f"ğŸ”„ RAG engine is initializing for game '{self.rag_integration._rag_init_game}', display waiting status")
            self.main_window.chat_view.show_status(t("rag_initializing"))
            
            # Delay processing query, check initialization status periodically
            self._pending_query = query
            self._check_rag_init_status()
            return
        
        # RAG engine is ready, process query normally
        self._process_query_immediately(query)
        
    def _check_rag_init_status(self):
        """Check RAG initialization status periodically"""
        from src.game_wiki_tooltip.core.i18n import t
        
        # Check if initialization is complete (check if _rag_initializing is False)
        if not self.rag_integration._rag_initializing:
            # Initialization completed (either success or failure)
            if self.rag_integration.rag_engine and self.rag_integration._current_rag_game:
                logger.info("âœ… RAG engine initialization completed, start processing query")
            else:
                logger.warning("âš ï¸ RAG engine initialization finished but engine not available")
            
            self.main_window.chat_view.hide_status()
            
            # Process waiting query
            if hasattr(self, '_pending_query'):
                self._process_query_immediately(self._pending_query)
                delattr(self, '_pending_query')
        elif hasattr(self.rag_integration, '_rag_init_error'):
            # Initialization failed
            logger.error(f"âŒ RAG engine initialization failed: {self.rag_integration._rag_init_error}")
            self.main_window.chat_view.hide_status()
            
            # Display error information
            if hasattr(self.rag_integration, '_rag_init_error'):
                error_msg = self.rag_integration._rag_init_error
                logger.error(f"RAG initialization error details: {error_msg}")
                # Send error to chat window
                self.main_window.chat_view.add_message(
                    MessageType.AI_RESPONSE,
                    f"{t('rag_init_failed')}: {error_msg}"
                )
            else:
                # General error information
                self.main_window.chat_view.add_message(
                    MessageType.AI_RESPONSE,
                    t("rag_init_failed")
                )
            
            # Clean up waiting query
            if hasattr(self, '_pending_query'):
                delattr(self, '_pending_query')
        else:
            # Continue waiting, check every 500ms, up to 10 seconds
            if not hasattr(self, '_rag_init_start_time'):
                import time
                self._rag_init_start_time = time.time()
            
            import time
            if time.time() - self._rag_init_start_time > 10:  # Timeout 10 seconds
                logger.warning("RAG initialization timeout")
                self.main_window.chat_view.hide_status()
                
                # Display timeout error
                self.main_window.chat_view.add_message(
                    MessageType.ERROR,
                    f"{t('rag_init_failed')}: Initialization timeout"
                )
                
                # Clean up
                if hasattr(self, '_pending_query'):
                    delattr(self, '_pending_query')
                if hasattr(self, '_rag_init_start_time'):
                    delattr(self, '_rag_init_start_time')
            else:
                # Continue waiting
                QTimer.singleShot(500, self._check_rag_init_status)
            
    def _process_query_immediately(self, query: str):
        """Immediately process query (RAG engine is ready)"""
        # Save query for potential web search
        self._last_user_query = query
        self._last_game_context = getattr(self, 'current_game_window', None)
        
        # Stop any existing worker and reset UI state
        if self._current_worker and self._current_worker.isRunning():
            logger.info("ğŸ›‘ New query started, stop previous generation")
            self._current_worker.stop()
            self._current_worker.wait()
            
            # If there is current streaming message, mark as stopped
            if hasattr(self, '_current_streaming_msg') and self._current_streaming_msg:
                self._current_streaming_msg.mark_as_stopped()
                
            # Reset UI state
            if self.main_window:
                self.main_window.set_generating_state(False)
                logger.info("ğŸ›‘ UI state reset to non-generating state")
            
        # Disconnect all signals from RAG integration to prevent duplicates
        try:
            self.rag_integration.streaming_chunk_ready.disconnect()
            print(f"ğŸ”Œ [SIGNAL-DEBUG] Disconnected previous streaming_chunk_ready signal")
        except:
            print(f"ğŸ”Œ [SIGNAL-DEBUG] No previous streaming_chunk_ready signal connection to disconnect")
            pass  # If no connection, ignore error
            
        # Use recorded game window title (recorded when hotkey is triggered)
        if hasattr(self, 'current_game_window') and self.current_game_window:
            logger.info(f"ğŸ® Using recorded game window: '{self.current_game_window}'")
        else:
            logger.warning("âš ï¸ No recorded game window, possibly abnormal program state")
        
        # Create and start new worker with game context
        self._current_worker = QueryWorker(
            self.rag_integration, 
            query, 
            game_context=self.current_game_window,
            search_mode=getattr(self, '_search_mode', 'auto')
        )
        self._current_worker.intent_detected.connect(self._on_intent_detected)
        self._current_worker.wiki_result.connect(self._on_wiki_result_from_worker)
        self._current_worker.guide_chunk.connect(self._on_guide_chunk)
        self._current_worker.error_occurred.connect(self._on_error)
        
        # Reconnect RAG integration signals to current worker
        self.rag_integration.streaming_chunk_ready.connect(
            self._on_streaming_chunk  # Directly connect to processing method, not worker's signal
        )
        print(f"ğŸ”Œ [SIGNAL-DEBUG] Reconnected streaming_chunk_ready signal to _on_streaming_chunk")
        
        # Add RAG status update timer to display processing progress
        if not hasattr(self, '_rag_status_timer'):
            self._rag_status_timer = QTimer()
            self._rag_status_timer.timeout.connect(self._update_rag_status)
            
        # Start status update timer
        self._rag_status_step = 0
        self._last_status_message = None  # Reset status message cache
        self._rag_status_timer.start(1500)  # Update every 1.5 seconds
        
        # Set generating state before starting worker, ensure user sees stop button
        if self.main_window:
            self.main_window.set_generating_state(True)
            logger.info("ğŸ”„ UI set to generating state (query started)")
        
        self._current_worker.start()
        
    def _on_intent_detected(self, intent: QueryIntent):
        """Handle intent detection result"""
        try:
            # Save rewritten query for potential web search
            if intent.rewritten_query:
                self._last_rewritten_query = intent.rewritten_query
            
            if intent.intent_type == "wiki":
                # Show wiki search transition
                self._current_transition_msg = self.main_window.chat_view.add_message(
                    MessageType.TRANSITION,
                    TransitionMessages.WIKI_SEARCHING
                )
            else:
                # Show guide search transition - Display status message instead of creating streaming message immediately
                self._current_status_widget = self.main_window.chat_view.show_status(
                    TransitionMessages.DB_SEARCHING
                )
                
                # Mark as waiting for RAG output, do not create streaming message immediately
                self._waiting_for_rag_output = True
                self._current_streaming_msg = None
                
        except Exception as e:
            logger.error(f"Intent detection handling error: {e}")
            self._on_error(str(e))
            
    def _setup_streaming_message(self):
        """Setup streaming message for guide responses"""
        print(f"ğŸ¯ [STREAMING-DEBUG] Start setting streaming message component")
        
        # If streaming message component already exists, do not create it again
        if hasattr(self, '_current_streaming_msg') and self._current_streaming_msg:
            logger.info("ğŸ”„ Streaming message component already exists, skip creating")
            print(f"ğŸ”„ [STREAMING-DEBUG] Streaming message component already exists, skip creating")
            return
            
        # Hide possible existing transition message
        if hasattr(self, '_current_transition_msg') and self._current_transition_msg:
            self._current_transition_msg.hide()
            print(f"ğŸ«¥ [STREAMING-DEBUG] Transition message hidden")
            
        # Create streaming message component
        print(f"ğŸ—ï¸ [STREAMING-DEBUG] Call add_streaming_message()")
        try:
            self._current_streaming_msg = self.main_window.chat_view.add_streaming_message()
            logger.info("âœ… Streaming message component created")
            print(f"âœ… [STREAMING-DEBUG] Streaming message component created: {self._current_streaming_msg}")
            print(f"âœ… [STREAMING-DEBUG] Streaming message component type: {type(self._current_streaming_msg)}")
            
            # Connect completion signal
            self._current_streaming_msg.streaming_finished.connect(self._on_streaming_finished)
            print(f"ğŸ”— [STREAMING-DEBUG] Streaming finished signal connected")
            
            # Update UI generating state, associate streaming message component
            if self.main_window:
                self.main_window.set_generating_state(True, self._current_streaming_msg)
                logger.info("ğŸ”„ UI generating state associated with streaming message component")
                print(f"ğŸ”„ [STREAMING-DEBUG] UI generating state associated with streaming message component")
                
        except Exception as e:
            print(f"âŒ [STREAMING-DEBUG] Create streaming message component failed: {e}")
            logger.error(f"Create streaming message component failed: {e}")
            # Ensure component is None, avoid subsequent operation exceptions
            self._current_streaming_msg = None
        
    def _on_wiki_result_from_worker(self, url: str, title: str):
        """Handle wiki result from worker"""
        try:
            # Wiki query completed, reset generating state
            if self.main_window:
                self.main_window.set_generating_state(False)
                logger.info("ğŸ”— Wiki query completed, UI state reset to non-generating state")
            
            if url:
                # Update transition message
                if hasattr(self, '_current_transition_msg'):
                    self._current_transition_msg.update_content(TransitionMessages.WIKI_FOUND)
                
                # Add wiki link message (initial display search URL)
                self._current_wiki_message = self.main_window.chat_view.add_message(
                    MessageType.WIKI_LINK,
                    title,
                    {"url": url}
                )
                
                # Show wiki page in the unified window (triggers JavaScript search for real URL)
                self.main_window.show_wiki_page(url, title)
            else:
                if hasattr(self, '_current_transition_msg'):
                    self._current_transition_msg.update_content(TransitionMessages.ERROR_NOT_FOUND)
                    
        except Exception as e:
            logger.error(f"Wiki result handling error: {e}")
            self._on_error(str(e))
            
    def _on_wiki_link_updated(self, real_url: str, real_title: str):
        """Handle wiki link update signal"""
        try:
            if self._current_wiki_message:
                logger.info(f"ğŸ”— Update wiki link in chat window: {real_title} -> {real_url}")
                
                # Update message content and metadata
                self._current_wiki_message.message.content = real_title
                self._current_wiki_message.message.metadata["url"] = real_url
                
                # Reset content to refresh display - fix: use real title instead of old content
                html_content = (
                    f'[LINK] <a href="{real_url}" style="color: #4096ff;">{real_url}</a><br/>'
                    f'<span style="color: #666; margin-left: 20px;">{real_title}</span>'
                )
                self._current_wiki_message.content_label.setText(html_content)
                self._current_wiki_message.content_label.setTextFormat(Qt.TextFormat.RichText)
                
                # Adjust component size to fit new content
                self._current_wiki_message.content_label.adjustSize()
                self._current_wiki_message.adjustSize()
                
                # Force redraw
                self._current_wiki_message.update()
                
                logger.info(f"âœ… Wiki link in chat window updated to real URL and title")
                
                # Only clear reference when title contains meaningful content (avoid premature clearing causing subsequent updates)
                # Check if title is a temporary loading state
                temporary_titles = ["è¯·ç¨å€™â€¦", "Loading...", "Redirecting...", ""]
                if real_title and real_title not in temporary_titles:
                    # Delay clearing reference, allow possible subsequent updates
                    QTimer.singleShot(2000, lambda: setattr(self, '_current_wiki_message', None))
                    logger.info(f"ğŸ“‹ Delay clearing wiki message reference, title: '{real_title}'")
                else:
                    logger.info(f"ğŸ“‹ Keep wiki message reference, waiting for more complete title (current: '{real_title}')")
                    
            else:
                logger.warning("âš ï¸ No wiki message component found to update")
                
        except Exception as e:
            logger.error(f"âŒ Update wiki link failed: {e}")
            
    def _on_streaming_chunk(self, chunk: str):
        # If waiting for RAG output and this is the first content chunk, create streaming message component
        if getattr(self, '_waiting_for_rag_output', False) and chunk.strip():
            logger.info("ğŸ”„ Received first RAG output chunk, create streaming message component")
            print(f"ğŸ”„ [STREAMING-DEBUG] Create streaming message component, content chunk: '{chunk.strip()[:50]}...'")
            
            # Hide status message
            if hasattr(self, '_current_status_widget') and self._current_status_widget:
                self.main_window.chat_view.hide_status()
                self._current_status_widget = None
                print(f"âœ… [STREAMING-DEBUG] Status message hidden")
            
            # Create streaming message component
            self._setup_streaming_message()
            self._waiting_for_rag_output = False
            print(f"âœ… [STREAMING-DEBUG] _waiting_for_rag_output set to False")
        
        # If there is streaming message component, add content chunk
        if hasattr(self, '_current_streaming_msg') and self._current_streaming_msg:
            print(f"ğŸ“ [STREAMING-DEBUG] Add content chunk to streaming message component")
            self._current_streaming_msg.append_chunk(chunk)
        else:
            print(f"âš ï¸ [STREAMING-DEBUG] No streaming message component, cannot add content chunk")
            # Try to create streaming message component immediately (fallback mechanism)
            if not getattr(self, '_waiting_for_rag_output', False):
                print(f"ğŸš¨ [STREAMING-DEBUG] Try to create streaming message component immediately (fallback mechanism)")
                self._setup_streaming_message()
                if hasattr(self, '_current_streaming_msg') and self._current_streaming_msg:
                    self._current_streaming_msg.append_chunk(chunk)
    
    def _update_rag_status(self):
        """Update RAG processing status message"""
        # If streaming output has started or not in waiting state, stop status update
        if (not getattr(self, '_waiting_for_rag_output', False) or 
            (hasattr(self, '_current_streaming_msg') and self._current_streaming_msg)):
            if hasattr(self, '_rag_status_timer'):
                self._rag_status_timer.stop()
            return
            
        # If there is no status component, do not update
        if not (hasattr(self, '_current_status_widget') and self._current_status_widget):
            return
            
        # In retrieval phase, keep displaying retrieval message, do not switch frequently
        # Only switch to AI processing message after long waiting
        if self._rag_status_step < 2:  # First 4.5 seconds (3 times * 1.5 seconds) keep displaying retrieval message
            current_message = TransitionMessages.DB_SEARCHING  # ğŸ“š Retrieving related knowledge base...
        else:
            current_message = TransitionMessages.AI_SUMMARIZING  # ğŸ“ AI summarizing in progress...
            
        # Only update when message actually changes, avoid setting same message repeatedly
        if not hasattr(self, '_last_status_message') or self._last_status_message != current_message:
            self.main_window.chat_view.update_status(current_message)
            self._last_status_message = current_message
            logger.info(f"ğŸ”„ RAG status updated: {current_message}")
        
        self._rag_status_step += 1
    
    def _on_guide_chunk(self, chunk: str):
        """Handle guide chunk from worker"""
        if hasattr(self, '_current_streaming_msg'):
            self._current_streaming_msg.append_chunk(chunk)
            
    def _on_streaming_finished(self):
        """Handle streaming output completed"""
        logger.info("âœ… Streaming output completed")
        
        # Stop status update timer
        if hasattr(self, '_rag_status_timer'):
            self._rag_status_timer.stop()
            
        # Reset waiting state and status cache
        self._waiting_for_rag_output = False
        self._last_status_message = None
        
        # Notify streaming message component to quickly display remaining content
        if hasattr(self, '_current_streaming_msg') and self._current_streaming_msg:
            self._current_streaming_msg.mark_as_completed()

        # Reset UI state
        if self.main_window:
            self.main_window.set_generating_state(False)
            logger.info("âœ… UI state reset to non-generating state")
        
    def _on_error(self, error_msg: str):
        """Handle error"""
        # Stop status update timer
        if hasattr(self, '_rag_status_timer'):
            self._rag_status_timer.stop()
            
        # Reset waiting state and status cache
        self._waiting_for_rag_output = False
        self._last_status_message = None
        
        # Reset UI generating state
        if self.main_window:
            self.main_window.set_generating_state(False)
            logger.info("âŒ UI state reset to non-generating state when error occurred")
        
        # Hide status message
        if hasattr(self, '_current_status_widget') and self._current_status_widget:
            self.main_window.chat_view.hide_status()
            self._current_status_widget = None
            
        self.main_window.chat_view.add_message(
            MessageType.AI_RESPONSE,
            f"âŒ {error_msg}"
        )
        
    def _on_wiki_result(self, url: str, title: str):
        """Handle wiki search result from RAG integration"""
        try:
            if url:
                # Update transition message
                if hasattr(self, '_current_transition_msg'):
                    self._current_transition_msg.update_content(TransitionMessages.WIKI_FOUND)
                
                # Add wiki link message (initial display search URL)
                self._current_wiki_message = self.main_window.chat_view.add_message(
                    MessageType.WIKI_LINK,
                    title,
                    {"url": url}
                )
                
                # Show wiki page in the unified window (triggers JavaScript search for real URL)
                self.main_window.show_wiki_page(url, title)
            else:
                if hasattr(self, '_current_transition_msg'):
                    self._current_transition_msg.update_content(TransitionMessages.ERROR_NOT_FOUND)
                    
        except Exception as e:
            logger.error(f"Wiki result handling error: {e}")
            self._on_error(str(e))
            
    def _reinitialize_rag_for_game(self, vector_game_name: str, retry_count: int = 0):
        """Reinitialize RAG engine for specific vector library (asynchronous, not blocking UI)"""
        try:
            logger.info(f"ğŸš€ Start reinitializing RAG engine for vector library '{vector_game_name}' (asynchronous mode)")
            
            # Check if RAG is already initializing or initialized for this game
            if self.rag_integration._rag_initializing:
                logger.info(f"âš ï¸ RAG already initializing for game '{self.rag_integration._rag_init_game}', skipping")
                return
                
            if self.rag_integration._current_rag_game == vector_game_name and self.rag_integration.rag_engine:
                logger.info(f"âœ“ RAG already initialized for game '{vector_game_name}', no need to reinitialize")
                return
            
            # Check if we should stop retrying
            MAX_RETRIES = 3
            if retry_count >= MAX_RETRIES:
                logger.info(f"â¹ï¸ Max retries ({MAX_RETRIES}) reached for RAG initialization, stopping")
                return
            
            # Ensure AI modules are loaded before attempting RAG initialization
            if not self.rag_integration._ensure_ai_components_loaded():
                # Check if this is a permanent failure (missing API key) or temporary (loading)
                settings = self.settings_manager.get()
                api_settings = settings.get('api', {})
                gemini_api_key = api_settings.get('gemini_api_key', '') or os.getenv('GEMINI_API_KEY') or os.getenv('GOOGLE_API_KEY')
                
                if not gemini_api_key:
                    # Permanent failure - no API key configured
                    logger.info("â¹ï¸ No API key configured, RAG initialization disabled")
                    return
                else:
                    # Temporary failure - modules still loading
                    if retry_count == 0:
                        logger.info(f"AI components loading, deferring RAG initialization...")
                    else:
                        logger.info(f"AI components not ready, retrying RAG initialization (attempt {retry_count + 1}/{MAX_RETRIES})")
                    # Schedule another attempt with exponential backoff
                    delay = min(1000 * (2 ** retry_count), 10000)  # 1s, 2s, 4s, 8s, max 10s
                    QTimer.singleShot(delay, lambda: self._reinitialize_rag_for_game(vector_game_name, retry_count + 1))
                    return
            
            # Get API settings
            settings = self.settings_manager.get()
            api_settings = settings.get('api', {})
            gemini_api_key = api_settings.get('gemini_api_key', '')
            # No longer need separate Jina API key, use Gemini API key for embeddings
            
            # Check environment variables
            if not gemini_api_key:
                gemini_api_key = os.getenv('GEMINI_API_KEY') or os.getenv('GOOGLE_API_KEY')
            # Gemini API key is used for both LLM and embeddings
            
            # Check if API key is available
            has_api_key = bool(gemini_api_key)
            
            if has_api_key:
                llm_config = LLMSettings(
                    api_key=gemini_api_key,
                    model='gemini-2.5-flash-lite'
                )
                
                # Update stored LLM configuration
                self._llm_config = llm_config
                
                # Asynchronously initialize RAG engine (do not wait for completion)
                self.rag_integration._init_rag_for_game(vector_game_name, llm_config, gemini_api_key, wait_for_init=False)
                logger.info(f"ğŸ”„ RAG engine initialization started (asynchronous): {vector_game_name}")
            else:
                logger.warning(f"âš ï¸ API key is missing, cannot initialize RAG engine (Gemini: {bool(gemini_api_key)})")
                
        except Exception as e:
            logger.error(f"RAG engine reinitialization failed: {e}")
        
    def reset_rag_retry_state(self):
        """Reset RAG retry state, useful when settings change or new API keys are added."""
        # This method can be called when settings are updated to allow retrying RAG initialization
        # The retry counter is passed as a parameter, so no persistent state to reset
        logger.info("RAG retry state reset - will retry initialization on next game window change")
        
        # If there's a current game, try to reinitialize
        if hasattr(self, 'current_game_window') and self.current_game_window:
            # Try to get vector name for current game
            settings = self.settings_manager.get()
            current_language = settings.get('language', 'zh')
            if current_language == 'en':
                games_config = self._games_config_en
            else:
                games_config = self._games_config_zh
            
            vector_game_name = self._get_vector_library_name(self.current_game_window, games_config)
            if vector_game_name:
                # Reset retry count to 0 for new attempt
                self._reinitialize_rag_for_game(vector_game_name, retry_count=0)
        
    def handle_wiki_page_found(self, url: str, title: str):
        """Override parent class method: handle WikiView signal when real wiki page is found"""
        logger.info(f"ğŸ”— IntegratedAssistantController received WikiView signal: {title} -> {url}")
        
        # Filter out obvious temporary state titles, only process meaningful updates
        if title and title not in ["è¯·ç¨å€™â€¦", "Loading...", "Redirecting...", ""]:
            logger.info(f"âœ… Accept wiki page update: {title}")
            # Directly call RAG integration method to handle wiki page discovery
            self.rag_integration.on_wiki_found(url, title)
        else:
            logger.info(f"â³ Skip temporary state wiki page update: {title}")
            # For temporary state, still call, but do not trigger final update in chat window
    
    # Smart interaction manager signal handling methods
    def _on_interaction_mode_changed(self, mode: InteractionMode):
        """Handle interaction mode changes"""
        logger.info(f"ğŸ® Interaction mode changed: {mode.value}")
        
        # Adjust window mouse passthrough state based on interaction mode
        if hasattr(self, 'main_window') and self.main_window:
            should_passthrough = self.smart_interaction.should_enable_mouse_passthrough()
            logger.info(f"ğŸ”§ Should enable passthrough: {should_passthrough}")
            
            # Get current mouse state for debugging
            mouse_state = self.smart_interaction.get_mouse_state()
            if mouse_state:
                logger.info(f"ğŸ–±ï¸ Current mouse state: visible={mouse_state.is_visible}, suppressed={mouse_state.is_suppressed}")
            
            self.smart_interaction.apply_mouse_passthrough(self.main_window, should_passthrough)
            
            # Show status message for different modes
            if mode == InteractionMode.GAME_HIDDEN:
                logger.info("ğŸ® Game mouse hidden mode: checking if passthrough needed")
            elif mode == InteractionMode.GAME_VISIBLE:
                logger.info("ğŸ® Game mouse visible mode: normal interaction")
            else:
                logger.info("ğŸ–¥ï¸ Normal mode: normal interaction")
        
    def _on_mouse_state_changed(self, mouse_state):
        """Handle mouse state changes"""
        logger.debug(f"ğŸ–±ï¸ Mouse state changed: visible={mouse_state.is_visible}, position={mouse_state.position}")
    
    def handle_smart_hotkey(self, current_visible: bool) -> bool:
        """
        Handle hotkey events using smart interaction manager
        
        Args:
            current_visible: Whether the chat window (main_window) is visible
            
        Returns:
            Whether the hotkey event was handled
        """
        # Debug: Log smart hotkey processing start
        logger.info(f"ğŸ¯ [DEBUG] Smart hotkey processing started")
        
        # æ£€æµ‹å½“å‰æ¸¸æˆçª—å£ä½†å…ˆä¸è®¾ç½®ï¼Œé¿å…é˜»å¡çª—å£æ˜¾ç¤º
        current_game_window = self.smart_interaction.get_current_game_window()
        logger.info(f"ğŸ” [DEBUG] Detected current game window: '{current_game_window}'")
        
        # å¼ºåˆ¶æ›´æ–°äº¤äº’æ¨¡å¼ï¼Œç¡®ä¿æ­£ç¡®è¯†åˆ«å½“å‰æ¸¸æˆçŠ¶æ€
        mouse_state = self.smart_interaction.get_mouse_state()
        window_state = self.smart_interaction.get_window_state()
        if mouse_state and window_state:
            new_mode = self.smart_interaction._calculate_interaction_mode(mouse_state, window_state)
            if new_mode != self.smart_interaction.current_mode:
                old_mode = self.smart_interaction.current_mode
                self.smart_interaction.current_mode = new_mode
                logger.info(f"ğŸ® Interaction mode updated for hotkey: {old_mode.value} -> {new_mode.value}")
        
        # åªæ£€æŸ¥èŠå¤©çª—å£çš„å¯è§æ€§ï¼Œè€Œä¸æ˜¯æ‰€æœ‰çª—å£
        chat_visible = (self.main_window and self.main_window.isVisible())
        action = self.smart_interaction.handle_hotkey_press(chat_visible)
        logger.info(f"ğŸ”¥ Smart hotkey handling result: {action}")
        
        if action == 'show_chat':
            # å…ˆæ˜¾ç¤ºèŠå¤©çª—å£
            self.show_chat_window()
            logger.info("ğŸ’¬ Show chat window requested - executed before game window setting")
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦è‡ªåŠ¨å¼€å¯è¯­éŸ³è¾“å…¥
            if (self.settings_manager.settings.auto_voice_on_hotkey and 
                self.main_window and 
                self.main_window.current_state in [WindowState.CHAT_ONLY, WindowState.FULL_CONTENT]):
                # å»¶è¿Ÿå¯åŠ¨è¯­éŸ³è¾“å…¥ï¼Œç¡®ä¿çª—å£å®Œå…¨æ˜¾ç¤ºä¸”è¾“å…¥æ¡†è·å¾—ç„¦ç‚¹
                from PyQt6.QtCore import QTimer
                QTimer.singleShot(150, lambda: self._auto_start_voice_input())
                logger.info("ğŸ¤ Auto voice input scheduled after hotkey trigger")
            
            # ç„¶åå¼‚æ­¥è®¾ç½®æ¸¸æˆçª—å£ï¼ˆé¿å…é˜»å¡UIï¼‰
            if current_game_window:
                logger.info(f"ğŸ® Setting current game window after chat display: '{current_game_window}'")
                # ä½¿ç”¨QTimerå¼‚æ­¥è®¾ç½®æ¸¸æˆçª—å£ï¼Œé¿å…é˜»å¡UI
                from PyQt6.QtCore import QTimer
                QTimer.singleShot(50, lambda: self._delayed_set_game_window(current_game_window))
                
            return True
        elif action == 'hide_chat':
            self.hide_chat_window()
            # Clear the flag after handling to allow future updates
            self._game_window_already_set = False
            return True
        elif action == 'show_mouse':
            self.show_mouse_for_interaction()
            # Clear the flag after handling to allow future updates
            self._game_window_already_set = False
            return True
        elif action == 'ignore':
            logger.info("ğŸ® Ignoring hotkey event")
            # Clear the flag after handling to allow future updates
            self._game_window_already_set = False
            return True
        
        # Clear the flag if no action was taken
        self._game_window_already_set = False
        return False
    
    def _delayed_set_game_window(self, game_window_title: str):
        """å»¶è¿Ÿè®¾ç½®æ¸¸æˆçª—å£ï¼Œé¿å…é˜»å¡UI"""
        try:
            logger.info(f"ğŸ® [DEBUG] About to set current game window (delayed): '{game_window_title}'")
            logger.info(f"ğŸ“‹ [DEBUG] Main window exists: {self.main_window is not None}")
            if self.main_window:
                logger.info(f"ğŸ“‹ [DEBUG] Main window task buttons count before: {len(getattr(self.main_window, 'game_task_buttons', {}))}")
            
            # è®¾ç½®æ¸¸æˆçª—å£å¹¶ç¡®ä¿task flowæŒ‰é’®æ­£ç¡®æ˜¾ç¤º
            self.set_current_game_window(game_window_title)
            
            # Debug: Log after setting game window
            if self.main_window:
                logger.info(f"ğŸ“‹ [DEBUG] Main window task buttons count after: {len(getattr(self.main_window, 'game_task_buttons', {}))}")
                # Log visibility of each button
                for game_name, button in getattr(self.main_window, 'game_task_buttons', {}).items():
                    if button:
                        is_visible = button.isVisible()
                        logger.info(f"    ğŸ“‹ [DEBUG] {game_name} task button visible: {is_visible}")
            
            # æ ‡è®°æ¸¸æˆçª—å£å·²ç»è®¾ç½®
            self._game_window_already_set = True
            logger.info(f"ğŸ [DEBUG] Game window already set flag: True (delayed)")
            
        except Exception as e:
            logger.error(f"Error in delayed game window setting: {e}")
            import traceback
            traceback.print_exc()
    
    def _auto_start_voice_input(self):
        """Auto start voice input after hotkey trigger"""
        try:
            if self.main_window and hasattr(self.main_window, 'toggle_voice_input'):
                logger.info("ğŸ¤ Auto-starting voice input")
                self.main_window.toggle_voice_input()
            else:
                logger.warning("âš ï¸ Cannot auto-start voice input: main_window or toggle_voice_input not available")
        except Exception as e:
            logger.error(f"Error auto-starting voice input: {e}")
            import traceback
            traceback.print_exc()
    
    def show_chat_window(self):
        """æ˜¾ç¤ºèŠå¤©çª—å£ï¼Œéšè—æ‚¬æµ®çª—"""
        logger.info("ğŸ’¬ Show chat window requested")
        
        # æ ‡è®°çª—å£åˆšåˆšæ˜¾ç¤ºï¼Œæ¿€æ´»ä¿æŠ¤æœŸ
        if hasattr(self, 'smart_interaction') and self.smart_interaction:
            self.smart_interaction.mark_window_just_shown()

        # å…ˆå†³å®šæ˜¾ç¤ºå“ªç§å½¢æ€
        if not self.main_window.has_switched_state:
            # å¦‚æœç”¨æˆ·æ²¡æœ‰åˆ‡æ¢è¿‡å½¢æ€ï¼Œæ˜¾ç¤ºCHAT_ONLYå½¢æ€
            logger.info("ğŸ¯ Switching to CHAT_ONLY mode (no state switch yet)")
            self.main_window.switch_to_chat_only()
            self.main_window.set_precreating_mode(False)

        # ç„¶åæ¢å¤å¯¹åº”çŠ¶æ€çš„å‡ ä½•ä½ç½®
        self.main_window.restore_geometry()

        # æœ€åæ˜¾ç¤ºçª—å£
        self.main_window.show()
        self.main_window.raise_()
        self.main_window.activateWindow()
        
        # å…³é”®ï¼šç¡®ä¿çª—å£æ˜¾ç¤ºæ—¶æ˜¯å¯äº¤äº’çš„
        # ä½¿ç”¨å°å»¶è¿Ÿç¡®ä¿çª—å£å®Œå…¨æ˜¾ç¤ºåå†è®¾ç½®
        from PyQt6.QtCore import QTimer
        QTimer.singleShot(50, self._ensure_window_interactable)

        # è®¾ç½®è¾“å…¥æ¡†ç„¦ç‚¹
        QTimer.singleShot(100, self.main_window._set_chat_input_focus)

        logger.info("ğŸ’¬ Chat window shown")
    
    def _ensure_window_interactable(self):
        """ç¡®ä¿çª—å£åœ¨æ˜¾ç¤ºåæ˜¯å¯äº¤äº’çš„"""
        if self.main_window and self.main_window.isVisible():
            logger.info("ğŸ”§ Ensuring window is interactable after showing")
            # å¼ºåˆ¶è®¾ç½®çª—å£ä¸ºéç©¿é€çŠ¶æ€
            self.smart_interaction.apply_mouse_passthrough(self.main_window, False)
    
    def hide_chat_window(self):
        """éšè—èŠå¤©çª—å£ï¼Œæ ¹æ®ç”¨æˆ·è®¾ç½®å†³å®šæ˜¯å¦æ˜¾ç¤ºæ‚¬æµ®çª—"""
        logger.info("ğŸ’¬ Hide chat window requested")
        
        # æ¸…é™¤ç”¨æˆ·ä¸»åŠ¨æ˜¾ç¤ºé¼ æ ‡çš„æ ‡è®°
        if hasattr(self, 'smart_interaction') and self.smart_interaction:
            self.smart_interaction.set_user_requested_mouse_visible(False)
        
        # éšè—èŠå¤©çª—å£
        if self.main_window:
            self.main_window.hide()
            logger.info("ğŸ’¬ Chat window hidden")
    
    def show_mouse_for_interaction(self):
        """æ˜¾ç¤ºé¼ æ ‡ä»¥ä¾¿ä¸èŠå¤©çª—å£äº’åŠ¨"""
        logger.info("ğŸ–±ï¸ Show mouse for interaction requested")
        try:
            # 1. å…ˆæ¿€æ´»èŠå¤©çª—å£ï¼Œç¡®ä¿å®ƒè·å¾—ç„¦ç‚¹
            if self.main_window and self.main_window.isVisible():
                logger.info("ğŸ¯ Activating chat window first")
                self.main_window.activateWindow()
                self.main_window.raise_()
            
            # 2. åœ¨æ˜¾ç¤ºé¼ æ ‡ä¹‹å‰ï¼Œå…ˆè®¾ç½®é¼ æ ‡ä½ç½®åˆ°çª—å£ä¸­å¿ƒ
            if self.main_window and self.main_window.isVisible():
                import ctypes
                
                # ä½¿ç”¨mapToGlobalè·å–çª—å£ä¸­å¿ƒçš„å±å¹•åæ ‡
                center_point = self.main_window.mapToGlobal(
                    QPoint(self.main_window.width() // 2, self.main_window.height() // 2)
                )
                center_x = center_point.x()
                center_y = center_point.y()
                
                # ä½¿ç”¨Windows APIç§»åŠ¨é¼ æ ‡åˆ°çª—å£ä¸­å¿ƒï¼ˆåœ¨æ˜¾ç¤ºä¹‹å‰ï¼‰
                ctypes.windll.user32.SetCursorPos(center_x, center_y)
                logger.info(f"ğŸ¯ Pre-positioned cursor to window center: ({center_x}, {center_y})")
            
            # 3. æ ‡è®°ç”¨æˆ·ä¸»åŠ¨è¯·æ±‚æ˜¾ç¤ºé¼ æ ‡
            if hasattr(self, 'smart_interaction') and self.smart_interaction:
                self.smart_interaction.set_user_requested_mouse_visible(True)
            
            # 4. æœ€åè°ƒç”¨Windows APIæ˜¾ç¤ºé¼ æ ‡
            from src.game_wiki_tooltip.core.utils import show_cursor_until_visible
            show_cursor_until_visible()
            logger.info("ğŸ–±ï¸ Mouse cursor shown (after positioning)")
            
            # 5. å¾®ç§»é¼ æ ‡ä»¥å¼ºåˆ¶Windowsç«‹å³æ¸²æŸ“ï¼ˆç§»åŠ¨1åƒç´ å†ç§»å›ï¼‰
            if self.main_window and self.main_window.isVisible():
                import ctypes
                # é‡æ–°è·å–åæ ‡ä»¥é˜²çª—å£ç§»åŠ¨
                center_point = self.main_window.mapToGlobal(
                    QPoint(self.main_window.width() // 2, self.main_window.height() // 2)
                )
                center_x = center_point.x()
                center_y = center_point.y()
                
                # å¾®ç§»åŠ¨ï¼šå³ç§»1åƒç´ å†ç§»å›ï¼Œè§¦å‘é¼ æ ‡æ¸²æŸ“
                ctypes.windll.user32.SetCursorPos(center_x + 1, center_y)
                ctypes.windll.user32.SetCursorPos(center_x, center_y)
                logger.info("ğŸ¯ Micro-moved cursor to ensure rendering")
            
            # å»¶è¿Ÿä¸€ç‚¹æ—¶é—´è®©é¼ æ ‡çŠ¶æ€æ›´æ–°ï¼Œç„¶åå¼ºåˆ¶æ›´æ–°äº¤äº’æ¨¡å¼
            # è¿™ä¼šé‡æ–°è¯„ä¼°çª—å£çš„é¼ æ ‡ç©¿é€çŠ¶æ€
            from PyQt6.QtCore import QTimer
            QTimer.singleShot(100, self._update_window_after_mouse_shown)
            
        except Exception as e:
            logger.error(f"Failed to show mouse cursor: {e}")
    
    def _update_window_after_mouse_shown(self):
        """åœ¨é¼ æ ‡æ˜¾ç¤ºåæ›´æ–°çª—å£çŠ¶æ€"""
        logger.info("ğŸ”„ Updating window state after mouse shown")
        
        # å¼ºåˆ¶æ›´æ–°äº¤äº’æ¨¡å¼ï¼Œè¿™ä¼šè§¦å‘çª—å£ç©¿é€çŠ¶æ€çš„é‡æ–°è¯„ä¼°
        if hasattr(self, 'smart_interaction') and self.smart_interaction:
            # å…ˆæ£€æŸ¥å½“å‰çš„ç©¿é€çŠ¶æ€
            current_passthrough = self.smart_interaction.should_enable_mouse_passthrough()
            logger.info(f"ğŸ” Current passthrough state check: {current_passthrough}")
            
            # å¼ºåˆ¶æ›´æ–°äº¤äº’æ¨¡å¼
            self.smart_interaction.force_update_interaction_mode()
            
            # å†æ¬¡æ£€æŸ¥æ›´æ–°åçš„ç©¿é€çŠ¶æ€
            new_passthrough = self.smart_interaction.should_enable_mouse_passthrough()
            logger.info(f"ğŸ” New passthrough state after update: {new_passthrough}")