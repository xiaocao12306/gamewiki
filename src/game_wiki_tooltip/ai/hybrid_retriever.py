"""
æ··åˆæœç´¢æ£€ç´¢å™¨æ¨¡å—
==================

åŠŸèƒ½ï¼š
1. æ•´åˆå‘é‡æœç´¢å’ŒBM25æœç´¢
2. å®ç°å¤šç§åˆ†æ•°èåˆç®—æ³•
3. æä¾›ç»Ÿä¸€çš„æœç´¢æ¥å£
4. æ”¯æŒç»Ÿä¸€æŸ¥è¯¢å¤„ç†ï¼ˆç¿»è¯‘+é‡å†™+æ„å›¾åˆ†æï¼‰
5. æ€§èƒ½ä¼˜åŒ–ï¼šä¸€æ¬¡LLMè°ƒç”¨å®Œæˆå¤šé¡¹ä»»åŠ¡
"""

import numpy as np
import logging
from typing import List, Dict, Any, Optional, Tuple
from sklearn.preprocessing import MinMaxScaler
from pathlib import Path
from .enhanced_bm25_indexer import EnhancedBM25Indexer
from .unified_query_processor import process_query_unified, UnifiedQueryResult
from ..config import LLMConfig

logger = logging.getLogger(__name__)


class VectorRetrieverAdapter:
    """å‘é‡æ£€ç´¢å™¨é€‚é…å™¨ï¼Œç”¨äºåŒ…è£…ç°æœ‰çš„å‘é‡æœç´¢åŠŸèƒ½"""
    
    def __init__(self, rag_query_instance):
        """
        åˆå§‹åŒ–é€‚é…å™¨
        
        Args:
            rag_query_instance: EnhancedRagQueryå®ä¾‹
        """
        self.rag_query = rag_query_instance
        
    def search(self, query: str, top_k: int = 10) -> List[Dict[str, Any]]:
        """
        æ‰§è¡Œå‘é‡æœç´¢
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            top_k: è¿”å›ç»“æœæ•°é‡
            
        Returns:
            æœç´¢ç»“æœåˆ—è¡¨
        """
        if self.rag_query.config and self.rag_query.config["vector_store_type"] == "faiss":
            return self.rag_query._search_faiss(query, top_k)
        else:
            return self.rag_query._search_qdrant(query, top_k)


class HybridSearchRetriever:
    """æ··åˆæœç´¢æ£€ç´¢å™¨"""
    
    def __init__(self, 
                 vector_retriever: VectorRetrieverAdapter,
                 bm25_index_path: str,
                 fusion_method: str = "rrf",
                 vector_weight: float = 0.6,
                 bm25_weight: float = 0.4,
                 rrf_k: int = 60,
                 llm_config: Optional[LLMConfig] = None,
                 enable_unified_processing: bool = True,
                 enable_query_rewrite: bool = True,
                 enable_query_translation: bool = True):
        """
        åˆå§‹åŒ–æ··åˆæœç´¢æ£€ç´¢å™¨
        
        Args:
            vector_retriever: å‘é‡æ£€ç´¢å™¨é€‚é…å™¨
            bm25_index_path: BM25ç´¢å¼•è·¯å¾„
            fusion_method: èåˆæ–¹æ³• ("rrf", "weighted", "normalized")
            vector_weight: å‘é‡æœç´¢æƒé‡
            bm25_weight: BM25æœç´¢æƒé‡
            rrf_k: RRFç®—æ³•çš„kå‚æ•°
            llm_config: LLMé…ç½®
            enable_unified_processing: æ˜¯å¦å¯ç”¨ç»Ÿä¸€æŸ¥è¯¢å¤„ç†ï¼ˆæ¨èï¼‰
            enable_query_rewrite: æ˜¯å¦å¯ç”¨æŸ¥è¯¢é‡å†™ï¼ˆä»…åœ¨ç»Ÿä¸€å¤„ç†ç¦ç”¨æ—¶ç”Ÿæ•ˆï¼‰
            enable_query_translation: æ˜¯å¦å¯ç”¨æŸ¥è¯¢ç¿»è¯‘ï¼ˆä»…åœ¨ç»Ÿä¸€å¤„ç†ç¦ç”¨æ—¶ç”Ÿæ•ˆï¼‰
        """
        self.vector_retriever = vector_retriever
        self.fusion_method = fusion_method
        self.vector_weight = vector_weight
        self.bm25_weight = bm25_weight
        self.rrf_k = rrf_k
        self.llm_config = llm_config or LLMConfig()
        
        # æ€§èƒ½ä¼˜åŒ–ï¼šç»Ÿä¸€å¤„ç†vsåˆ†ç¦»å¤„ç†
        self.enable_unified_processing = enable_unified_processing
        self.enable_query_rewrite = enable_query_rewrite if not enable_unified_processing else False
        self.enable_query_translation = enable_query_translation if not enable_unified_processing else False
        
        # åˆå§‹åŒ–å¢å¼ºBM25ç´¢å¼•å™¨
        self.bm25_indexer = None
        bm25_path = Path(bm25_index_path)
        if bm25_path.exists():
            try:
                self.bm25_indexer = EnhancedBM25Indexer()
                self.bm25_indexer.load_index(str(bm25_path))
                logger.info(f"å¢å¼ºBM25ç´¢å¼•åŠ è½½æˆåŠŸ: {bm25_index_path}")
            except Exception as e:
                logger.error(f"å¢å¼ºBM25ç´¢å¼•åŠ è½½å¤±è´¥: {e}")
                self.bm25_indexer = None
        else:
            logger.warning(f"å¢å¼ºBM25ç´¢å¼•æ–‡ä»¶ä¸å­˜åœ¨: {bm25_index_path}")
            logger.info("å°†æŸ¥æ‰¾legacy BM25ç´¢å¼•æ–‡ä»¶...")
            # å°è¯•æŸ¥æ‰¾æ—§çš„BM25ç´¢å¼•æ–‡ä»¶
            legacy_bm25_path = bm25_path.parent / "bm25_index.pkl"
            if legacy_bm25_path.exists():
                logger.warning(f"æ‰¾åˆ°æ—§BM25ç´¢å¼•ï¼Œå»ºè®®é‡æ–°æ„å»ºå¢å¼ºç´¢å¼•: {legacy_bm25_path}")
                # å¯ä»¥é€‰æ‹©æ€§åœ°åŠ è½½æ—§ç´¢å¼•ä½œä¸ºé™çº§æ–¹æ¡ˆ
                # ä½†è¿™é‡Œæˆ‘ä»¬é€‰æ‹©ä¸åŠ è½½ï¼Œä»¥ä¿ƒä½¿ç”¨æˆ·ä½¿ç”¨æ–°çš„å¢å¼ºç´¢å¼•
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.unified_processing_stats = {
            "total_queries": 0,
            "unified_successful": 0,
            "unified_failed": 0,
            "cache_hits": 0,
            "average_processing_time": 0.0
        }
        
        # é™çº§å¤„ç†çš„ç»Ÿè®¡ï¼ˆä»…åœ¨ç»Ÿä¸€å¤„ç†ç¦ç”¨æ—¶ä½¿ç”¨ï¼‰
        self.query_rewrite_stats = {
            "total_queries": 0,
            "rewritten_queries": 0,
            "cache_hits": 0
        }
        
        self.query_translation_stats = {
            "total_queries": 0,
            "translated_queries": 0
        }
    
    def search(self, query: str, top_k: int = 5) -> Dict[str, Any]:
        """
        æ‰§è¡Œæ··åˆæœç´¢
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            top_k: è¿”å›ç»“æœæ•°é‡ï¼ˆä¿ç•™å‚æ•°å…¼å®¹æ€§ï¼Œä½†å†…éƒ¨é€»è¾‘å›ºå®šä¸º5ï¼‰
            
        Returns:
            æœç´¢ç»“æœå­—å…¸ï¼ŒåŒ…å«ç»“æœåˆ—è¡¨å’Œå…ƒæ•°æ®
        """
        logger.info(f"å¼€å§‹æ··åˆæœç´¢: {query}")
        
        # å›ºå®šæœç´¢å‚æ•°ï¼šå‘é‡å’ŒBM25å„è¿”å›10ä¸ªï¼Œæœ€ç»ˆèåˆåè¿”å›5ä¸ª
        vector_search_count = 10
        bm25_search_count = 10
        final_result_count = 5
        
        # æ›´æ–°ç»Ÿè®¡
        if self.enable_unified_processing:
            self.unified_processing_stats["total_queries"] += 1
        else:
            self.query_rewrite_stats["total_queries"] += 1
            self.query_translation_stats["total_queries"] += 1
        
        # æŸ¥è¯¢å¤„ç†
        if self.enable_unified_processing:
            # ä½¿ç”¨ç»Ÿä¸€å¤„ç†å™¨ï¼ˆæ¨èæ–¹å¼ï¼‰
            try:
                unified_result = process_query_unified(query, self.llm_config)
                
                # æå–å¤„ç†ç»“æœ
                final_query = unified_result.rewritten_query
                translation_applied = unified_result.translation_applied
                rewrite_applied = unified_result.rewrite_applied
                
                # æ›´æ–°ç»Ÿè®¡
                self.unified_processing_stats["unified_successful"] += 1
                if hasattr(unified_result, 'processing_time'):
                    avg_time = self.unified_processing_stats["average_processing_time"]
                    total_queries = self.unified_processing_stats["total_queries"]
                    self.unified_processing_stats["average_processing_time"] = (
                        (avg_time * (total_queries - 1) + unified_result.processing_time) / total_queries
                    )
                
                # æ„å»ºæŸ¥è¯¢å…ƒæ•°æ®
                query_metadata = {
                    "original_query": query,
                    "processed_query": final_query,
                    "bm25_optimized_query": unified_result.bm25_optimized_query,  # æ·»åŠ BM25ä¼˜åŒ–æŸ¥è¯¢
                    "translation_applied": translation_applied,
                    "rewrite_applied": rewrite_applied,
                    "intent": unified_result.intent,
                    "confidence": unified_result.confidence,
                    "detected_language": unified_result.detected_language,
                    "processing_method": "unified",
                    "reasoning": unified_result.reasoning
                }
                
                logger.info(f"ç»Ÿä¸€å¤„ç†æˆåŠŸ: '{query}' -> '{final_query}' (ç¿»è¯‘: {translation_applied}, é‡å†™: {rewrite_applied})")
                
            except Exception as e:
                logger.error(f"ç»Ÿä¸€å¤„ç†å¤±è´¥: {e}")
                self.unified_processing_stats["unified_failed"] += 1
                
                # é™çº§åˆ°åŸå§‹æŸ¥è¯¢
                final_query = query
                translation_applied = False
                rewrite_applied = False
                query_metadata = {
                    "original_query": query,
                    "processed_query": final_query,
                    "bm25_optimized_query": final_query,  # é™çº§æ—¶ä½¿ç”¨åŸå§‹æŸ¥è¯¢
                    "translation_applied": False,
                    "rewrite_applied": False,
                    "processing_method": "fallback",
                    "error": str(e)
                }
        else:
            # åŸæœ‰çš„åˆ†ç¦»å¤„ç†æ–¹å¼ï¼ˆå…¼å®¹æ€§ä¿ç•™ï¼‰
            final_query = query
            translation_applied = False
            rewrite_applied = False
            
            # æŸ¥è¯¢ç¿»è¯‘ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if self.enable_query_translation:
                try:
                    from .query_translator import translate_query_if_needed
                    translated_query = translate_query_if_needed(query, self.llm_config)
                    if translated_query != query:
                        final_query = translated_query
                        translation_applied = True
                        self.query_translation_stats["translated_queries"] += 1
                        logger.info(f"æŸ¥è¯¢ç¿»è¯‘: '{query}' -> '{translated_query}'")
                except Exception as e:
                    logger.warning(f"æŸ¥è¯¢ç¿»è¯‘å¤±è´¥: {e}")
            
            # æŸ¥è¯¢é‡å†™ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if self.enable_query_rewrite:
                try:
                    from .intent.intent_classifier import rewrite_query_for_search
                    rewrite_result = rewrite_query_for_search(final_query, self.llm_config)
                    
                    if rewrite_result.rewritten_query != final_query:
                        final_query = rewrite_result.rewritten_query
                        rewrite_applied = True
                        self.query_rewrite_stats["rewritten_queries"] += 1
                        logger.info(f"æŸ¥è¯¢é‡å†™: '{query}' -> '{final_query}'")
                        
                except Exception as e:
                    logger.warning(f"æŸ¥è¯¢é‡å†™å¤±è´¥: {e}")
            
            query_metadata = {
                "original_query": query,
                "processed_query": final_query,
                "bm25_optimized_query": final_query,  # åˆ†ç¦»å¤„ç†æ—¶ä½¿ç”¨å¤„ç†åçš„æŸ¥è¯¢
                "translation_applied": translation_applied,
                "rewrite_applied": rewrite_applied,
                "processing_method": "separate"
            }
        
        # æ‰§è¡Œæ··åˆæœç´¢
        try:
            # å‘é‡æœç´¢ - å›ºå®šè¿”å›10ä¸ªç»“æœ
            print(f"ğŸ” [HYBRID-DEBUG] å¼€å§‹å‘é‡æœç´¢: query='{final_query}', top_k={vector_search_count}")
            vector_results = self.vector_retriever.search(final_query, vector_search_count)
            print(f"ğŸ“Š [HYBRID-DEBUG] å‘é‡æœç´¢ç»“æœæ•°é‡: {len(vector_results)}")
            
            if vector_results:
                print(f"   ğŸ“‹ [HYBRID-DEBUG] å‘é‡æœç´¢Top3ç»“æœ:")
                for i, result in enumerate(vector_results[:3]):
                    chunk = result.get("chunk", {})
                    print(f"      {i+1}. ä¸»é¢˜: {chunk.get('topic', 'Unknown')}")
                    print(f"         åˆ†æ•°: {result.get('score', 0):.4f}")
                    print(f"         æ‘˜è¦: {chunk.get('summary', '')[:80]}...")
            
            # BM25æœç´¢ - å›ºå®šè¿”å›10ä¸ªç»“æœï¼Œä½¿ç”¨LLMä¼˜åŒ–çš„æŸ¥è¯¢
            bm25_results = []
            if self.bm25_indexer:
                # ä½¿ç”¨LLMä¼˜åŒ–çš„BM25æŸ¥è¯¢
                bm25_query = query_metadata.get("bm25_optimized_query", final_query)
                print(f"ğŸ” [HYBRID-DEBUG] å¼€å§‹BM25æœç´¢:")
                print(f"   - åŸå§‹æŸ¥è¯¢: '{query}'")
                print(f"   - è¯­ä¹‰æŸ¥è¯¢: '{final_query}'")
                print(f"   - BM25ä¼˜åŒ–: '{bm25_query}'")
                print(f"   - æ£€ç´¢æ•°é‡: {bm25_search_count}")
                
                bm25_results = self.bm25_indexer.search(bm25_query, bm25_search_count)
                print(f"ğŸ“Š [HYBRID-DEBUG] BM25æœç´¢ç»“æœæ•°é‡: {len(bm25_results)}")
                
                if bm25_results:
                    print(f"   ğŸ“‹ [HYBRID-DEBUG] BM25æœç´¢Top3ç»“æœ:")
                    for i, result in enumerate(bm25_results[:3]):
                        chunk = result.get("chunk", {})
                        print(f"      {i+1}. ä¸»é¢˜: {chunk.get('topic', 'Unknown')}")
                        print(f"         åˆ†æ•°: {result.get('score', 0):.4f}")
                        print(f"         æ‘˜è¦: {chunk.get('summary', '')[:80]}...")
                        if "match_info" in result:
                            print(f"         åŒ¹é…ä¿¡æ¯: {result['match_info'].get('relevance_reason', 'N/A')}")
            else:
                print(f"âš ï¸ [HYBRID-DEBUG] BM25ç´¢å¼•å™¨æœªåˆå§‹åŒ–ï¼Œè·³è¿‡BM25æœç´¢")
            
            # åˆ†æ•°èåˆ - å›ºå®šè¿”å›5ä¸ªç»“æœ
            print(f"ğŸ”„ [HYBRID-DEBUG] å¼€å§‹åˆ†æ•°èåˆ: æ–¹æ³•={self.fusion_method}")
            print(f"   - å‘é‡æƒé‡: {self.vector_weight}")
            print(f"   - BM25æƒé‡: {self.bm25_weight}")
            print(f"   - RRF_K: {self.rrf_k}")
            print(f"   - æœ€ç»ˆè¿”å›ç»“æœæ•°: {final_result_count}")
            
            final_results = self._fuse_results(vector_results, bm25_results, final_result_count)
            
            print(f"âœ… [HYBRID-DEBUG] åˆ†æ•°èåˆå®Œæˆï¼Œæœ€ç»ˆç»“æœæ•°é‡: {len(final_results)}")
            if final_results:
                print(f"   ğŸ“‹ [HYBRID-DEBUG] èåˆåTop5ç»“æœ:")
                for i, result in enumerate(final_results):
                    chunk = result.get("chunk", {})
                    print(f"      {i+1}. ä¸»é¢˜: {chunk.get('topic', 'Unknown')}")
                    print(f"         èåˆåˆ†æ•°: {result.get('fusion_score', 0):.4f}")
                    print(f"         å‘é‡åˆ†æ•°: {result.get('vector_score', 0):.4f}")
                    print(f"         BM25åˆ†æ•°: {result.get('bm25_score', 0):.4f}")
            
            # æ„å»ºè¿”å›ç»“æœ
            return {
                "results": final_results,
                "query": query_metadata,
                "metadata": {
                    "fusion_method": self.fusion_method,
                    "vector_results_count": len(vector_results),
                    "bm25_results_count": len(bm25_results),
                    "final_results_count": len(final_results),
                    "vector_search_count": vector_search_count,
                    "bm25_search_count": bm25_search_count,
                    "target_final_count": final_result_count,
                    "processing_stats": self._get_processing_stats()
                }
            }
            
        except Exception as e:
            print(f"âŒ [HYBRID-DEBUG] æ··åˆæœç´¢æ‰§è¡Œå¤±è´¥: {e}")
            logger.error(f"æ··åˆæœç´¢æ‰§è¡Œå¤±è´¥: {e}")
            return {
                "results": [],
                "query": query_metadata,
                "metadata": {
                    "error": str(e),
                    "vector_search_count": vector_search_count,
                    "bm25_search_count": bm25_search_count,
                    "target_final_count": final_result_count,
                    "processing_stats": self._get_processing_stats()
                }
            }
    
    def _fuse_results(self, vector_results: List[Dict], bm25_results: List[Dict], top_k: int) -> List[Dict]:
        """
        èåˆå‘é‡æœç´¢å’ŒBM25æœç´¢çš„ç»“æœ
        
        Args:
            vector_results: å‘é‡æœç´¢ç»“æœ
            bm25_results: BM25æœç´¢ç»“æœ
            top_k: è¿”å›çš„ç»“æœæ•°é‡
            
        Returns:
            èåˆåçš„æœç´¢ç»“æœ
        """
        if self.fusion_method == "rrf":
            return self._reciprocal_rank_fusion(vector_results, bm25_results, top_k)
        elif self.fusion_method == "weighted":
            return self._weighted_fusion(vector_results, bm25_results, top_k)
        elif self.fusion_method == "normalized":
            return self._normalized_fusion(vector_results, bm25_results, top_k)
        else:
            logger.warning(f"æœªçŸ¥çš„èåˆæ–¹æ³•: {self.fusion_method}ï¼Œä½¿ç”¨RRF")
            return self._reciprocal_rank_fusion(vector_results, bm25_results, top_k)
    
    def _reciprocal_rank_fusion(self, vector_results: List[Dict], bm25_results: List[Dict], top_k: int) -> List[Dict]:
        """
        ä½¿ç”¨å€’æ•°æ’åèåˆ(RRF)ç®—æ³•èåˆç»“æœ
        """
        print(f"ğŸ”„ [FUSION-DEBUG] å¼€å§‹RRFèåˆ: å‘é‡ç»“æœ={len(vector_results)}, BM25ç»“æœ={len(bm25_results)}, k={self.rrf_k}")
        
        # åˆ›å»ºæ–‡æ¡£IDåˆ°åˆ†æ•°çš„æ˜ å°„
        doc_scores = {}
        
        # å¤„ç†å‘é‡æœç´¢ç»“æœ
        print(f"   ğŸ“Š [FUSION-DEBUG] å¤„ç†å‘é‡æœç´¢ç»“æœ:")
        for rank, result in enumerate(vector_results, 1):
            chunk = result.get("chunk", {})
            doc_id = chunk.get("chunk_id", f"vector_{rank}")
            rrf_score = 1.0 / (self.rrf_k + rank)
            
            print(f"      {rank}. ID: {doc_id}")
            print(f"         åŸå§‹åˆ†æ•°: {result.get('score', 0):.4f}")
            print(f"         RRFåˆ†æ•°: {rrf_score:.4f}")
            print(f"         ä¸»é¢˜: {chunk.get('topic', 'Unknown')}")
            
            if doc_id not in doc_scores:
                doc_scores[doc_id] = {
                    "result": result,
                    "vector_score": result.get("score", 0),
                    "bm25_score": 0,
                    "rrf_score": 0
                }
            doc_scores[doc_id]["rrf_score"] += rrf_score
        
        # å¤„ç†BM25æœç´¢ç»“æœ
        print(f"   ğŸ“Š [FUSION-DEBUG] å¤„ç†BM25æœç´¢ç»“æœ:")
        for rank, result in enumerate(bm25_results, 1):
            chunk = result.get("chunk", {})
            doc_id = chunk.get("chunk_id", f"bm25_{rank}")
            rrf_score = 1.0 / (self.rrf_k + rank)
            
            print(f"      {rank}. ID: {doc_id}")
            print(f"         åŸå§‹åˆ†æ•°: {result.get('score', 0):.4f}")
            print(f"         RRFåˆ†æ•°: {rrf_score:.4f}")
            print(f"         ä¸»é¢˜: {chunk.get('topic', 'Unknown')}")
            
            if doc_id not in doc_scores:
                doc_scores[doc_id] = {
                    "result": result,
                    "vector_score": 0,
                    "bm25_score": result.get("score", 0),
                    "rrf_score": 0
                }
            else:
                doc_scores[doc_id]["bm25_score"] = result.get("score", 0)
            
            doc_scores[doc_id]["rrf_score"] += rrf_score
        
        # æŒ‰RRFåˆ†æ•°æ’åºå¹¶è¿”å›top_kç»“æœ
        sorted_docs = sorted(doc_scores.items(), key=lambda x: x[1]["rrf_score"], reverse=True)
        
        print(f"   ğŸ“Š [FUSION-DEBUG] èåˆåæ’åºç»“æœ:")
        for i, (doc_id, scores) in enumerate(sorted_docs[:min(5, len(sorted_docs))]):
            print(f"      {i+1}. ID: {doc_id}")
            print(f"         æœ€ç»ˆRRFåˆ†æ•°: {scores['rrf_score']:.4f}")
            print(f"         å‘é‡åˆ†æ•°: {scores['vector_score']:.4f}")
            print(f"         BM25åˆ†æ•°: {scores['bm25_score']:.4f}")
            print(f"         ä¸»é¢˜: {scores['result'].get('chunk', {}).get('topic', 'Unknown')}")
        
        final_results = []
        for doc_id, scores in sorted_docs[:top_k]:
            # æ·±æ‹·è´ç»“æœå¯¹è±¡ä»¥é¿å…å¼•ç”¨é—®é¢˜
            result = scores["result"].copy()
            
            # ç¡®ä¿æ­£ç¡®è®¾ç½®åˆ†æ•°å­—æ®µ
            result["score"] = scores["rrf_score"]  # ä¸»è¦åˆ†æ•°æ˜¯RRFåˆ†æ•°
            result["fusion_score"] = scores["rrf_score"]
            result["vector_score"] = scores["vector_score"] 
            result["bm25_score"] = scores["bm25_score"]
            result["fusion_method"] = "rrf"
            result["original_vector_score"] = scores["vector_score"]  # ä¿ç•™åŸå§‹å‘é‡åˆ†æ•°
            result["original_bm25_score"] = scores["bm25_score"]     # ä¿ç•™åŸå§‹BM25åˆ†æ•°
            
            # æ·»åŠ è°ƒè¯•éªŒè¯
            print(f"   ğŸ”§ [FUSION-DEBUG] æœ€ç»ˆç»“æœ {len(final_results)+1}:")
            print(f"      ä¸»é¢˜: {result.get('chunk', {}).get('topic', 'Unknown')}")
            print(f"      è®¾ç½®çš„scoreå­—æ®µ: {result['score']:.4f}")
            print(f"      RRFåˆ†æ•°: {result['fusion_score']:.4f}")
            
            final_results.append(result)
        
        print(f"âœ… [FUSION-DEBUG] RRFèåˆå®Œæˆï¼Œè¿”å› {len(final_results)} ä¸ªç»“æœ")
        return final_results
    
    def _weighted_fusion(self, vector_results: List[Dict], bm25_results: List[Dict], top_k: int) -> List[Dict]:
        """
        ä½¿ç”¨åŠ æƒå¹³å‡èåˆç»“æœ
        """
        # å½’ä¸€åŒ–åˆ†æ•°
        vector_scores = [r.get("score", 0) for r in vector_results]
        bm25_scores = [r.get("score", 0) for r in bm25_results]
        
        if vector_scores:
            vector_scaler = MinMaxScaler()
            vector_scores_norm = vector_scaler.fit_transform([[s] for s in vector_scores]).flatten()
        else:
            vector_scores_norm = []
        
        if bm25_scores:
            bm25_scaler = MinMaxScaler()
            bm25_scores_norm = bm25_scaler.fit_transform([[s] for s in bm25_scores]).flatten()
        else:
            bm25_scores_norm = []
        
        # åˆ›å»ºæ–‡æ¡£åˆ†æ•°æ˜ å°„
        doc_scores = {}
        
        # å¤„ç†å‘é‡ç»“æœ
        for i, result in enumerate(vector_results):
            doc_id = result.get("chunk_id", f"vector_{i}")
            normalized_score = vector_scores_norm[i] if i < len(vector_scores_norm) else 0
            
            if doc_id not in doc_scores:
                doc_scores[doc_id] = {
                    "result": result,
                    "vector_score": normalized_score,
                    "bm25_score": 0
                }
            else:
                doc_scores[doc_id]["vector_score"] = normalized_score
        
        # å¤„ç†BM25ç»“æœ
        for i, result in enumerate(bm25_results):
            doc_id = result.get("chunk_id", f"bm25_{i}")
            normalized_score = bm25_scores_norm[i] if i < len(bm25_scores_norm) else 0
            
            if doc_id not in doc_scores:
                doc_scores[doc_id] = {
                    "result": result,
                    "vector_score": 0,
                    "bm25_score": normalized_score
                }
            else:
                doc_scores[doc_id]["bm25_score"] = normalized_score
        
        # è®¡ç®—åŠ æƒåˆ†æ•°
        for doc_id, scores in doc_scores.items():
            weighted_score = (
                scores["vector_score"] * self.vector_weight +
                scores["bm25_score"] * self.bm25_weight
            )
            scores["fusion_score"] = weighted_score
        
        # æ’åºå¹¶è¿”å›ç»“æœ
        sorted_docs = sorted(doc_scores.items(), key=lambda x: x[1]["fusion_score"], reverse=True)
        
        final_results = []
        for doc_id, scores in sorted_docs[:top_k]:
            result = scores["result"].copy()
            result["fusion_score"] = scores["fusion_score"]
            result["vector_score"] = scores["vector_score"]
            result["bm25_score"] = scores["bm25_score"]
            result["fusion_method"] = "weighted"
            final_results.append(result)
        
        return final_results
    
    def _normalized_fusion(self, vector_results: List[Dict], bm25_results: List[Dict], top_k: int) -> List[Dict]:
        """
        ä½¿ç”¨å½’ä¸€åŒ–èåˆç»“æœ
        """
        # å½’ä¸€åŒ–å¤„ç†é€»è¾‘ç±»ä¼¼åŠ æƒèåˆï¼Œä½†æƒé‡ç›¸ç­‰
        temp_vector_weight = self.vector_weight
        temp_bm25_weight = self.bm25_weight
        
        # ä¸´æ—¶è®¾ç½®ç›¸ç­‰æƒé‡
        self.vector_weight = 0.5
        self.bm25_weight = 0.5
        
        result = self._weighted_fusion(vector_results, bm25_results, top_k)
        
        # æ¢å¤åŸæƒé‡
        self.vector_weight = temp_vector_weight
        self.bm25_weight = temp_bm25_weight
        
        # æ›´æ–°èåˆæ–¹æ³•æ ‡è®°
        for r in result:
            r["fusion_method"] = "normalized"
        
        return result
    
    def _get_processing_stats(self) -> Dict[str, Any]:
        """è·å–å¤„ç†ç»Ÿè®¡ä¿¡æ¯"""
        if self.enable_unified_processing:
            return {
                "method": "unified_processing",
                "stats": self.unified_processing_stats.copy()
            }
        else:
            return {
                "method": "separate_processing",
                "translation_stats": self.query_translation_stats.copy(),
                "rewrite_stats": self.query_rewrite_stats.copy()
            }
    
    def get_search_stats(self) -> Dict[str, Any]:
        """è·å–æœç´¢ç»Ÿè®¡ä¿¡æ¯"""
        vector_stats = {}
        bm25_stats = {}
        
        # è·å–BM25ç»Ÿè®¡
        if hasattr(self.bm25_indexer, 'get_stats'):
            bm25_stats = self.bm25_indexer.get_stats()
        
        base_stats = {
            "vector_stats": vector_stats,
            "bm25_stats": bm25_stats,
            "unified_processing_enabled": self.enable_unified_processing,
            "query_rewrite_enabled": self.enable_query_rewrite,
            "query_translation_enabled": self.enable_query_translation
        }
        
        if self.enable_unified_processing:
            base_stats["unified_processing_stats"] = self.unified_processing_stats.copy()
        else:
            base_stats["query_rewrite_stats"] = self.query_rewrite_stats.copy()
            base_stats["query_translation_stats"] = self.query_translation_stats.copy()
        
        return base_stats
    
    def reset_stats(self):
        """é‡ç½®æ‰€æœ‰ç»Ÿè®¡ä¿¡æ¯"""
        self.unified_processing_stats = {
            "total_queries": 0,
            "unified_successful": 0,
            "unified_failed": 0,
            "cache_hits": 0,
            "average_processing_time": 0.0
        }
        
        self.query_rewrite_stats = {
            "total_queries": 0,
            "rewritten_queries": 0,
            "cache_hits": 0
        }
        
        self.query_translation_stats = {
            "total_queries": 0,
            "translated_queries": 0
        }


def test_hybrid_retriever():
    """æµ‹è¯•æ··åˆæ£€ç´¢å™¨"""
    # è¿™é‡Œéœ€è¦å®é™…çš„å‘é‡æ£€ç´¢å™¨å®ä¾‹
    print("æ··åˆæ£€ç´¢å™¨æµ‹è¯•éœ€è¦å®Œæ•´çš„RAGç³»ç»Ÿæ”¯æŒ")
    print("è¯·åœ¨å®Œæ•´ç³»ç»Ÿä¸­æµ‹è¯•")


if __name__ == "__main__":
    test_hybrid_retriever() 