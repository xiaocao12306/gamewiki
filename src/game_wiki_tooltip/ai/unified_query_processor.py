"""
ç»Ÿä¸€æŸ¥è¯¢å¤„ç†å™¨ - ä¸€æ¬¡LLMè°ƒç”¨å®Œæˆå¤šé¡¹ä»»åŠ¡
===================================================

å°†æŸ¥è¯¢ç¿»è¯‘ã€é‡å†™ã€æ„å›¾åˆ†æåˆå¹¶åˆ°å•æ¬¡LLMè°ƒç”¨ä¸­ï¼Œæé«˜å“åº”é€Ÿåº¦
"""

import json
import hashlib
import time
import logging
from typing import Dict, Any, Optional, Literal
from dataclasses import dataclass

from ..config import LLMConfig

logger = logging.getLogger(__name__)

@dataclass
class UnifiedQueryResult:
    """ç»Ÿä¸€æŸ¥è¯¢å¤„ç†ç»“æœ"""
    original_query: str
    detected_language: str
    translated_query: str
    rewritten_query: str
    bm25_optimized_query: str  # æ–°å¢ï¼šä¸“é—¨ä¸ºBM25ä¼˜åŒ–çš„æŸ¥è¯¢
    intent: str
    confidence: float
    search_type: str
    reasoning: str
    translation_applied: bool
    rewrite_applied: bool
    processing_time: float

class UnifiedQueryProcessor:
    """ç»Ÿä¸€æŸ¥è¯¢å¤„ç†å™¨ - ä¸€æ¬¡LLMè°ƒç”¨å®Œæˆç¿»è¯‘+é‡å†™+æ„å›¾åˆ†æ"""
    
    def __init__(self, llm_config: Optional[LLMConfig] = None):
        self.llm_config = llm_config or LLMConfig()
        self.llm_client = None
        
        # ç¼“å­˜æœºåˆ¶
        self.query_cache = {}
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            "total_queries": 0,
            "cache_hits": 0,
            "successful_processing": 0,
            "failed_processing": 0,
            "average_processing_time": 0.0
        }
        
        # åˆå§‹åŒ–LLMå®¢æˆ·ç«¯
        if self.llm_config.is_valid():
            self._initialize_llm_client()
        else:
            logger.warning("LLMé…ç½®æ— æ•ˆï¼Œå°†ä½¿ç”¨åŸºç¡€å¤„ç†æ¨¡å¼")
    
    def _initialize_llm_client(self):
        """åˆå§‹åŒ–LLMå®¢æˆ·ç«¯"""
        try:
            if "gemini" in self.llm_config.model.lower():
                self._initialize_gemini_client()
            elif "gpt" in self.llm_config.model.lower():
                self._initialize_openai_client()
            else:
                logger.error(f"ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹: {self.llm_config.model}")
                return
                
            logger.info(f"ç»Ÿä¸€æŸ¥è¯¢å¤„ç†å™¨åˆå§‹åŒ–æˆåŠŸï¼Œæ¨¡å‹: {self.llm_config.model}")
        except Exception as e:
            logger.error(f"LLMå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
            
    def _initialize_gemini_client(self):
        """åˆå§‹åŒ–Geminiå®¢æˆ·ç«¯"""
        try:
            import google.generativeai as genai
            
            api_key = self.llm_config.get_api_key()
            if not api_key:
                raise ValueError("æœªæ‰¾åˆ°Gemini APIå¯†é’¥")
                
            genai.configure(api_key=api_key)
            
            generation_config = genai.types.GenerationConfig(
                max_output_tokens=self.llm_config.max_tokens,
                temperature=self.llm_config.temperature,
            )
            
            self.llm_client = genai.GenerativeModel(
                model_name=self.llm_config.model,
                generation_config=generation_config,
            )
            
        except Exception as e:
            logger.error(f"Geminiå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    def _initialize_openai_client(self):
        """åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯"""
        try:
            import openai
            
            api_key = self.llm_config.get_api_key()
            if not api_key:
                raise ValueError("æœªæ‰¾åˆ°OpenAI APIå¯†é’¥")
                
            self.llm_client = openai.OpenAI(
                api_key=api_key,
                base_url=self.llm_config.base_url if self.llm_config.base_url else None,
                timeout=self.llm_config.timeout
            )
            
        except Exception as e:
            logger.error(f"OpenAIå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    def _generate_cache_key(self, query: str) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        return hashlib.md5(f"{query}_{self.llm_config.model}".encode()).hexdigest()
    
    def _get_cached_result(self, query: str) -> Optional[UnifiedQueryResult]:
        """è·å–ç¼“å­˜çš„ç»“æœ"""
        if not self.llm_config.enable_cache:
            return None
            
        cache_key = self._generate_cache_key(query)
        if cache_key in self.query_cache:
            cached_data, timestamp = self.query_cache[cache_key]
            if time.time() - timestamp < self.llm_config.cache_ttl:
                self.stats["cache_hits"] += 1
                return cached_data
            else:
                del self.query_cache[cache_key]
        return None
    
    def _cache_result(self, query: str, result: UnifiedQueryResult):
        """ç¼“å­˜ç»“æœ"""
        if not self.llm_config.enable_cache:
            return
            
        cache_key = self._generate_cache_key(query)
        self.query_cache[cache_key] = (result, time.time())
    
    def _create_unified_prompt(self, query: str) -> str:
        """åˆ›å»ºç»Ÿä¸€å¤„ç†çš„æç¤ºè¯"""
        prompt = f"""You are an AI assistant that processes search queries for a universal game wiki and guide system.

Your task is to analyze the user's query and perform the following tasks in ONE response:
1. **Language Detection**: Detect the language of the query
2. **Translation**: If the query is in Chinese, translate it to English
3. **Intent Classification**: Classify the intent (wiki/guide/unknown)
4. **Query Rewriting**: Optimize the query for semantic search
5. **BM25 Optimization**: Create a specialized query for keyword-based BM25 search

Original Query: "{query}"

Please provide a JSON response with the following structure:
{{
    "detected_language": "zh|en|other",
    "translated_query": "English translation if needed, otherwise same as original",
    "intent": "wiki|guide|unknown",
    "confidence": 0.0-1.0,
    "rewritten_query": "optimized query for semantic search",
    "bm25_optimized_query": "specialized query for BM25 keyword search",
    "reasoning": "explanation of your analysis and optimizations",
    "search_type": "semantic|keyword|hybrid"
}}

**Analysis Guidelines:**

**Language Detection:**
- If >30% characters are Chinese (\\u4e00-\\u9fff), mark as "zh"
- Otherwise mark as "en" or "other"

**Intent Classification:**
- **wiki**: User wants factual information, definitions, stats, or specific item/character/enemy data
  - Single words or short phrases that look like game-specific terms should be classified as wiki
  - **Game-specific term indicators:**
    - Proper nouns (capitalized words like "Excalibur", "Gandalf", "Dragonbone")
    - Uncommon word combinations that sound like item/character names (e.g. Democratic detonation)
    - Single technical-sounding words without common modifiers
    - Foreign or fantasy-sounding terms
    - Compound words that suggest game items (e.g., "Bloodstone", "Frostbolt", "Ironhelm")
  - Examples: "wizard", "sword stats", "Excalibur", "ä»€ä¹ˆæ˜¯æ³•å¸ˆ", "è§’è‰²å±æ€§", "Bloodstone", "é“å‰‘", "æ³•å¸ˆå¡”"
  - Keywords: "what is", "info", "stats", "damage", "æ˜¯ä»€ä¹ˆ", "ä¿¡æ¯", "æ•°æ®", "å±æ€§"
  - **Rule**: If the query is 1-2 words and doesn't contain guide keywords, classify as wiki

- **guide**: User wants strategies, recommendations, progression advice, or how-to instructions
  - Examples: "how to beat boss", "best build", "progression guide", "é€‰æ‹©ä»€ä¹ˆèŒä¸š", "longsword build"
  - Keywords: "how", "best", "recommend", "next", "after", "should", "build", "guide", "strategy", "tips", "æ€ä¹ˆ", "æ¨è", "ä¸‹ä¸€ä¸ª", "é€‰æ‹©", "é…ç½®", "æ”»ç•¥", "ç­–ç•¥"
  - **Strategy-related terms**: "build", "setup", "loadout", "combo", "synergy", "meta", "tier", "rotation", "counter", "optimal", "efficient", "playstyle", "progression", "priority", "comparison", "vs", "choice", "unlock", "é…ç½®", "æ­é…", "ç»„åˆ", "è¿å‡»", "å…‹åˆ¶", "æœ€ä¼˜", "é«˜æ•ˆ", "ç©æ³•", "è¿›é˜¶", "ä¼˜å…ˆçº§", "æ¯”è¾ƒ", "è§£é”", "ååŒ"
  - **Build-related queries**: Any query containing strategy-related terms should be classified as guide
  - Special attention: Queries about "what's next", "what to unlock after X", "progression order" are GUIDE queries
  - **Rule**: Classify as guide if the query asks for advice, strategy, how-to information, OR contains build/setup-related terms

**Query Rewriting (for semantic search):**
- DO NOT add any specific game names or prefixes unless they exist in the original query
- For general terms, keep them general (e.g., "æ³•å¸ˆ" -> "mage" or "wizard", not "GameName mage")
- For strategy queries, add keywords like "strategy", "guide"
- For recommendation queries, add "best", "recommendation"
- Keep original game-specific terms unchanged only if they appear in the query
- Preserve the original meaning and scope of the query

**BM25 Query Optimization (CRITICAL - for keyword search):**
This is a specialized query designed to enhance important game terms while preserving the original query intent.

**Key Principles:**
1. **Preserve original query structure**: Keep the user's original words and intent
2. **Enhance game-specific nouns**: Repeat weapon names, character names, item names, location names
3. **Boost core topic words**: Repeat important concepts like "build", "weapon", "character", "strategy"
4. **Maintain query coherence**: Don't add unrelated terms that might match wrong content
5. **Weight through repetition**: Use repetition to increase BM25 term frequency scores

**Examples:**
- "best warbond" -> "best warbond warbond warbond recommendations"
- "wizard build guide" -> "wizard wizard build build loadout guide"  
- "sword recommendations" -> "sword sword weapon recommendations guide"
- "æ³•å¸ˆæ¨èè£…å¤‡" -> "æ³•å¸ˆ æ³•å¸ˆ æ¨è è£…å¤‡ è£…å¤‡ é…ç½®"

**Rules for BM25 optimization:**
- Keep ALL original query terms
- Identify game-specific proper nouns and repeat them 2-3 times
- Identify core topic words (build, weapon, character, boss, etc.) and repeat them 1-2 times
- Add closely related game terms only if they enhance the topic (e.g., "build" -> add "loadout")
- For build queries, add: "loadout", "setup", "configuration" 
- For weapon queries, add: "gear", "equipment"
- For character queries, add: "class", "hero"
- NEVER replace words - only enhance through repetition and related terms
- Maintain readability and avoid excessive repetition (max 3 times per term)

**Search Type:**
- "semantic": For conceptual queries requiring understanding (recommendations, strategies)
- "keyword": For specific item/character lookups
- "hybrid": When both approaches would be beneficial

**Important Notes:**
- Queries asking for recommendations or "what's next" are ALWAYS guide intents
- Queries about progression order or unlock priorities are ALWAYS guide intents
- Only classify as "wiki" when user explicitly wants factual data/definitions
- DO NOT assume any specific game context unless explicitly mentioned in the query
- Keep translations and rewrites GENERIC and GAME-AGNOSTIC
- BM25 optimization should focus on KEYWORDS and SPECIFIC TERMS, not generic descriptors
"""
        
        return prompt
    
    def _call_llm_with_retry(self, prompt: str) -> Optional[Dict]:
        """å¸¦é‡è¯•çš„LLMè°ƒç”¨"""
        for attempt in range(self.llm_config.max_retries):
            try:
                if "gemini" in self.llm_config.model.lower():
                    response = self.llm_client.generate_content(prompt)
                    response_text = response.text.strip()
                elif "gpt" in self.llm_config.model.lower():
                    response = self.llm_client.chat.completions.create(
                        model=self.llm_config.model,
                        messages=[{"role": "user", "content": prompt}],
                        max_tokens=self.llm_config.max_tokens,
                        temperature=self.llm_config.temperature
                    )
                    response_text = response.choices[0].message.content.strip()
                else:
                    return None
                
                # è§£æJSONå“åº”
                if response_text.startswith('```json'):
                    response_text = response_text[7:-3]
                elif response_text.startswith('```'):
                    response_text = response_text[3:-3]
                
                return json.loads(response_text)
                
            except Exception as e:
                logger.warning(f"ç»Ÿä¸€å¤„ç†LLMè°ƒç”¨å¤±è´¥ (å°è¯• {attempt + 1}/{self.llm_config.max_retries}): {e}")
                if attempt < self.llm_config.max_retries - 1:
                    time.sleep(self.llm_config.retry_delay * (2 ** attempt))
                
        return None
    
    def _basic_processing(self, query: str) -> UnifiedQueryResult:
        """åŸºç¡€å¤„ç†æ¨¡å¼ï¼ˆLLMä¸å¯ç”¨æ—¶çš„é™çº§æ–¹æ¡ˆï¼‰"""
        # ç®€å•çš„è¯­è¨€æ£€æµ‹
        chinese_chars = sum(1 for char in query if '\u4e00' <= char <= '\u9fff')
        detected_language = "zh" if chinese_chars / len(query) > 0.3 else "en"
        
        # åŸºç¡€æ„å›¾åˆ†ç±»
        intent = "guide"
        confidence = 0.6
        
        # åˆ¤æ–­æ˜¯å¦æ˜¯è¯¢é—®å®šä¹‰çš„wikiæŸ¥è¯¢
        wiki_patterns = ["what is", "ä»€ä¹ˆæ˜¯", "æ˜¯ä»€ä¹ˆ", "info", "stats", "æ•°æ®", "å±æ€§"]
        if any(pattern in query.lower() for pattern in wiki_patterns):
            intent = "wiki"
            confidence = 0.8
        # åˆ¤æ–­æ˜¯å¦æ˜¯guideæŸ¥è¯¢
        elif any(word in query.lower() for word in ["how", "å¦‚ä½•", "æ€ä¹ˆ", "best", "recommend", "æ¨è", "next", "ä¸‹ä¸€ä¸ª", "é€‰æ‹©", "è¯¥"]):
            intent = "guide"
            confidence = 0.8
        # ç‰¹æ®Šå¤„ç†"ä»€ä¹ˆ"çš„æƒ…å†µ
        elif "ä»€ä¹ˆ" in query:
            # å¦‚æœæ˜¯"è¯¥xxxä»€ä¹ˆ"æˆ–"é€‰ä»€ä¹ˆ"ç­‰æ¨èç±»æŸ¥è¯¢
            if any(pattern in query for pattern in ["è¯¥", "é€‰", "ä¸‹ä¸€ä¸ª", "æ¨è"]):
                intent = "guide"
                confidence = 0.7
            else:
                intent = "wiki"
                confidence = 0.6
        
        # åŸºç¡€é‡å†™ - ä¿æŒé€šç”¨æ€§ï¼Œä¸ç‰¹å®šäºä»»ä½•æ¸¸æˆ
        rewritten_query = query
        
        # é€šç”¨çš„æ¨èæŸ¥è¯¢å¤„ç†
        if any(word in query.lower() for word in ["æ¨è", "é€‰æ‹©", "recommend", "choice", "next", "ä¸‹ä¸€ä¸ª"]):
            # æ£€æµ‹æ˜¯å¦ä¸ºæ¨èç±»æŸ¥è¯¢
            if not any(word in rewritten_query.lower() for word in ["guide", "recommendation", "æ”»ç•¥"]):
                rewritten_query += " guide recommendation"
            intent = "guide"
            confidence = 0.8
        
        # é€šç”¨çš„ç­–ç•¥æŸ¥è¯¢å¤„ç†
        elif any(word in query.lower() for word in ["æ€ä¹ˆ", "å¦‚ä½•", "how to", "strategy", "æ”»ç•¥"]):
            if not any(word in rewritten_query.lower() for word in ["guide", "strategy", "æ”»ç•¥"]):
                rewritten_query += " strategy guide"
            intent = "guide"
            confidence = 0.8
        
        # åŸºç¡€BM25ä¼˜åŒ–ï¼šç§»é™¤é€šç”¨è¯æ±‡ï¼Œä¿ç•™æ ¸å¿ƒè¯æ±‡
        bm25_optimized_query = self._basic_bm25_optimization(query)
        
        return UnifiedQueryResult(
            original_query=query,
            detected_language=detected_language,
            translated_query=query,  # åŸºç¡€æ¨¡å¼ä¸ç¿»è¯‘
            rewritten_query=rewritten_query,
            bm25_optimized_query=bm25_optimized_query,  # åŸºç¡€æ¨¡å¼BM25ä¼˜åŒ–
            intent=intent,
            confidence=confidence,
            search_type="hybrid",
            reasoning="åŸºç¡€å¤„ç†æ¨¡å¼ - LLMä¸å¯ç”¨",
            translation_applied=False,
            rewrite_applied=rewritten_query != query,
            processing_time=0.001
        )
    
    def _basic_bm25_optimization(self, query: str) -> str:
        """åŸºç¡€BM25ä¼˜åŒ–ï¼ˆLLMä¸å¯ç”¨æ—¶çš„ç®€å•ç‰ˆæœ¬ï¼‰- ä½¿ç”¨æƒé‡å¢å¼º"""
        
        words = query.lower().split()
        optimized_words = []
        
        # æ¸¸æˆä¸“æœ‰åè¯æŒ‡æ ‡ï¼ˆå¯èƒ½çš„æ¸¸æˆæœ¯è¯­ï¼‰
        game_terms = [
            # é€šç”¨æ¸¸æˆæœ¯è¯­
            'build', 'weapon', 'character', 'boss', 'enemy', 'skill', 'spell', 'item', 'gear',
            'armor', 'shield', 'sword', 'bow', 'staff', 'magic', 'fire', 'ice', 'poison',
            # Helldivers 2 ç›¸å…³
            'warbond', 'stratagem', 'helldiver', 'terminid', 'automaton', 'bile', 'charger',
            # ä¸­æ–‡æ¸¸æˆæœ¯è¯­
            'é…è£…', 'æ­¦å™¨', 'è§’è‰²', 'æŠ€èƒ½', 'è£…å¤‡', 'æŠ¤ç”²', 'æ³•æœ¯', 'é­”æ³•', 'æ•Œäºº', 'é¦–é¢†'
        ]
        
        # ä¸»é¢˜è¯æ±‡ï¼ˆæ ¸å¿ƒæ¦‚å¿µï¼‰
        topic_words = [
            'build', 'weapon', 'character', 'boss', 'strategy', 'guide', 'tip',
            'é…è£…', 'æ­¦å™¨', 'è§’è‰²', 'ç­–ç•¥', 'æ”»ç•¥', 'æŠ€å·§'
        ]
        
        # é€šç”¨è¯æ±‡ï¼ˆé™ä½æƒé‡ï¼Œä½†ä¸åˆ é™¤ï¼‰
        generic_words = [
            'best', 'good', 'great', 'top', 'recommendation', 'guide', 'tutorial', 'help',
            'æœ€å¥½', 'æœ€ä½³', 'æ¨è', 'æ”»ç•¥', 'æ•™ç¨‹', 'å¸®åŠ©'
        ]
        
        for word in words:
            # ä¿ç•™åŸå§‹è¯æ±‡
            optimized_words.append(word)
            
            # å¦‚æœæ˜¯æ¸¸æˆä¸“æœ‰åè¯ï¼Œé‡å¤2-3æ¬¡å¢å¼ºæƒé‡
            if word in game_terms:
                optimized_words.extend([word] * 2)  # é¢å¤–é‡å¤2æ¬¡
                
            # å¦‚æœæ˜¯ä¸»é¢˜è¯æ±‡ï¼Œé‡å¤1æ¬¡å¢å¼ºæƒé‡
            elif word in topic_words:
                optimized_words.append(word)  # é¢å¤–é‡å¤1æ¬¡
                
            # é€šç”¨è¯æ±‡ä¿æŒåŸæ ·ï¼Œä¸å¢å¼ºä¹Ÿä¸åˆ é™¤
        
        # æ ¹æ®æŸ¥è¯¢ç±»å‹æ·»åŠ ç›¸å…³æœ¯è¯­
        query_lower = query.lower()
        
        # å¦‚æœæ˜¯buildç›¸å…³æŸ¥è¯¢ï¼Œæ·»åŠ ç›¸å…³æœ¯è¯­
        if any(term in query_lower for term in ['build', 'setup', 'loadout', 'é…è£…', 'æ­é…']):
            optimized_words.extend(['loadout', 'setup', 'configuration'])
            
        # å¦‚æœæ˜¯weaponç›¸å…³æŸ¥è¯¢ï¼Œæ·»åŠ ç›¸å…³æœ¯è¯­  
        elif any(term in query_lower for term in ['weapon', 'sword', 'gun', 'æ­¦å™¨', 'å‰‘', 'æª']):
            optimized_words.extend(['gear', 'equipment'])
            
        # å¦‚æœæ˜¯characterç›¸å…³æŸ¥è¯¢ï¼Œæ·»åŠ ç›¸å…³æœ¯è¯­
        elif any(term in query_lower for term in ['character', 'class', 'hero', 'è§’è‰²', 'èŒä¸š', 'è‹±é›„']):
            optimized_words.extend(['class', 'hero'])
        
        # æ¸…ç†å¤šä½™ç©ºæ ¼å¹¶è¿”å›
        optimized = " ".join(optimized_words)
        return optimized if optimized.strip() else query
    
    def process_query(self, query: str) -> UnifiedQueryResult:
        """
        ç»Ÿä¸€å¤„ç†æŸ¥è¯¢ï¼šç¿»è¯‘+é‡å†™+æ„å›¾åˆ†æ
        
        Args:
            query: åŸå§‹æŸ¥è¯¢
            
        Returns:
            UnifiedQueryResult: ç»Ÿä¸€å¤„ç†ç»“æœ
        """
        print(f"ğŸ”„ [QUERY-DEBUG] å¼€å§‹ç»Ÿä¸€æŸ¥è¯¢å¤„ç†: '{query}'")
        
        start_time = time.time()
        self.stats["total_queries"] += 1
        
        # æ£€æŸ¥ç¼“å­˜
        cached_result = self._get_cached_result(query)
        if cached_result:
            print(f"ğŸ’¾ [QUERY-DEBUG] ä½¿ç”¨ç¼“å­˜ç»“æœ")
            print(f"   - åŸå§‹æŸ¥è¯¢: '{cached_result.original_query}'")
            print(f"   - ç¿»è¯‘ç»“æœ: '{cached_result.translated_query}'")
            print(f"   - é‡å†™ç»“æœ: '{cached_result.rewritten_query}'")
            print(f"   - BM25ä¼˜åŒ–: '{cached_result.bm25_optimized_query}'")
            print(f"   - æ„å›¾: {cached_result.intent} (ç½®ä¿¡åº¦: {cached_result.confidence:.3f})")
            logger.info(f"ä½¿ç”¨ç¼“å­˜ç»“æœ: {query}")
            return cached_result
        
        # å¦‚æœLLMä¸å¯ç”¨ï¼Œä½¿ç”¨åŸºç¡€å¤„ç†
        if not self.llm_client:
            print(f"âš ï¸ [QUERY-DEBUG] LLMä¸å¯ç”¨ï¼Œä½¿ç”¨åŸºç¡€å¤„ç†")
            result = self._basic_processing(query)
            print(f"   - æ£€æµ‹è¯­è¨€: {result.detected_language}")
            print(f"   - æ„å›¾: {result.intent} (ç½®ä¿¡åº¦: {result.confidence:.3f})")
            print(f"   - é‡å†™æŸ¥è¯¢: '{result.rewritten_query}'")
            print(f"   - BM25ä¼˜åŒ–: '{result.bm25_optimized_query}'")
            print(f"   - é‡å†™åº”ç”¨: {result.rewrite_applied}")
            self._cache_result(query, result)
            return result
        
        try:
            # ä½¿ç”¨LLMè¿›è¡Œç»Ÿä¸€å¤„ç†
            print(f"ğŸ¤– [QUERY-DEBUG] è°ƒç”¨LLMè¿›è¡Œç»Ÿä¸€å¤„ç†")
            prompt = self._create_unified_prompt(query)
            print(f"   - ä½¿ç”¨æ¨¡å‹: {self.llm_config.model}")
            print(f"   - æç¤ºè¯é•¿åº¦: {len(prompt)} å­—ç¬¦")
            
            llm_response = self._call_llm_with_retry(prompt)
            
            if llm_response:
                # è§£æLLMå“åº”
                detected_language = llm_response.get("detected_language", "en")
                translated_query = llm_response.get("translated_query", query)
                rewritten_query = llm_response.get("rewritten_query", translated_query)
                
                processing_time = time.time() - start_time
                
                print(f"âœ… [QUERY-DEBUG] LLMå¤„ç†æˆåŠŸ:")
                print(f"   - æ£€æµ‹è¯­è¨€: {detected_language}")
                print(f"   - ç¿»è¯‘ç»“æœ: '{translated_query}'")
                print(f"   - é‡å†™ç»“æœ: '{rewritten_query}'")
                print(f"   - BM25ä¼˜åŒ–: '{llm_response.get('bm25_optimized_query', rewritten_query)}'")
                print(f"   - æ„å›¾: {llm_response.get('intent', 'guide')} (ç½®ä¿¡åº¦: {llm_response.get('confidence', 0.7):.3f})")
                print(f"   - æœç´¢ç±»å‹: {llm_response.get('search_type', 'hybrid')}")
                print(f"   - å¤„ç†æ—¶é—´: {processing_time:.3f}ç§’")
                print(f"   - æ¨ç†è¿‡ç¨‹: {llm_response.get('reasoning', 'LLMç»Ÿä¸€å¤„ç†')}")
                
                result = UnifiedQueryResult(
                    original_query=query,
                    detected_language=detected_language,
                    translated_query=translated_query,
                    rewritten_query=rewritten_query,
                    bm25_optimized_query=llm_response.get("bm25_optimized_query", rewritten_query), # LLMå¤„ç†ä¸ä¼˜åŒ–
                    intent=llm_response.get("intent", "guide"),
                    confidence=llm_response.get("confidence", 0.7),
                    search_type=llm_response.get("search_type", "hybrid"),
                    reasoning=llm_response.get("reasoning", "LLMç»Ÿä¸€å¤„ç†"),
                    translation_applied=translated_query != query,
                    rewrite_applied=rewritten_query != translated_query,
                    processing_time=processing_time
                )
                
                self.stats["successful_processing"] += 1
                logger.info(f"ç»Ÿä¸€å¤„ç†æˆåŠŸ: '{query}' -> ç¿»è¯‘: '{translated_query}' -> é‡å†™: '{rewritten_query}'")
                
            else:
                # LLMè°ƒç”¨å¤±è´¥ï¼Œä½¿ç”¨åŸºç¡€å¤„ç†
                print(f"âŒ [QUERY-DEBUG] LLMè°ƒç”¨å¤±è´¥ï¼Œä½¿ç”¨åŸºç¡€å¤„ç†")
                result = self._basic_processing(query)
                print(f"   - æ£€æµ‹è¯­è¨€: {result.detected_language}")
                print(f"   - æ„å›¾: {result.intent} (ç½®ä¿¡åº¦: {result.confidence:.3f})")
                print(f"   - é‡å†™æŸ¥è¯¢: '{result.rewritten_query}'")
                print(f"   - BM25ä¼˜åŒ–: '{result.bm25_optimized_query}'")
                print(f"   - é‡å†™åº”ç”¨: {result.rewrite_applied}")
                self.stats["failed_processing"] += 1
                logger.warning(f"LLMç»Ÿä¸€å¤„ç†å¤±è´¥ï¼Œä½¿ç”¨åŸºç¡€å¤„ç†: {query}")
                
        except Exception as e:
            print(f"âŒ [QUERY-DEBUG] ç»Ÿä¸€å¤„ç†å¼‚å¸¸: {e}")
            logger.error(f"ç»Ÿä¸€å¤„ç†å¼‚å¸¸: {e}")
            result = self._basic_processing(query)
            print(f"   - é™çº§åˆ°åŸºç¡€å¤„ç†")
            print(f"   - æ£€æµ‹è¯­è¨€: {result.detected_language}")
            print(f"   - æ„å›¾: {result.intent} (ç½®ä¿¡åº¦: {result.confidence:.3f})")
            print(f"   - é‡å†™æŸ¥è¯¢: '{result.rewritten_query}'")
            print(f"   - BM25ä¼˜åŒ–: '{result.bm25_optimized_query}'")
            self.stats["failed_processing"] += 1
        
        # æ›´æ–°å¹³å‡å¤„ç†æ—¶é—´
        self.stats["average_processing_time"] = (
            (self.stats["average_processing_time"] * (self.stats["total_queries"] - 1) + 
             result.processing_time) / self.stats["total_queries"]
        )
        
        print(f"ğŸ“Š [QUERY-DEBUG] æŸ¥è¯¢å¤„ç†å®Œæˆï¼Œç¼“å­˜ç»“æœ")
        print(f"   - æ€»æŸ¥è¯¢æ•°: {self.stats['total_queries']}")
        print(f"   - ç¼“å­˜å‘½ä¸­æ•°: {self.stats['cache_hits']}")
        print(f"   - æˆåŠŸå¤„ç†æ•°: {self.stats['successful_processing']}")
        print(f"   - å¤±è´¥å¤„ç†æ•°: {self.stats['failed_processing']}")
        
        # ç¼“å­˜ç»“æœ
        self._cache_result(query, result)
        return result
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        return self.stats.copy()
    
    def reset_stats(self):
        """é‡ç½®ç»Ÿè®¡ä¿¡æ¯"""
        self.stats = {
            "total_queries": 0,
            "cache_hits": 0,
            "successful_processing": 0,
            "failed_processing": 0,
            "average_processing_time": 0.0
        }

# å…¨å±€å®ä¾‹
_unified_processor = None

def get_unified_processor(llm_config: Optional[LLMConfig] = None) -> UnifiedQueryProcessor:
    """è·å–ç»Ÿä¸€æŸ¥è¯¢å¤„ç†å™¨çš„å•ä¾‹å®ä¾‹"""
    global _unified_processor
    if _unified_processor is None:
        _unified_processor = UnifiedQueryProcessor(llm_config=llm_config)
    return _unified_processor

def process_query_unified(query: str, llm_config: Optional[LLMConfig] = None) -> UnifiedQueryResult:
    """
    ç»Ÿä¸€å¤„ç†æŸ¥è¯¢çš„ä¾¿æ·å‡½æ•°
    
    Args:
        query: ç”¨æˆ·æŸ¥è¯¢
        llm_config: LLMé…ç½®
        
    Returns:
        UnifiedQueryResult: å¤„ç†ç»“æœ
    """
    processor = get_unified_processor(llm_config)
    return processor.process_query(query) 