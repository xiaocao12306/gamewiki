"""
å¢å¼ºçš„RAGæŸ¥è¯¢æ¥å£ - é›†æˆæ‰¹é‡åµŒå…¥å’Œå‘é‡åº“æ£€ç´¢
============================================

åŠŸèƒ½ï¼š
1. åŠ è½½é¢„æ„å»ºçš„å‘é‡åº“
2. æ‰§è¡Œè¯­ä¹‰æ£€ç´¢
3. æ”¯æŒLLMæŸ¥è¯¢é‡å†™
4. æ··åˆæœç´¢ï¼ˆå‘é‡+BM25ï¼‰
5. è¿”å›ç›¸å…³æ¸¸æˆæ”»ç•¥ä¿¡æ¯
"""

import logging
import asyncio
import json
import numpy as np
from typing import Optional, Dict, Any, List
from pathlib import Path

# å¯¼å…¥æ‰¹é‡åµŒå…¥å¤„ç†å™¨
try:
    from .batch_embedding import BatchEmbeddingProcessor
    BATCH_EMBEDDING_AVAILABLE = True
except ImportError:
    BATCH_EMBEDDING_AVAILABLE = False
    logging.warning("æ‰¹é‡åµŒå…¥æ¨¡å—ä¸å¯ç”¨")

# å‘é‡åº“æ”¯æŒ
try:
    import faiss
    FAISS_AVAILABLE = True
except ImportError:
    FAISS_AVAILABLE = False
    logging.warning("FAISSä¸å¯ç”¨")

try:
    import qdrant_client
    QDRANT_AVAILABLE = True
except ImportError:
    QDRANT_AVAILABLE = False
    logging.warning("Qdrantä¸å¯ç”¨")

# å¯¼å…¥Geminiæ‘˜è¦å™¨
try:
    from .gemini_summarizer import create_gemini_summarizer, SummarizationConfig
    GEMINI_AVAILABLE = True
except ImportError:
    GEMINI_AVAILABLE = False
    logging.warning("Geminiæ‘˜è¦æ¨¡å—ä¸å¯ç”¨")

# å¯¼å…¥æ„å›¾æ„ŸçŸ¥é‡æ’åºå™¨
try:
    from .intent_aware_reranker import IntentAwareReranker
    RERANKER_AVAILABLE = True
except ImportError:
    RERANKER_AVAILABLE = False
    logging.warning("æ„å›¾é‡æ’åºæ¨¡å—ä¸å¯ç”¨")

# å¯¼å…¥é…ç½®å’ŒæŸ¥è¯¢é‡å†™
from ..config import LLMConfig

logger = logging.getLogger(__name__)

def map_window_title_to_game_name(window_title: str) -> Optional[str]:
    """
    å°†çª—å£æ ‡é¢˜æ˜ å°„åˆ°å‘é‡åº“æ–‡ä»¶å
    
    Args:
        window_title: çª—å£æ ‡é¢˜
        
    Returns:
        å¯¹åº”çš„å‘é‡åº“æ–‡ä»¶åï¼ˆä¸åŒ…å«.jsonæ‰©å±•åï¼‰ï¼Œå¦‚æœæœªæ‰¾åˆ°åˆ™è¿”å›None
    """
    # è½¬æ¢ä¸ºå°å†™è¿›è¡ŒåŒ¹é…
    title_lower = window_title.lower()
    
    # çª—å£æ ‡é¢˜åˆ°å‘é‡åº“æ–‡ä»¶åçš„æ˜ å°„ï¼ˆåŸºäºå®é™…å­˜åœ¨çš„å‘é‡åº“æ–‡ä»¶ï¼‰
    title_to_vectordb_mapping = {
        "don't starve together": "dst",
        "don't starve": "dst",
        "é¥¥è’": "dst",
        "helldivers 2": "helldiver2",
        "åœ°ç‹±æ½œå…µ2": "helldiver2",
        "åœ°ç‹±æ½œå…µ": "helldiver2",
        "elden ring": "eldenring",
        "è‰¾å°”ç™»æ³•ç¯": "eldenring",
        "è€å¤´ç¯": "eldenring",
        "civilization vi": "civilization6",
        "civilization 6": "civilization6",
        "æ–‡æ˜6": "civilization6",
        "7 days to die": "7daystodie",
        "ä¸ƒæ—¥æ€": "7daystodie",
    }
    
    # å°è¯•ç²¾ç¡®åŒ¹é…
    for title_key, vectordb_name in title_to_vectordb_mapping.items():
        if title_key in title_lower:
            logger.info(f"çª—å£æ ‡é¢˜ '{window_title}' æ˜ å°„åˆ°å‘é‡åº“ '{vectordb_name}'")
            return vectordb_name
    
    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ˜ å°„ï¼Œè®°å½•è­¦å‘Šå¹¶è¿”å›None
    logger.warning(f"æœªæ‰¾åˆ°çª—å£æ ‡é¢˜ '{window_title}' å¯¹åº”çš„å‘é‡åº“æ˜ å°„")
    return None

class EnhancedRagQuery:
    """å¢å¼ºçš„RAGæŸ¥è¯¢æ¥å£ï¼Œæ”¯æŒå‘é‡åº“æ£€ç´¢å’ŒLLMæŸ¥è¯¢é‡å†™"""
    
    def __init__(self, vector_store_path: Optional[str] = None,
                 enable_hybrid_search: bool = True,
                 hybrid_config: Optional[Dict] = None,
                 llm_config: Optional[LLMConfig] = None,
                 enable_query_rewrite: bool = True,
                 enable_summarization: bool = False,
                 summarization_config: Optional[Dict] = None,
                 enable_intent_reranking: bool = True,
                 reranking_config: Optional[Dict] = None):
        """
        åˆå§‹åŒ–RAGæŸ¥è¯¢å™¨
        
        Args:
            vector_store_path: å‘é‡åº“è·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤è·¯å¾„
            enable_hybrid_search: æ˜¯å¦å¯ç”¨æ··åˆæœç´¢
            hybrid_config: æ··åˆæœç´¢é…ç½®
            llm_config: LLMé…ç½®
            enable_query_rewrite: æ˜¯å¦å¯ç”¨æŸ¥è¯¢é‡å†™
            enable_summarization: æ˜¯å¦å¯ç”¨Geminiæ‘˜è¦
            summarization_config: æ‘˜è¦é…ç½®
            enable_intent_reranking: æ˜¯å¦å¯ç”¨æ„å›¾æ„ŸçŸ¥é‡æ’åº
            reranking_config: é‡æ’åºé…ç½®
        """
        self.is_initialized = False
        self.vector_store_path = vector_store_path
        self.vector_store = None
        self.metadata = None
        self.config = None
        self.processor = None
        self.enable_hybrid_search = enable_hybrid_search
        self.hybrid_config = hybrid_config or {
            "fusion_method": "rrf",
            "vector_weight": 0.3,
            "bm25_weight": 0.7,
            "rrf_k": 60
        }
        self.llm_config = llm_config
        self.enable_query_rewrite = enable_query_rewrite
        self.hybrid_retriever = None
        
        # æ‘˜è¦é…ç½®
        self.enable_summarization = enable_summarization and GEMINI_AVAILABLE
        self.summarization_config = summarization_config or {}
        self.summarizer = None
        
        # æ„å›¾é‡æ’åºé…ç½®
        self.enable_intent_reranking = enable_intent_reranking and RERANKER_AVAILABLE
        self.reranking_config = reranking_config or {
            "intent_weight": 0.4,
            "semantic_weight": 0.6
        }
        self.reranker = None
        
        # åˆå§‹åŒ–æ‘˜è¦å™¨
        if self.enable_summarization:
            self._initialize_summarizer()
            
        # åˆå§‹åŒ–é‡æ’åºå™¨
        if self.enable_intent_reranking:
            self._initialize_reranker()
        
    async def initialize(self, game_name: Optional[str] = None):
        """
        åˆå§‹åŒ–RAGç³»ç»Ÿ
        
        Args:
            game_name: æ¸¸æˆåç§°ï¼Œç”¨äºè‡ªåŠ¨æŸ¥æ‰¾å‘é‡åº“
        """
        try:
            logger.info("åˆå§‹åŒ–å¢å¼ºRAGç³»ç»Ÿ...")
            
            if not BATCH_EMBEDDING_AVAILABLE:
                logger.warning("æ‰¹é‡åµŒå…¥æ¨¡å—ä¸å¯ç”¨ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼")
                self.is_initialized = True
                return
            
            # ç¡®å®šå‘é‡åº“è·¯å¾„
            if self.vector_store_path is None and game_name:
                # è‡ªåŠ¨æŸ¥æ‰¾å‘é‡åº“ - ä½¿ç”¨ç»å¯¹è·¯å¾„
                import os
                current_dir = Path(__file__).parent
                vector_dir = current_dir / "vectorstore"
                
                logger.info(f"æŸ¥æ‰¾å‘é‡åº“ç›®å½•: {vector_dir}")
                config_files = list(vector_dir.glob(f"{game_name}_vectors_config.json"))
                
                if config_files:
                    self.vector_store_path = str(config_files[0])
                    logger.info(f"æ‰¾åˆ°å‘é‡åº“é…ç½®: {self.vector_store_path}")
                else:
                    logger.warning(f"æœªæ‰¾åˆ°æ¸¸æˆ {game_name} çš„å‘é‡åº“ï¼Œæœç´¢è·¯å¾„: {vector_dir}")
                    logger.warning(f"æŸ¥æ‰¾æ¨¡å¼: {game_name}_vectors_config.json")
                    # åˆ—å‡ºç°æœ‰çš„æ–‡ä»¶ç”¨äºè°ƒè¯•
                    try:
                        existing_files = list(vector_dir.glob("*_vectors_config.json"))
                        logger.info(f"ç°æœ‰çš„å‘é‡åº“é…ç½®æ–‡ä»¶: {[f.name for f in existing_files]}")
                    except Exception as e:
                        logger.error(f"åˆ—å‡ºç°æœ‰æ–‡ä»¶å¤±è´¥: {e}")
                    # ä¸ç«‹å³è¿”å›ï¼Œè®©åç»­ä»£ç å¤„ç†è¿™ç§æƒ…å†µ
                    self.vector_store_path = None
            
            if self.vector_store_path and Path(self.vector_store_path).exists():
                # åŠ è½½å‘é‡åº“
                self.processor = BatchEmbeddingProcessor()
                self.vector_store = self.processor.load_vector_store(self.vector_store_path)
                
                # åŠ è½½é…ç½®å’Œå…ƒæ•°æ®
                with open(self.vector_store_path, 'r', encoding='utf-8') as f:
                    self.config = json.load(f)
                
                if self.config["vector_store_type"] == "faiss":
                    self.metadata = self.vector_store["metadata"]
                
                logger.info(f"å‘é‡åº“åŠ è½½å®Œæˆ: {self.config['chunk_count']} ä¸ªçŸ¥è¯†å—")
                
                # åˆå§‹åŒ–æ··åˆæ£€ç´¢å™¨
                if self.enable_hybrid_search:
                    self._initialize_hybrid_retriever()
                    
            else:
                logger.warning("å‘é‡åº“ä¸å¯ç”¨ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼")
            
            self.is_initialized = True
            logger.info("å¢å¼ºRAGç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            logger.error(f"RAGç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}")
            self.is_initialized = False
    
    def _initialize_hybrid_retriever(self):
        """åˆå§‹åŒ–æ··åˆæ£€ç´¢å™¨"""
        if not self.config or not self.config.get("hybrid_search_enabled", False):
            logger.warning("æ··åˆæœç´¢æœªå¯ç”¨ï¼Œå°†ä»…ä½¿ç”¨å‘é‡æœç´¢")
            return
        
        try:
            from .hybrid_retriever import HybridSearchRetriever, VectorRetrieverAdapter
            
            bm25_index_path = self.config.get("bm25_index_path")
            if not bm25_index_path:
                logger.warning("BM25ç´¢å¼•è·¯å¾„æœªæ‰¾åˆ°ï¼Œå°†ä»…ä½¿ç”¨å‘é‡æœç´¢")
                return
            
            # æ£€æŸ¥BM25ç´¢å¼•æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            from pathlib import Path
            if not Path(bm25_index_path).exists():
                logger.warning(f"BM25ç´¢å¼•æ–‡ä»¶ä¸å­˜åœ¨: {bm25_index_path}ï¼Œå°†ä»…ä½¿ç”¨å‘é‡æœç´¢")
                return
            
            # åˆ›å»ºå‘é‡æ£€ç´¢å™¨é€‚é…å™¨
            vector_retriever = VectorRetrieverAdapter(self)
            
            # åˆ›å»ºæ··åˆæ£€ç´¢å™¨ - é»˜è®¤å¯ç”¨ç»Ÿä¸€å¤„ç†ä»¥æé«˜æ€§èƒ½
            self.hybrid_retriever = HybridSearchRetriever(
                vector_retriever=vector_retriever,
                bm25_index_path=bm25_index_path,
                fusion_method=self.hybrid_config.get("fusion_method", "rrf"),
                vector_weight=self.hybrid_config.get("vector_weight", 0.3),
                bm25_weight=self.hybrid_config.get("bm25_weight", 0.7),
                rrf_k=self.hybrid_config.get("rrf_k", 60),
                llm_config=self.llm_config,
                enable_unified_processing=True,  # å¯ç”¨ç»Ÿä¸€å¤„ç†ä»¥æé«˜æ€§èƒ½
                enable_query_rewrite=self.enable_query_rewrite,
                enable_query_translation=self.enable_summarization and self.enable_query_rewrite  # ä»…åœ¨ç»Ÿä¸€å¤„ç†ç¦ç”¨æ—¶ä½¿ç”¨
            )
            
            logger.info("æ··åˆæ£€ç´¢å™¨åˆå§‹åŒ–æˆåŠŸï¼ˆç»Ÿä¸€å¤„ç†æ¨¡å¼ï¼‰")
            
        except Exception as e:
            logger.error(f"æ··åˆæ£€ç´¢å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            logger.info("å°†å›é€€åˆ°ä»…ä½¿ç”¨å‘é‡æœç´¢æ¨¡å¼")
    
    def _initialize_summarizer(self):
        """åˆå§‹åŒ–Geminiæ‘˜è¦å™¨"""
        try:
            import os
            
            # è·å–APIå¯†é’¥
            api_key = self.summarization_config.get("api_key") or os.environ.get("GEMINI_API_KEY")
            if not api_key:
                logger.warning("æœªæ‰¾åˆ°Gemini APIå¯†é’¥ï¼Œæ‘˜è¦åŠŸèƒ½å°†è¢«ç¦ç”¨")
                self.enable_summarization = False
                return
            
            # åˆ›å»ºæ‘˜è¦é…ç½®
            config = SummarizationConfig(
                api_key=api_key,
                model_name=self.summarization_config.get("model_name", "gemini-2.5-flash-lite-preview-06-17"),
                max_summary_length=self.summarization_config.get("max_summary_length", 300),
                temperature=self.summarization_config.get("temperature", 0.3),
                include_sources=self.summarization_config.get("include_sources", True),
                language=self.summarization_config.get("language", "auto")
            )
            
            # åˆ›å»ºæ‘˜è¦å™¨
            self.summarizer = create_gemini_summarizer(
                api_key=api_key,
                model_name=config.model_name,
                max_summary_length=config.max_summary_length,
                temperature=config.temperature,
                include_sources=config.include_sources,
                language=config.language
            )
            
            logger.info(f"Geminiæ‘˜è¦å™¨åˆå§‹åŒ–æˆåŠŸ: {config.model_name}")
            
        except Exception as e:
            logger.error(f"Geminiæ‘˜è¦å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            self.enable_summarization = False
    
    def _initialize_reranker(self):
        """åˆå§‹åŒ–æ„å›¾æ„ŸçŸ¥é‡æ’åºå™¨"""
        try:
            self.reranker = IntentAwareReranker()
            logger.info("æ„å›¾æ„ŸçŸ¥é‡æ’åºå™¨åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.error(f"æ„å›¾é‡æ’åºå™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            self.enable_intent_reranking = False
    
    def _search_faiss(self, query: str, top_k: int = 3) -> List[Dict[str, Any]]:
        """
        ä½¿ç”¨FAISSè¿›è¡Œå‘é‡æ£€ç´¢
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            top_k: è¿”å›ç»“æœæ•°é‡
            
        Returns:
            æ£€ç´¢ç»“æœåˆ—è¡¨
        """
        if not self.vector_store or not self.metadata:
            return []
        
        try:
            # è·å–æŸ¥è¯¢å‘é‡
            query_text = self.processor.build_text({"topic": query, "summary": query, "keywords": []})
            query_vectors = self.processor.embed_batch([query_text])
            query_vector = np.array(query_vectors[0], dtype=np.float32).reshape(1, -1)
            
            # æ„å»ºæ­£ç¡®çš„ç´¢å¼•æ–‡ä»¶è·¯å¾„
            # ä½¿ç”¨ä¸BatchEmbeddingProcessor._load_faiss_storeç›¸åŒçš„è·¯å¾„é€»è¾‘
            index_path_str = self.config["index_path"]
            if not Path(index_path_str).is_absolute():
                # ä½¿ç”¨å‘é‡åº“å­˜å‚¨è·¯å¾„æ¥æ„å»ºç»å¯¹è·¯å¾„
                current_dir = Path(__file__).parent
                index_path = current_dir / "vectorstore" / Path(index_path_str).name
            else:
                index_path = Path(index_path_str)
            
            index_file_path = index_path / "index.faiss"
            logger.info(f"å°è¯•åŠ è½½FAISSç´¢å¼•æ–‡ä»¶: {index_file_path}")
            
            if not index_file_path.exists():
                logger.error(f"FAISSç´¢å¼•æ–‡ä»¶ä¸å­˜åœ¨: {index_file_path}")
                return []
            
            # åŠ è½½FAISSç´¢å¼•
            index = faiss.read_index(str(index_file_path))
            
            # æ‰§è¡Œæ£€ç´¢
            scores, indices = index.search(query_vector, top_k)
            
            # è¿”å›ç»“æœ
            results = []
            for i, (score, idx) in enumerate(zip(scores[0], indices[0])):
                if idx < len(self.metadata):
                    chunk = self.metadata[idx]
                    results.append({
                        "chunk": chunk,
                        "score": float(score),
                        "rank": i + 1
                    })
            
            logger.info(f"FAISSæ£€ç´¢å®Œæˆï¼Œæ‰¾åˆ° {len(results)} ä¸ªç»“æœ")
            return results
            
        except Exception as e:
            logger.error(f"FAISSæ£€ç´¢å¤±è´¥: {e}")
            return []
    
    def _search_qdrant(self, query: str, top_k: int = 3) -> List[Dict[str, Any]]:
        """
        ä½¿ç”¨Qdrantè¿›è¡Œå‘é‡æ£€ç´¢
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            top_k: è¿”å›ç»“æœæ•°é‡
            
        Returns:
            æ£€ç´¢ç»“æœåˆ—è¡¨
        """
        if not self.vector_store or not QDRANT_AVAILABLE:
            return []
        
        try:
            # è·å–æŸ¥è¯¢å‘é‡
            query_text = self.processor.build_text({"topic": query, "summary": query, "keywords": []})
            query_vectors = self.processor.embed_batch([query_text])
            
            # æ‰§è¡Œæ£€ç´¢
            results = self.vector_store.search(
                collection_name=self.config["collection_name"],
                query_vector=query_vectors[0],
                limit=top_k
            )
            
            # æ ¼å¼åŒ–ç»“æœ
            formatted_results = []
            for i, result in enumerate(results):
                formatted_results.append({
                    "chunk": result.payload,
                    "score": result.score,
                    "rank": i + 1
                })
            
            return formatted_results
            
        except Exception as e:
            logger.error(f"Qdrantæ£€ç´¢å¤±è´¥: {e}")
            return []
    
    def _search_hybrid(self, query: str, top_k: int = 3) -> Dict[str, Any]:
        """
        ä½¿ç”¨æ··åˆæœç´¢è¿›è¡Œæ£€ç´¢
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            top_k: è¿”å›ç»“æœæ•°é‡
            
        Returns:
            æ··åˆæœç´¢ç»“æœï¼ˆåŒ…å«å…ƒæ•°æ®ï¼‰
        """
        if not self.hybrid_retriever:
            logger.warning("æ··åˆæ£€ç´¢å™¨æœªåˆå§‹åŒ–ï¼Œå›é€€åˆ°å‘é‡æœç´¢")
            results = self._search_faiss(query, top_k) if self.config["vector_store_type"] == "faiss" else self._search_qdrant(query, top_k)
            return {
                "results": results,
                "query": {"original": query, "rewritten": query, "rewrite_applied": False},
                "metadata": {
                    "total_results": len(results),
                    "search_type": "vector_fallback",
                    "fusion_method": "none",
                    "rewrite_info": {
                        "intent": "unknown",
                        "confidence": 0.0,
                        "reasoning": "æ··åˆæ£€ç´¢å™¨æœªåˆå§‹åŒ–"
                    }
                }
            }
        
        # æ‰§è¡Œæ··åˆæœç´¢
        try:
            search_response = self.hybrid_retriever.search(query, top_k)
            logger.info(f"æ··åˆæœç´¢å®Œæˆï¼Œæ‰¾åˆ° {len(search_response.get('results', []))} ä¸ªç»“æœ")
            return search_response
        except Exception as e:
            logger.error(f"æ··åˆæœç´¢å¤±è´¥: {e}")
            # å›é€€åˆ°å‘é‡æœç´¢
            results = self._search_faiss(query, top_k) if self.config["vector_store_type"] == "faiss" else self._search_qdrant(query, top_k)
            return {
                "results": results,
                "query": {"original": query, "rewritten": query, "rewrite_applied": False},
                "metadata": {
                    "total_results": len(results),
                    "search_type": "vector_fallback",
                    "fusion_method": "none",
                    "rewrite_info": {
                        "intent": "unknown",
                        "confidence": 0.0,
                        "reasoning": f"æ··åˆæœç´¢å¤±è´¥: {str(e)}"
                    }
                }
            }
    
    def _format_answer(self, search_response: Dict[str, Any], question: str) -> str:
        """
        æ ¼å¼åŒ–æ£€ç´¢ç»“æœä¸ºç­”æ¡ˆ
        
        Args:
            search_response: æœç´¢å“åº”ï¼ˆåŒ…å«resultså’Œmetadataï¼‰
            question: åŸå§‹é—®é¢˜
            
        Returns:
            æ ¼å¼åŒ–çš„ç­”æ¡ˆ
        """
        results = search_response.get("results", [])
        metadata = search_response.get("metadata", {})
        query_info = search_response.get("query", {})
        
        if not results:
            return f"æŠ±æ­‰ï¼Œæ²¡æœ‰æ‰¾åˆ°å…³äº'{question}'çš„ç›¸å…³ä¿¡æ¯ã€‚"
        
        # æ„å»ºç­”æ¡ˆ
        answer_parts = [f"å…³äº'{question}'çš„æ”»ç•¥ä¿¡æ¯ï¼š\n"]
        
        # å¦‚æœæŸ¥è¯¢è¢«ç¿»è¯‘ï¼Œæ˜¾ç¤ºç¿»è¯‘ä¿¡æ¯
        if query_info.get("translation_applied", False):
            translation_info = metadata.get("translation_info", {})
            translated_query = translation_info.get("translated_query", "")
            if translated_query:
                answer_parts.append(f"æŸ¥è¯¢ç¿»è¯‘: '{question}' -> '{translated_query}'")
        
        # å¦‚æœæŸ¥è¯¢è¢«é‡å†™ï¼Œæ˜¾ç¤ºç›¸å…³ä¿¡æ¯
        if query_info.get("rewrite_applied", False):
            rewrite_info = metadata.get("rewrite_info", {})
            answer_parts.append(f"æ„å›¾åˆ†æ: {rewrite_info.get('intent', 'unknown')}")
            answer_parts.append(f"æŸ¥è¯¢ä¼˜åŒ–: {rewrite_info.get('reasoning', 'æœªçŸ¥')}")
        
        # å¦‚æœæœ‰ç¿»è¯‘æˆ–é‡å†™ä¿¡æ¯ï¼Œæ·»åŠ ç©ºè¡Œ
        if query_info.get("translation_applied", False) or query_info.get("rewrite_applied", False):
            answer_parts.append("")
        
        for result in results:
            chunk = result["chunk"]
            score = result["score"]
            
            # æå–å…³é”®ä¿¡æ¯
            topic = chunk.get("topic", "æœªçŸ¥ä¸»é¢˜")
            summary = chunk.get("summary", "")
            
            answer_parts.append(f"\nã€{topic}ã€‘")
            
            # æ˜¾ç¤ºåˆ†æ•°ä¿¡æ¯ï¼ˆåŒºåˆ†æ··åˆæœç´¢å’Œå•ä¸€æœç´¢ï¼‰
            if "fusion_method" in result:
                # æ··åˆæœç´¢ç»“æœ
                fusion_method = result.get("fusion_method", "unknown")
                vector_score = result.get("vector_score", 0)
                bm25_score = result.get("bm25_score", 0)
                answer_parts.append(f"ç›¸å…³åº¦: {score:.3f}")
                if vector_score > 0 and bm25_score > 0:
                    answer_parts.append(f"(è¯­ä¹‰åŒ¹é…: {vector_score:.3f} | å…³é”®è¯åŒ¹é…: {bm25_score:.3f})")
            else:
                # å•ä¸€æœç´¢ç»“æœ
                answer_parts.append(f"ç›¸å…³åº¦: {score:.3f}")
            
            answer_parts.append(f"{summary}")
            
            # å¦‚æœæœ‰buildä¿¡æ¯ï¼Œæ·»åŠ é…è£…å»ºè®®
            if "build" in chunk:
                build = chunk["build"]
                if "name" in build:
                    answer_parts.append(f"\næ¨èé…è£…: {build['name']}")
                if "focus" in build:
                    answer_parts.append(f"é…è£…é‡ç‚¹: {build['focus']}")
                
                # æ·»åŠ å…³é”®è£…å¤‡ä¿¡æ¯
                if "stratagems" in build:
                    stratagems = [s["name"] for s in build["stratagems"]]
                    answer_parts.append(f"æ ¸å¿ƒè£…å¤‡: {', '.join(stratagems[:3])}")
        
        return "\n".join(answer_parts)
    
    async def _format_answer_with_summary(self, search_response: Dict[str, Any], question: str) -> str:
        """
        ä½¿ç”¨Geminiæ‘˜è¦å™¨æ ¼å¼åŒ–æ£€ç´¢ç»“æœ
        
        Args:
            search_response: æœç´¢å“åº”ï¼ˆåŒ…å«resultså’Œmetadataï¼‰
            question: åŸå§‹é—®é¢˜
            
        Returns:
            æ‘˜è¦åçš„ç­”æ¡ˆ
        """
        results = search_response.get("results", [])
        
        if not results:
            return "ğŸ˜” æŠ±æ­‰ï¼Œæˆ‘æ²¡æœ‰æ‰¾åˆ°ç›¸å…³çš„æ¸¸æˆæ”»ç•¥ä¿¡æ¯ã€‚å¯ä»¥è¯•è¯•æ¢ä¸ªå…³é”®è¯é—®æˆ‘å“¦ï¼"
        
        try:
            # å‡†å¤‡çŸ¥è¯†å—æ•°æ®
            chunks = []
            for result in results:
                chunk_data = result["chunk"]
                chunks.append({
                    "topic": chunk_data.get("topic", "æœªçŸ¥ä¸»é¢˜"),
                    "summary": chunk_data.get("summary", ""),
                    "keywords": chunk_data.get("keywords", []),
                    "score": result.get("score", 0),
                    "content": chunk_data.get("summary", "")
                })
            
            # è·å–æ¸¸æˆä¸Šä¸‹æ–‡
            game_context = None
            if hasattr(self, 'config') and self.config:
                game_context = self.config.get("game_name", None)
            
            # è°ƒç”¨æ‘˜è¦å™¨ç”Ÿæˆå¯¹è¯å¼å›å¤
            summary_result = self.summarizer.summarize_chunks(
                chunks=chunks,
                query=question,
                context=game_context
            )
            
            # ç›´æ¥è¿”å›æ‘˜è¦å†…å®¹ï¼ˆå¯¹è¯å¼æ ¼å¼ï¼‰
            return summary_result["summary"]
            
        except Exception as e:
            logger.error(f"æ‘˜è¦ç”Ÿæˆå¤±è´¥: {e}")
            # å›é€€åˆ°å‹å¥½çš„é”™è¯¯æ¶ˆæ¯
            return "ğŸ˜… æŠ±æ­‰ï¼Œæˆ‘åœ¨æ•´ç†ä¿¡æ¯æ—¶é‡åˆ°äº†ä¸€ç‚¹é—®é¢˜ã€‚è®©æˆ‘ç”¨ç®€å•çš„æ–¹å¼å›ç­”ä½ ï¼š\n\n" + self._format_simple_answer(results)
    
    def _format_simple_answer(self, results: List[Dict[str, Any]]) -> str:
        """ç®€å•æ ¼å¼åŒ–ç­”æ¡ˆï¼ˆç”¨äºæ‘˜è¦å¤±è´¥æ—¶çš„é™çº§ï¼‰"""
        if not results:
            return "æ²¡æœ‰æ‰¾åˆ°ç›¸å…³ä¿¡æ¯ã€‚"
        
        # åªå–æœ€ç›¸å…³çš„ç»“æœ
        top_result = results[0]
        chunk = top_result.get("chunk", top_result)
        
        topic = chunk.get("topic", "")
        summary = chunk.get("summary", "")
        
        return f"æ ¹æ®{topic}ï¼š\n{summary}"
    
    async def query(self, question: str, top_k: int = 3) -> Dict[str, Any]:
        """
        æ‰§è¡ŒRAGæŸ¥è¯¢
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            top_k: æ£€ç´¢ç»“æœæ•°é‡
            
        Returns:
            åŒ…å«ç­”æ¡ˆçš„å­—å…¸
        """
        if not self.is_initialized:
            await self.initialize()
        
        try:
            logger.info(f"RAGæŸ¥è¯¢: {question}")
            start_time = asyncio.get_event_loop().time()
            
            # æ‰§è¡Œæ£€ç´¢
            if self.vector_store and self.config:
                # é€‰æ‹©æœç´¢æ–¹å¼
                if self.enable_hybrid_search and self.hybrid_retriever:
                    search_response = self._search_hybrid(question, top_k)
                    results = search_response.get("results", [])
                    
                    # åº”ç”¨æ„å›¾æ„ŸçŸ¥é‡æ’åº
                    if self.enable_intent_reranking and self.reranker and results:
                        logger.info("åº”ç”¨æ„å›¾æ„ŸçŸ¥é‡æ’åº")
                        results = self.reranker.rerank_results(
                            results, 
                            question,
                            intent_weight=self.reranking_config.get("intent_weight", 0.4),
                            semantic_weight=self.reranking_config.get("semantic_weight", 0.6)
                        )
                        search_response["results"] = results
                        # åœ¨å…ƒæ•°æ®ä¸­è®°å½•é‡æ’åºä¿¡æ¯
                        search_response.setdefault("metadata", {})["reranking_applied"] = True
                    
                    # æ ¼å¼åŒ–ç­”æ¡ˆï¼ˆä½¿ç”¨æ‘˜è¦æˆ–åŸå§‹æ ¼å¼ï¼‰
                    if self.enable_summarization and self.summarizer and len(results) > 1:
                        answer = await self._format_answer_with_summary(search_response, question)
                    else:
                        answer = self._format_answer(search_response, question)
                    
                    confidence = max([r["score"] for r in results]) if results else 0.0
                    sources = [r["chunk"].get("topic", "æœªçŸ¥") for r in results]
                    
                    # æ·»åŠ æœç´¢å…ƒæ•°æ®
                    search_metadata = search_response.get("metadata", {})
                    
                else:
                    # å•ä¸€æœç´¢
                    if self.config["vector_store_type"] == "faiss":
                        results = self._search_faiss(question, top_k)
                    else:
                        results = self._search_qdrant(question, top_k)
                    
                    # åº”ç”¨æ„å›¾æ„ŸçŸ¥é‡æ’åº
                    if self.enable_intent_reranking and self.reranker and results:
                        logger.info("åº”ç”¨æ„å›¾æ„ŸçŸ¥é‡æ’åºï¼ˆå•ä¸€æœç´¢æ¨¡å¼ï¼‰")
                        results = self.reranker.rerank_results(
                            results, 
                            question,
                            intent_weight=self.reranking_config.get("intent_weight", 0.4),
                            semantic_weight=self.reranking_config.get("semantic_weight", 0.6)
                        )
                    
                    # æ„å»ºå…¼å®¹çš„search_responseæ ¼å¼
                    search_response = {
                        "results": results,
                        "query": {"original": question, "rewritten": question, "rewrite_applied": False},
                        "metadata": {
                            "total_results": len(results),
                            "search_type": "vector_only",
                            "fusion_method": "none",
                            "rewrite_info": {
                                "intent": "unknown",
                                "confidence": 0.0,
                                "reasoning": "æœªä½¿ç”¨æŸ¥è¯¢é‡å†™"
                            },
                            "reranking_applied": self.enable_intent_reranking and self.reranker is not None
                        }
                    }
                    
                    # æ ¼å¼åŒ–ç­”æ¡ˆï¼ˆä½¿ç”¨æ‘˜è¦æˆ–åŸå§‹æ ¼å¼ï¼‰
                    if self.enable_summarization and self.summarizer and len(results) > 1:
                        answer = await self._format_answer_with_summary(search_response, question)
                    else:
                        answer = self._format_answer(search_response, question)
                    
                    confidence = max([r["score"] for r in results]) if results else 0.0
                    sources = [r["chunk"].get("topic", "æœªçŸ¥") for r in results]
                    search_metadata = search_response.get("metadata", {})
                
            else:
                # æ£€æŸ¥æ˜¯å¦æ˜¯å› ä¸ºå‘é‡åº“ä¸å­˜åœ¨
                if hasattr(self, 'vector_store_path') and self.vector_store_path is None:
                    # æ²¡æœ‰æ‰¾åˆ°å¯¹åº”çš„å‘é‡åº“
                    return {
                        "answer": "æŠ±æ­‰ï¼Œæš‚æ—¶æ²¡æœ‰æ‰¾åˆ°è¯¥æ¸¸æˆçš„æ”»ç•¥æ•°æ®åº“ã€‚\n\nç›®å‰æ”¯æŒæ”»ç•¥æŸ¥è¯¢çš„æ¸¸æˆï¼š\nâ€¢ åœ°ç‹±æ½œå…µ2 - å¯ä»¥è¯¢é—®æ­¦å™¨é…è£…ã€æ•Œäººæ”»ç•¥ç­‰\nâ€¢ è‰¾å°”ç™»æ³•ç¯ - å¯ä»¥è¯¢é—®Bossæ”»ç•¥ã€è£…å¤‡æ¨èç­‰\nâ€¢ é¥¥è’è”æœºç‰ˆ - å¯ä»¥è¯¢é—®ç”Ÿå­˜æŠ€å·§ã€è§’è‰²æ”»ç•¥ç­‰\nâ€¢ æ–‡æ˜6 - å¯ä»¥è¯¢é—®æ–‡æ˜ç‰¹è‰²ã€èƒœåˆ©ç­–ç•¥ç­‰\nâ€¢ ä¸ƒæ—¥æ€ - å¯ä»¥è¯¢é—®å»ºç­‘ã€æ­¦å™¨åˆ¶ä½œç­‰",
                        "sources": [],
                        "confidence": 0.0,
                        "query_time": 0.0,
                        "results_count": 0,
                        "error": "VECTOR_STORE_NOT_FOUND"
                    }
                else:
                    # å…¶ä»–æƒ…å†µï¼Œå›é€€åˆ°æ¨¡æ‹Ÿæ¨¡å¼
                    await asyncio.sleep(0.5)
                    answer = self._get_mock_answer(question)
                    confidence = 0.8
                    sources = ["æ¨¡æ‹ŸçŸ¥è¯†åº“"]
                    search_metadata = {"search_type": "mock"}
            
            query_time = asyncio.get_event_loop().time() - start_time
            
            response = {
                "answer": answer,
                "sources": sources,
                "confidence": confidence,
                "query_time": query_time,
                "results_count": len(results) if 'results' in locals() else 0
            }
            
            # æ·»åŠ æœç´¢å…ƒæ•°æ®
            if 'search_metadata' in locals():
                response["search_metadata"] = search_metadata
            
            return response
            
        except Exception as e:
            logger.error(f"RAGæŸ¥è¯¢å¤±è´¥: {e}")
            return {
                "answer": "æŠ±æ­‰ï¼ŒæŸ¥è¯¢è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼Œè¯·ç¨åé‡è¯•ã€‚",
                "sources": [],
                "confidence": 0.0,
                "query_time": 0.0,
                "error": str(e)
            }
    
    def _get_mock_answer(self, question: str) -> str:
        """è·å–æ¨¡æ‹Ÿç­”æ¡ˆï¼ˆç”¨äºæµ‹è¯•ï¼‰"""
        question_lower = question.lower()
        
        if "å¥½æ„Ÿåº¦" in question_lower or "å…³ç³»" in question_lower:
            return """æå‡å¥½æ„Ÿåº¦çš„æ–¹æ³•ï¼š
1. é€ç¤¼ç‰©ï¼šæ¯ä¸ªè§’è‰²éƒ½æœ‰å–œæ¬¢çš„ç¤¼ç‰©ï¼Œé€å¯¹ç¤¼ç‰©èƒ½å¿«é€Ÿæå‡å¥½æ„Ÿåº¦
2. å¯¹è¯ï¼šæ¯å¤©ä¸è§’è‰²å¯¹è¯
3. å‚åŠ èŠ‚æ—¥æ´»åŠ¨
4. å®Œæˆè§’è‰²ä»»åŠ¡

å»ºè®®ï¼šè‰¾ç±³ä¸½å–œæ¬¢ç¾Šæ¯›ã€å¸ƒæ–™ç­‰æ‰‹å·¥åˆ¶å“ï¼›è°¢æ©å–œæ¬¢å•¤é…’å’ŒæŠ«è¨ã€‚"""
        
        elif "èµšé’±" in question_lower or "æ”¶å…¥" in question_lower:
            return """èµšé’±æ”»ç•¥ï¼š
1. ç§æ¤é«˜ä»·å€¼ä½œç‰©ï¼šè‰è“ã€è“è“ã€è”“è¶Šè“
2. å…»æ®–åŠ¨ç‰©ï¼šé¸¡ã€ç‰›ã€ç¾Š
3. é’“é±¼ï¼šä¸åŒå­£èŠ‚æœ‰ä¸åŒé±¼ç±»
4. æŒ–çŸ¿ï¼šè·å¾—å®çŸ³å’ŒçŸ¿çŸ³
5. åˆ¶ä½œæ‰‹å·¥è‰ºå“ï¼šæœé…±ã€å¥¶é…ªç­‰

æœ€ä½³ç­–ç•¥ï¼šæ˜¥å­£ç§æ¤è‰è“ï¼Œå¤å­£ç§æ¤è“è“ï¼Œç§‹å­£ç§æ¤è”“è¶Šè“ã€‚"""
        
        elif "æ–°æ‰‹" in question_lower or "å…¥é—¨" in question_lower:
            return """æ–°æ‰‹å…¥é—¨æŒ‡å—ï¼š
1. ç¬¬ä¸€å‘¨ï¼šæ¸…ç†å†œåœºï¼Œç§æ¤é˜²é£è‰
2. ç¬¬äºŒå‘¨ï¼šå»ºé€ é¸¡èˆï¼Œå¼€å§‹å…»æ®–
3. ç¬¬ä¸‰å‘¨ï¼šå‡çº§å·¥å…·ï¼Œæ‰©å¤§ç§æ¤
4. ç¬¬å››å‘¨ï¼šå‚åŠ æ˜¥å­£èŠ‚æ—¥

é‡ç‚¹ï¼šä¼˜å…ˆå‡çº§æ°´å£¶å’Œé”„å¤´ï¼Œå¤šä¸æ‘æ°‘äº’åŠ¨ã€‚"""
        
        else:
            return f"å…³äº'{question}'çš„æ”»ç•¥ï¼š\n\nè¿™æ˜¯ä¸€ä¸ªé€šç”¨çš„æ¸¸æˆæ”»ç•¥å»ºè®®ã€‚å»ºè®®æ‚¨å°è¯•ä¸åŒçš„æ¸¸æˆç­–ç•¥ï¼Œæ¢ç´¢æ¸¸æˆä¸­çš„å„ç§å¯èƒ½æ€§ã€‚è®°ä½ï¼Œæ¯ä¸ªç©å®¶éƒ½æœ‰è‡ªå·±ç‹¬ç‰¹çš„æ¸¸æˆé£æ ¼ï¼"


# å…¨å±€å®ä¾‹
_enhanced_rag_query = None

def get_enhanced_rag_query(vector_store_path: Optional[str] = None,
                          llm_config: Optional[LLMConfig] = None) -> EnhancedRagQuery:
    """è·å–å¢å¼ºRAGæŸ¥è¯¢å™¨çš„å•ä¾‹å®ä¾‹"""
    global _enhanced_rag_query
    if _enhanced_rag_query is None:
        _enhanced_rag_query = EnhancedRagQuery(
            vector_store_path=vector_store_path,
            llm_config=llm_config
        )
    return _enhanced_rag_query

async def query_enhanced_rag(question: str, 
                           game_name: Optional[str] = None,
                           top_k: int = 3,
                           enable_hybrid_search: bool = True,
                           hybrid_config: Optional[Dict] = None,
                           llm_config: Optional[LLMConfig] = None,
                           enable_summarization: bool = False,
                           summarization_config: Optional[Dict] = None,
                           enable_intent_reranking: bool = None,
                           reranking_config: Optional[Dict] = None) -> Dict[str, Any]:
    """
    æ‰§è¡Œå¢å¼ºRAGæŸ¥è¯¢çš„ä¾¿æ·å‡½æ•°
    
    Args:
        question: ç”¨æˆ·é—®é¢˜
        game_name: æ¸¸æˆåç§°ï¼ˆå¯é€‰ï¼‰
        top_k: æ£€ç´¢ç»“æœæ•°é‡
        enable_hybrid_search: æ˜¯å¦å¯ç”¨æ··åˆæœç´¢
        hybrid_config: æ··åˆæœç´¢é…ç½®
        llm_config: LLMé…ç½®
        enable_summarization: æ˜¯å¦å¯ç”¨Geminiæ‘˜è¦
        summarization_config: æ‘˜è¦é…ç½®
        enable_intent_reranking: æ˜¯å¦å¯ç”¨æ„å›¾æ„ŸçŸ¥é‡æ’åº
        reranking_config: é‡æ’åºé…ç½®
        
    Returns:
        æŸ¥è¯¢ç»“æœå­—å…¸
    """
    # ä»é…ç½®æ–‡ä»¶åŠ è½½è®¾ç½®
    import os
    from pathlib import Path
    config_path = Path(__file__).parent.parent / "assets" / "settings.json"
    if config_path.exists():
        import json
        with open(config_path, 'r', encoding='utf-8') as f:
            settings = json.load(f)
            
            # åŠ è½½æ··åˆæœç´¢è®¾ç½®
            if hybrid_config is None:
                hybrid_search_settings = settings.get("hybrid_search", {})
                enable_hybrid_search = hybrid_search_settings.get("enabled", True)
                hybrid_config = {
                    "fusion_method": hybrid_search_settings.get("fusion_method", "rrf"),
                    "vector_weight": hybrid_search_settings.get("vector_weight", 0.3),
                    "bm25_weight": hybrid_search_settings.get("bm25_weight", 0.7),
                    "rrf_k": hybrid_search_settings.get("rrf_k", 60)
                }
            
            # åŠ è½½æ‘˜è¦è®¾ç½®
            if summarization_config is None:
                summarization_settings = settings.get("summarization", {})
                enable_summarization = summarization_settings.get("enabled", False)
                summarization_config = {
                    "api_key": summarization_settings.get("api_key") or os.environ.get("GEMINI_API_KEY"),
                    "model_name": summarization_settings.get("model_name", "gemini-2.5-flash-lite-preview-06-17"),
                    "max_summary_length": summarization_settings.get("max_summary_length", 300),
                    "temperature": summarization_settings.get("temperature", 0.3),
                    "include_sources": summarization_settings.get("include_sources", True),
                    "language": summarization_settings.get("language", "auto")
                }
            
            # åŠ è½½é‡æ’åºè®¾ç½®
            if enable_intent_reranking is None:
                reranking_settings = settings.get("intent_reranking", {})
                enable_intent_reranking = reranking_settings.get("enabled", True)
            
            if reranking_config is None:
                reranking_settings = settings.get("intent_reranking", {})
                reranking_config = {
                    "intent_weight": reranking_settings.get("intent_weight", 0.4),
                    "semantic_weight": reranking_settings.get("semantic_weight", 0.6)
                }
    
    rag_query = EnhancedRagQuery(
        enable_hybrid_search=enable_hybrid_search,
        hybrid_config=hybrid_config,
        llm_config=llm_config,
        enable_summarization=enable_summarization,
        summarization_config=summarization_config,
        enable_intent_reranking=enable_intent_reranking,
        reranking_config=reranking_config
    )
    
    await rag_query.initialize(game_name)
    return await rag_query.query(question, top_k)


class SimpleRagQuery(EnhancedRagQuery):
    """ç®€åŒ–çš„RAGæŸ¥è¯¢å™¨ï¼Œä¿æŒå‘åå…¼å®¹"""
    pass

def get_rag_query() -> SimpleRagQuery:
    """è·å–ç®€åŒ–RAGæŸ¥è¯¢å™¨çš„å•ä¾‹å®ä¾‹ï¼ˆå‘åå…¼å®¹ï¼‰"""
    return SimpleRagQuery()

async def query_rag(question: str, game_name: Optional[str] = None) -> Dict[str, Any]:
    """æ‰§è¡Œç®€åŒ–RAGæŸ¥è¯¢çš„ä¾¿æ·å‡½æ•°ï¼ˆå‘åå…¼å®¹ï¼‰"""
    return await query_enhanced_rag(question, game_name) 