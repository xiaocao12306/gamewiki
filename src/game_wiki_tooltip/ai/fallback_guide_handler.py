"""
Fallback Guide Handler - Handle guide queries for games without knowledge bases
============================================================================

When a game doesn't have a pre-built vector store but the user wants guide/strategy information,
this module uses Google Search grounding to provide answers with proper citations and warnings.
"""

import os
import logging
import asyncio
from typing import Optional, AsyncGenerator
from dataclasses import dataclass

logger = logging.getLogger(__name__)


@dataclass
class FallbackConfig:
    """Configuration for fallback guide handler"""
    api_key: str
    model_name: str = "gemini-2.5-flash"
    temperature: float = 0.3
    language: str = "auto"  # auto, zh, en


class FallbackGuideHandler:
    """Handle guide queries for unsupported games using Google Search"""
    
    def __init__(self, config: FallbackConfig, llm_config=None):
        """Initialize fallback guide handler"""
        self.config = config
        self.llm_config = llm_config  # Store LLM config for language settings
        logger.info(f"Initialized FallbackGuideHandler with model: {config.model_name}")
    
    async def generate_guide_stream(
        self,
        query: str,
        game_context: Optional[str] = None,
        language: str = "auto",
        original_query: Optional[str] = None
    ) -> AsyncGenerator[str, None]:
        """
        Generate guide response with Google Search grounding
        
        Args:
            query: User query (processed/translated)
            game_context: Game name or context
            language: Response language (auto/zh/en)
            original_query: Original user query for better context
            
        Yields:
            Streaming response chunks with warnings and citations
        """
        try:
            logger.debug(f"Starting fallback guide generation")
            logger.debug(f"Query: {query}")
            logger.debug(f"Game context: {game_context}")
            logger.debug(f"Language: {language}")
            logger.debug(f"Original query: {original_query}")
            
            # Import here to avoid startup delays
            from google import genai
            from google.genai import types
            
            # Configure the client
            client = genai.Client(api_key=self.config.api_key)
            
            # Define the grounding tool
            grounding_tool = types.Tool(
                google_search=types.GoogleSearch()
            )
            
            # Use LLM config response language if available
            if self.llm_config and hasattr(self.llm_config, 'response_language') and self.llm_config.response_language != "auto":
                language = self.llm_config.response_language
                logger.info(f"ðŸŒ Using LLM config response language for fallback guide: {language}")
            else:
                logger.info(f"ðŸŒ Using fallback language detection for fallback guide: {language}")
            
            # Build system instruction and prompt
            system_instruction = self._build_system_instruction(language)
            user_prompt = self._build_user_prompt(query, game_context, language, original_query)
            
            # Configure generation settings
            config = types.GenerateContentConfig(
                system_instruction=system_instruction,
                tools=[grounding_tool],
                temperature=self.config.temperature
            )
            
            logger.debug(f"Calling Gemini with Google Search")
            logger.debug(f"System instruction length: {len(system_instruction)} chars")
            logger.debug(f"User prompt length: {len(user_prompt)} chars")
            
            # Generate complete response using standard API
            response = client.models.generate_content(
                model=self.config.model_name,
                contents=user_prompt,
                config=config
            )
            
            logger.debug(f"Received complete response from Gemini")
            
            # Get main response text
            main_text = response.text if response.text else ""
            logger.debug(f"Main response length: {len(main_text)} characters")
            
            # Yield the main content
            if main_text:
                yield main_text
            
            # Try to extract and append real citations from grounding metadata
            try:
                citations_text = self._extract_grounding_citations(response, language)
                if citations_text:
                    logger.debug("Found grounding citations, appending to output")
                    yield citations_text
                else:
                    logger.debug("No additional citations to extract")
            except Exception as e:
                logger.debug(f"Citation extraction failed: {e}")
                # Continue without additional citations
            
        except Exception as e:
            logger.error(f"Error in fallback guide generation: {e}")
            logger.debug(f"Fallback error details: {e}")
            
            # Check for specific error types
            error_str = str(e).lower()
            if "quota" in error_str or "rate limit" in error_str or "429" in error_str:
                if language == "zh" or self._is_chinese(query):
                    yield (
                        "\n\n**API ä½¿ç”¨é™åˆ¶**\n\n"
                        "æ‚¨å·²è¾¾åˆ° Google Gemini API çš„ä½¿ç”¨é™åˆ¶ã€‚å…è´¹è´¦æˆ·é™åˆ¶ï¼š\n"
                        "â€¢ æ¯åˆ†é’Ÿæœ€å¤š 15 æ¬¡è¯·æ±‚\n"
                        "â€¢ æ¯å¤©æœ€å¤š 1500 æ¬¡è¯·æ±‚\n\n"
                        "è¯·ç¨åŽå†è¯•ï¼Œæˆ–è€ƒè™‘å‡çº§åˆ°ä»˜è´¹è´¦æˆ·ä»¥èŽ·å¾—æ›´é«˜çš„é…é¢ã€‚"
                    )
                else:
                    yield (
                        "\n\n**API Rate Limit**\n\n"
                        "You've reached the Google Gemini API usage limit. Free tier limits:\n"
                        "â€¢ Maximum 15 requests per minute\n"
                        "â€¢ Maximum 1500 requests per day\n\n"
                        "Please try again later, or consider upgrading to a paid account for higher quotas."
                    )
            elif "api_key" in error_str or "authentication" in error_str:
                if language == "zh" or self._is_chinese(query):
                    yield "\n\n**API å¯†é’¥é”™è¯¯**\n\nè¯·æ£€æŸ¥æ‚¨çš„ Google Gemini API å¯†é’¥é…ç½®ã€‚"
                else:
                    yield "\n\n**API Key Error**\n\nPlease check your Google Gemini API key configuration."
            else:
                # General error message
                if language == "zh" or self._is_chinese(query):
                    yield f"\n\næŠ±æ­‰ï¼Œç”ŸæˆæŒ‡å¯¼å†…å®¹æ—¶å‡ºçŽ°é”™è¯¯ï¼š{str(e)}"
                else:
                    yield f"\n\nSorry, an error occurred while generating guide content: {str(e)}"
    
    def _build_system_instruction(self, language: str) -> str:
        """Build system instruction with user warnings"""
        if language == "zh":
            return """ä½ æ˜¯ä¸€ä¸ªæ¸¸æˆç­–ç•¥æŒ‡å¯¼åŠ©æ‰‹ã€‚è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼å›žå¤ï¼š

1. é¦–å…ˆåœ¨å›žå¤å¼€å¤´æ·»åŠ ä»¥ä¸‹è­¦å‘Šï¼ˆä¿æŒåŽŸæ ·ï¼‰ï¼š
"NOTICE: æ‚¨æ­£åœ¨æ²¡æœ‰é¢„å»ºçŸ¥è¯†åº“çš„æ¸¸æˆä¸­ä½¿ç”¨AIæŒ‡å¯¼åŠŸèƒ½ã€‚æ¶‰åŠä¸»è§‚æŽ¨èçš„å†…å®¹ï¼ˆå¦‚é…è£…æŽ¨èç­‰ï¼‰å¯èƒ½å­˜åœ¨åå·®ï¼Œè¯·åŠ¡å¿…å‚è€ƒä¸‹æ–¹å¼•ç”¨çš„æƒå¨æ¥æºè¿›è¡ŒéªŒè¯ã€‚"

2. ç„¶åŽå›žç­”ç”¨æˆ·çš„æ¸¸æˆé—®é¢˜ï¼Œé‡ç‚¹æä¾›æ–¹æ³•å’Œç­–ç•¥ï¼š
- ä½¿ç”¨ç½‘ç»œæœç´¢èŽ·å–æœ€æ–°ä¿¡æ¯æ¥æº
- é‡ç‚¹è¯´æ˜Ž"å¦‚ä½•åš"çš„æ–¹æ³•å’Œæ­¥éª¤ï¼Œè€Œä¸æ˜¯å¤åˆ¶å…·ä½“çš„æ•°å€¼ã€ç‰©å“åˆ—è¡¨ã€æŽ‰è½çŽ‡ç­‰è¯¦ç»†æ•°æ®
- æä¾›æ“ä½œæŠ€å·§ã€ç­–ç•¥æ€è·¯ã€æ³¨æ„äº‹é¡¹ç­‰å®žç”¨æŒ‡å¯¼
- å¦‚æžœæ¶‰åŠè£…å¤‡æˆ–é…ç½®ï¼Œè¯´æ˜Žé€‰æ‹©åŽŸåˆ™è€Œä¸æ˜¯å…·ä½“åç§°å’Œæ•°æ®
- å¼•å¯¼ç”¨æˆ·åˆ°æƒå¨æ¥æºæŸ¥çœ‹è¯¦ç»†æ•°æ®

è¯·ç”¨ä¸­æ–‡å›žç­”ï¼Œé‡ç‚¹å…³æ³¨æ–¹æ³•è®ºå’Œæ“ä½œæŒ‡å¯¼ï¼Œé¿å…ç›´æŽ¥å¤åˆ¶wikiçš„å…·ä½“æ•°æ®å†…å®¹ã€‚"""

        else:
            return """You are a gaming strategy guide assistant. Please strictly follow this format:

1. Start your response with this notice (keep as-is):
"NOTICE: You are using AI guidance in a game without a pre-built knowledge base. Content involving subjective recommendations (such as build recommendations) may be biased. Please verify against the authoritative sources cited below."

2. Then answer the user's gaming question, focusing on methods and strategies:
- Use web search to get latest information sources
- Focus on explaining "how to do" methods and steps, rather than copying specific numbers, item lists, drop rates, or detailed data
- Provide operational tips, strategic approaches, and key considerations
- For equipment or builds, explain selection principles rather than specific names and stats
- Guide users to authoritative sources for detailed data"

Answer in the same language as the user's query, focusing on methodology and operational guidance, avoiding direct copying of specific wiki data content."""
    
    def _build_user_prompt(
        self,
        query: str,
        game_context: Optional[str],
        language: str,
        original_query: Optional[str]
    ) -> str:
        """Build user prompt for the query"""
        if language == "zh" or self._is_chinese(query):
            base_prompt = f"è¯·å¸®æˆ‘å›žç­”è¿™ä¸ªæ¸¸æˆé—®é¢˜ï¼š{query}"
            
            if original_query and original_query != query:
                base_prompt += f"\n\nï¼ˆåŽŸå§‹é—®é¢˜ï¼š{original_query}ï¼‰"
            
            if game_context:
                base_prompt += f"\n\næ¸¸æˆèƒŒæ™¯ï¼š{game_context}"
            
            base_prompt += "\n\nè¯·æœç´¢æœ€æ–°çš„æ¸¸æˆä¿¡æ¯å¹¶æä¾›è¯¦ç»†çš„æŒ‡å¯¼ã€‚"
            
        else:
            base_prompt = f"Please help me answer this gaming question: {query}"
            
            if original_query and original_query != query:
                base_prompt += f"\n\n(Original question: {original_query})"
            
            if game_context:
                base_prompt += f"\n\nGame context: {game_context}"
            
            base_prompt += "\n\nPlease search for the latest game information and provide detailed guidance."
        
        return base_prompt
    
    def _is_chinese(self, text: str) -> bool:
        """Check if text contains Chinese characters"""
        if not text:
            return False
        chinese_chars = sum(1 for char in text if '\u4e00' <= char <= '\u9fff')
        return chinese_chars > len(text) * 0.3
    
    def _extract_grounding_citations(self, response, language: str) -> Optional[str]:
        """Extract real citations from Google Search grounding metadata"""
        try:
            # Check if we have candidates with grounding metadata
            if not (hasattr(response, 'candidates') and response.candidates):
                logger.debug("No candidates found in response")
                return None
                
            candidate = response.candidates[0]
            if not (hasattr(candidate, 'grounding_metadata') and candidate.grounding_metadata):
                logger.debug("No grounding metadata found in candidate")
                return None
                
            grounding_metadata = candidate.grounding_metadata
            logger.debug("Found grounding metadata in response")
            
            # Try to get grounding chunks (should contain URLs and titles)
            grounding_chunks = getattr(grounding_metadata, 'grounding_chunks', None)
            
            if grounding_chunks and len(grounding_chunks) > 0:
                logger.debug(f"Found {len(grounding_chunks)} grounding chunks")
                
                citations = []
                for i, chunk in enumerate(grounding_chunks):
                    try:
                        # Try to access web information
                        web_info = getattr(chunk, 'web', None)
                        if web_info:
                            uri = getattr(web_info, 'uri', None)
                            title = getattr(web_info, 'title', None)
                            
                            if uri and title:
                                # Clean up title
                                if title and '.' in title and len(title.split()) == 1:
                                    title = f"Source from {title}"
                                
                                citations.append({
                                    'uri': uri,
                                    'title': title or 'Web Source'
                                })
                                logger.debug(f"Extracted citation {i}: {title} - {uri}")
                                
                    except Exception as e:
                        logger.debug(f"Error processing grounding chunk {i}: {e}")
                        continue
                
                if citations:
                    return self._format_citations(citations, language)
                else:
                    logger.debug("No valid citations extracted from grounding chunks")
            
            # Check grounding supports as fallback
            grounding_supports = getattr(grounding_metadata, 'grounding_supports', None)
            if grounding_supports and len(grounding_supports) > 0:
                logger.debug(f"Google Search active with {len(grounding_supports)} grounding supports")
                # Citations are integrated in AI response, but no extractable URLs
                return None
            
            logger.debug("No grounding chunks or supports found")
            return None
            
        except Exception as e:
            logger.debug(f"Error extracting grounding citations: {e}")
            return None
    
    def _format_citations(self, citations: list, language: str) -> str:
        """Format citations into user-friendly text"""
        if not citations:
            return None
            
        # Remove AI-generated citation section and replace with real ones
        if language == "zh":
            citation_header = "\n\n**Real Sources (Verified):**\n"
        else:
            citation_header = "\n\n**Real Sources (Verified):**\n"
        
        citation_lines = []
        seen_uris = set()  # Deduplicate citations
        
        for citation in citations:
            uri = citation['uri']
            title = citation['title']
            
            # Skip duplicates
            if uri in seen_uris:
                continue
            seen_uris.add(uri)
            
            # Format citation line
            citation_lines.append(f"- [{title}]({uri})")
        
        if citation_lines:
            return citation_header + "\n".join(citation_lines)
        else:
            return None


# Convenience function
def create_fallback_guide_handler(
    api_key: Optional[str] = None,
    model_name: str = "gemini-2.5-flash",
    llm_config=None,
    **kwargs
) -> FallbackGuideHandler:
    """
    Create a FallbackGuideHandler instance
    
    Args:
        api_key: Google API key
        model_name: Model to use (gemini-2.5-flash recommended)
        llm_config: LLM configuration for language settings
        **kwargs: Additional config parameters
        
    Returns:
        FallbackGuideHandler instance
    """
    if not api_key:
        api_key = os.environ.get("GOOGLE_API_KEY") or os.environ.get("GEMINI_API_KEY")
        if not api_key:
            raise ValueError("Google API key not provided")
    
    config = FallbackConfig(
        api_key=api_key,
        model_name=model_name,
        **kwargs
    )
    
    return FallbackGuideHandler(config, llm_config=llm_config)